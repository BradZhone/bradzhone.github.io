import{_ as c}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as l,o as u,c as i,a as n,d as a,w as e,b as s,e as p}from"./app-Coh1oo3x.js";const d="/assets/image-20221108171540235-2ioNMG-d.png",r="/assets/image-20221108170653755-DPFXAhTN.png",k="/assets/641-B16B_pOR.png",m="/assets/642-DwzHOy1P.png",b="/assets/640-CS1I0ZdW.png",h="/assets/image-20221108165507297-BOY8AWvn.png",g={},_=p(`<h1 id="hugectr源码阅读笔记" tabindex="-1"><a class="header-anchor" href="#hugectr源码阅读笔记"><span>HugeCTR源码阅读笔记</span></a></h1><h2 id="_1-data" tabindex="-1"><a class="header-anchor" href="#_1-data"><span>1. Data</span></a></h2><ul><li><p>深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例：</p></li><li><p><strong>数值特征</strong>（numeric feature、dense feature）：</p><ul><li><table><thead><tr><th></th><th>_col0</th><th>_col1</th><th>_col2</th><th>_col3</th><th>_col4</th><th>_col5</th><th>_col6</th></tr></thead><tbody><tr><td>0</td><td>0.080380</td><td>0.435741</td><td>0.078185</td><td>0.194161</td><td>0.087724</td><td>0.845081</td><td>0.937019</td></tr><tr><td>1</td><td>0.310647</td><td>0.669963</td><td>0.218886</td><td>0.945537</td><td>0.735421</td><td>0.637027</td><td>0.007011</td></tr><tr><td>2</td><td>0.337267</td><td>0.908792</td><td>0.795987</td><td>0.608301</td><td>0.290421</td><td>0.012273</td><td>0.671650</td></tr><tr><td>3</td><td>0.873908</td><td>0.694296</td><td>0.796788</td><td>0.553089</td><td>0.872149</td><td>0.502299</td><td>0.114150</td></tr><tr><td>4</td><td>0.333109</td><td>0.456773</td><td>0.403027</td><td>0.091778</td><td>0.215718</td><td>0.729457</td><td>0.941204</td></tr></tbody></table></li><li><table><thead><tr><th></th><th>_col7</th><th>_col8</th><th>_col9</th><th>_col10</th><th>_col11</th><th>_col12</th><th>_col13</th></tr></thead><tbody><tr><td>0</td><td>0.977882</td><td>0.042342</td><td>0.054632</td><td>0.855919</td><td>0.264451</td><td>0.224891</td><td>0.467242</td></tr><tr><td>1</td><td>0.204856</td><td>0.307856</td><td>0.775143</td><td>0.265654</td><td>0.301945</td><td>0.066413</td><td>0.499416</td></tr><tr><td>2</td><td>0.960113</td><td>0.018073</td><td>0.639101</td><td>0.229013</td><td>0.645756</td><td>0.123180</td><td>0.894010</td></tr><tr><td>3</td><td>0.444433</td><td>0.001794</td><td>0.147979</td><td>0.083302</td><td>0.744487</td><td>0.971924</td><td>0.362019</td></tr><tr><td>4</td><td>0.997079</td><td>0.563684</td><td>0.811862</td><td>0.457039</td><td>0.133213</td><td>0.169442</td><td>0.124149</td></tr></tbody></table></li></ul></li><li><p><strong>分类特征</strong>（sparse feature、category feature）：</p><ul><li><table><thead><tr><th></th><th>_col14</th><th>_col15</th><th>_col16</th><th>_col17</th><th>_col18</th><th>_col19</th><th>_col20</th><th>_col21</th><th>_col22</th></tr></thead><tbody><tr><td>0</td><td>151</td><td>0</td><td>9</td><td>13</td><td>1</td><td>1</td><td>1</td><td>9</td><td>4</td></tr><tr><td>1</td><td>0</td><td>0</td><td>11</td><td>4801</td><td>44</td><td>2</td><td>160</td><td>9</td><td>0</td></tr><tr><td>2</td><td>4549</td><td>3</td><td>1</td><td>10</td><td>31</td><td>2</td><td>485</td><td>2</td><td>10</td></tr><tr><td>3</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>3</td><td>111</td><td>10</td></tr><tr><td>4</td><td>2</td><td>5</td><td>160</td><td>0</td><td>72</td><td>0</td><td>13</td><td>53</td><td>0</td></tr></tbody></table></li><li><table><thead><tr><th></th><th>_col23</th><th>_col24</th><th>_col25</th><th>_col26</th><th>_col27</th><th>_col28</th><th>_col29</th><th>_col30</th><th>_col31</th></tr></thead><tbody><tr><td>0</td><td>2</td><td>395</td><td>41</td><td>1</td><td>14</td><td>5</td><td>2</td><td>7</td><td>0</td></tr><tr><td>1</td><td>101</td><td>3</td><td>1</td><td>1</td><td>4</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>2</td><td>2</td><td>19</td><td>6</td><td>6</td><td>1</td><td>0</td><td>4</td><td>1</td><td>2</td></tr><tr><td>3</td><td>1</td><td>2</td><td>38</td><td>6</td><td>1</td><td>7</td><td>1</td><td>2</td><td>0</td></tr><tr><td>4</td><td>63</td><td>616</td><td>7</td><td>1</td><td>175</td><td>23</td><td>4</td><td>0</td><td>1</td></tr></tbody></table></li><li><table><thead><tr><th></th><th>_col32</th><th>_col33</th><th>_col34</th><th>_col35</th><th>_col36</th><th>_col37</th><th>_col38</th><th>_col39</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>1</td><td>5283</td><td>4</td><td>0</td><td>21</td><td>33</td><td>1</td></tr><tr><td>1</td><td>2</td><td>3</td><td>204</td><td>310</td><td>1640</td><td>6</td><td>4</td><td>6</td></tr><tr><td>2</td><td>4</td><td>7</td><td>29</td><td>2</td><td>11</td><td>66</td><td>2</td><td>22</td></tr><tr><td>3</td><td>9</td><td>43</td><td>2</td><td>10</td><td>286</td><td>6</td><td>2</td><td>0</td></tr><tr><td>4</td><td>0</td><td>477</td><td>10</td><td>6</td><td>0</td><td>2</td><td>0</td><td>30</td></tr></tbody></table></li></ul></li><li><p>数据相关属性：</p><ul><li><p>以生成模拟数据为例：</p><ul><li><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># generate_data.py</span>

<span class="token keyword">import</span> hugectr
<span class="token keyword">from</span> hugectr<span class="token punctuation">.</span>tools <span class="token keyword">import</span> DataGenerator<span class="token punctuation">,</span> DataGeneratorParams
<span class="token keyword">from</span> mpi4py <span class="token keyword">import</span> MPI
<span class="token keyword">import</span> argparse
parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">&quot;Data Generation&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&quot;--num_files&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;number of files in training data&quot;</span><span class="token punctuation">,</span> default <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&quot;--eval_num_files&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;number of files in validation data&quot;</span><span class="token punctuation">,</span> default <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&#39;--num_samples_per_file&#39;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;number of samples per file&quot;</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1000000</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&#39;--dir_name&#39;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;data directory name(Required)&quot;</span><span class="token punctuation">)</span>
args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

data_generator_params <span class="token operator">=</span> DataGeneratorParams<span class="token punctuation">(</span>
  <span class="token builtin">format</span> <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>DataReaderType_t<span class="token punctuation">.</span>Parquet<span class="token punctuation">,</span>
  label_dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
  dense_dim <span class="token operator">=</span> <span class="token number">13</span><span class="token punctuation">,</span>
  num_slot <span class="token operator">=</span> <span class="token number">26</span><span class="token punctuation">,</span>
  num_files <span class="token operator">=</span> args<span class="token punctuation">.</span>num_files<span class="token punctuation">,</span>
  eval_num_files <span class="token operator">=</span> args<span class="token punctuation">.</span>eval_num_files<span class="token punctuation">,</span>
  i64_input_key <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
  num_samples_per_file <span class="token operator">=</span> args<span class="token punctuation">.</span>num_samples_per_file<span class="token punctuation">,</span>
  source <span class="token operator">=</span> <span class="token string">&quot;./etc_data/&quot;</span> <span class="token operator">+</span> args<span class="token punctuation">.</span>dir_name <span class="token operator">+</span> <span class="token string">&quot;/file_list.txt&quot;</span><span class="token punctuation">,</span>
  eval_source <span class="token operator">=</span> <span class="token string">&quot;./etc_data/&quot;</span> <span class="token operator">+</span> args<span class="token punctuation">.</span>dir_name <span class="token operator">+</span> <span class="token string">&quot;/file_list_test.txt&quot;</span><span class="token punctuation">,</span>
  slot_size_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">12988</span><span class="token punctuation">,</span> <span class="token number">7129</span><span class="token punctuation">,</span> <span class="token number">8720</span><span class="token punctuation">,</span> <span class="token number">5820</span><span class="token punctuation">,</span> <span class="token number">15196</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4914</span><span class="token punctuation">,</span> <span class="token number">1020</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">14274</span><span class="token punctuation">,</span> <span class="token number">10220</span><span class="token punctuation">,</span> <span class="token number">15088</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1518</span><span class="token punctuation">,</span> <span class="token number">3672</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">820</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">12817</span><span class="token punctuation">,</span> <span class="token number">13908</span><span class="token punctuation">,</span> <span class="token number">13447</span><span class="token punctuation">,</span> <span class="token number">9447</span><span class="token punctuation">,</span> <span class="token number">5867</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  nnz_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token comment"># for parquet, check_type doesn&#39;t make any difference</span>
  check_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>Check_t<span class="token punctuation">.</span>Non<span class="token punctuation">,</span>
  dist_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>Distribution_t<span class="token punctuation">.</span>PowerLaw<span class="token punctuation">,</span>
  power_law_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>PowerLaw_t<span class="token punctuation">.</span>Short<span class="token punctuation">)</span>
data_generator <span class="token operator">=</span> DataGenerator<span class="token punctuation">(</span>data_generator_params<span class="token punctuation">)</span>
data_generator<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>num_files：即数据集分为几个子集，也是使用ETC训练时每一个pass所用到的数据，子集数等于训练所需pass数</p></li><li><p>num_samples_per_file：也即每个子数据集的样本数</p></li><li><p>label_dim：每一个sample的标签维度</p></li><li><p>dense_dim：连续特征的数量</p></li><li><p>num_slot：分类特征的数量，也即slot数（特征域数量）</p></li><li><p>slot_size_array：每一个slot中的最大特征数量（也就是特征域的大小）</p></li><li><p>nnz_array： 样本在对应的slot (特征域)中最多可同时有几个特征（用于选择是one-hot还是multi-hot）</p></li></ul></li><li><p>执行脚本生成模拟数据（总共产生8个训练数据子集和2个测试子集）：</p><ul><li><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>python generate_data<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>dir_name <span class="token string">&quot;file0&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: Generate Parquet dataset
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: train data folder: ./etc_data/file0, <span class="token builtin class-name">eval</span> data folder: ./etc_data/file0, slot_size_array: <span class="token number">12988</span>, <span class="token number">7129</span>, <span class="token number">8720</span>, <span class="token number">5820</span>, <span class="token number">15196</span>, <span class="token number">4</span>, <span class="token number">4914</span>, <span class="token number">1020</span>, <span class="token number">30</span>, <span class="token number">14274</span>, <span class="token number">10220</span>, <span class="token number">15088</span>, <span class="token number">10</span>, <span class="token number">1518</span>, <span class="token number">3672</span>, <span class="token number">48</span>, <span class="token number">4</span>, <span class="token number">820</span>, <span class="token number">15</span>, <span class="token number">12817</span>, <span class="token number">13908</span>, <span class="token number">13447</span>, <span class="token number">9447</span>, <span class="token number">5867</span>, <span class="token number">45</span>, <span class="token number">33</span>, nnz array: <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token comment">#files for train: 8, #files for eval: 2, #samples per file: 1000000, Use power law distribution: 1, alpha of power law: 1.3</span>
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0 exist
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_0.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:33.757<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_1.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:36.560<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_2.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:39.337<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_3.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:42.083<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_4.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:44.807<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_5.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:47.641<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_6.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:50.377<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_7.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:53.131<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/file_list.txt done<span class="token operator">!</span>
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:53.132<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/val/gen_0.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:55.941<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/val/gen_1.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:58.788<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/file_list_test.txt done<span class="token operator">!</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>输出keysets（以gen_0为例）：</p><ul><li><p>每一个子数据集（每个pass用的数据集）会生成一个keysets，所有数据的keysets构成一个更大的集合all_keysets，最终将根据all_keysets生成keysets文件xxx.keyset供GPU在t时刻预读取t+1时刻的数据到ETC中</p></li><li><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>  ------------------------
  unique_keys:
  <span class="token number">0</span>            <span class="token number">0</span>
  <span class="token number">1</span>            <span class="token number">1</span>
  <span class="token number">2</span>            <span class="token number">2</span>
  <span class="token number">3</span>            <span class="token number">3</span>
  <span class="token number">4</span>            <span class="token number">4</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">12115</span>    <span class="token number">12978</span>
  <span class="token number">12116</span>    <span class="token number">12979</span>
  <span class="token number">12117</span>    <span class="token number">12981</span>
  <span class="token number">12118</span>    <span class="token number">12983</span>
  <span class="token number">12119</span>    <span class="token number">12986</span>
  Name: _col14, Length: <span class="token number">12120</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">12988</span>
  <span class="token number">1</span>       <span class="token number">12989</span>
  <span class="token number">2</span>       <span class="token number">12990</span>
  <span class="token number">3</span>       <span class="token number">12991</span>
  <span class="token number">4</span>       <span class="token number">12992</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">7077</span>    <span class="token number">20111</span>
  <span class="token number">7078</span>    <span class="token number">20112</span>
  <span class="token number">7079</span>    <span class="token number">20113</span>
  <span class="token number">7080</span>    <span class="token number">20114</span>
  <span class="token number">7081</span>    <span class="token number">20116</span>
  Name: _col15, Length: <span class="token number">7082</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">20117</span>
  <span class="token number">1</span>       <span class="token number">20118</span>
  <span class="token number">2</span>       <span class="token number">20119</span>
  <span class="token number">3</span>       <span class="token number">20120</span>
  <span class="token number">4</span>       <span class="token number">20121</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">8554</span>    <span class="token number">28827</span>
  <span class="token number">8555</span>    <span class="token number">28828</span>
  <span class="token number">8556</span>    <span class="token number">28830</span>
  <span class="token number">8557</span>    <span class="token number">28831</span>
  <span class="token number">8558</span>    <span class="token number">28834</span>
  Name: _col16, Length: <span class="token number">8559</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">28837</span>
  <span class="token number">1</span>       <span class="token number">28838</span>
  <span class="token number">2</span>       <span class="token number">28839</span>
  <span class="token number">3</span>       <span class="token number">28840</span>
  <span class="token number">4</span>       <span class="token number">28841</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">5798</span>    <span class="token number">34652</span>
  <span class="token number">5799</span>    <span class="token number">34653</span>
  <span class="token number">5800</span>    <span class="token number">34654</span>
  <span class="token number">5801</span>    <span class="token number">34655</span>
  <span class="token number">5802</span>    <span class="token number">34656</span>
  Name: _col17, Length: <span class="token number">5803</span>, dtype: int64
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li></ul></li></ul></li><li><p>使用ETC分pass训练示例(与上例不同，此例使用10个pass来训练)：</p><ul><li><table><thead><tr><th style="text-align:right;">Pass ID</th><th style="text-align:right;">Number of Unique Keys</th><th style="text-align:right;">Embedding size (GB)</th></tr></thead><tbody><tr><td style="text-align:right;">#0</td><td style="text-align:right;">24199179</td><td style="text-align:right;">11.54</td></tr><tr><td style="text-align:right;">#1</td><td style="text-align:right;">26015075</td><td style="text-align:right;">12.40</td></tr><tr><td style="text-align:right;">#2</td><td style="text-align:right;">27387817</td><td style="text-align:right;">13.06</td></tr><tr><td style="text-align:right;">#3</td><td style="text-align:right;">23672542</td><td style="text-align:right;">11.29</td></tr><tr><td style="text-align:right;">#4</td><td style="text-align:right;">26053910</td><td style="text-align:right;">12.42</td></tr><tr><td style="text-align:right;">#5</td><td style="text-align:right;">27697628</td><td style="text-align:right;">13.21</td></tr><tr><td style="text-align:right;">#6</td><td style="text-align:right;">24727672</td><td style="text-align:right;">11.79</td></tr><tr><td style="text-align:right;">#7</td><td style="text-align:right;">25643779</td><td style="text-align:right;">12.23</td></tr><tr><td style="text-align:right;">#8</td><td style="text-align:right;">26374086</td><td style="text-align:right;">12.58</td></tr><tr><td style="text-align:right;">#9</td><td style="text-align:right;">26580983</td><td style="text-align:right;">12.67</td></tr></tbody></table></li></ul></li><li><p>数据预处理时，HugeCTR将分类特征转换为整型序列的方法：</p><ul><li><p>使用NVTabular：</p></li><li><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># e.g. using NVTabular</span>

target_encode <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token string">&#39;brand&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;user_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;product_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;cat_2&#39;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&#39;ts_weekday&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;ts_day&#39;</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span>
    nvt<span class="token punctuation">.</span>ops<span class="token punctuation">.</span>TargetEncoding<span class="token punctuation">(</span>
        nvt<span class="token punctuation">.</span>ColumnGroup<span class="token punctuation">(</span><span class="token string">&#39;target&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        kfold<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
        p_smooth<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
        out_dtype<span class="token operator">=</span><span class="token string">&quot;float32&quot;</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><blockquote><p>https://nvidia-merlin.github.io/NVTabular/v0.7.1/api/ops/targetencoding.html</p><p>Target encoding is a common feature-engineering technique for categorical columns in tabular datasets. For each categorical group, the mean of a continuous target column is calculated, and the group-specific mean of each row is used to create a new feature (column). To prevent overfitting, the following additional logic is applied:</p><blockquote><ol><li><p>Cross Validation: To prevent overfitting in training data, a cross-validation strategy is used - The data is split into k random “folds”, and the mean values within the i-th fold are calculated with data from all other folds. The cross-validation strategy is only employed when the dataset is used to update recorded statistics. For transformation-only workflow execution, global-mean statistics are used instead.</p></li><li><p>Smoothing: To prevent overfitting for low cardinality categories, the means are smoothed with the overall mean of the target variable.</p></li></ol></blockquote></blockquote></li></ul></li></ul><h2 id="_2-hashing" tabindex="-1"><a class="header-anchor" href="#_2-hashing"><span>2. Hashing</span></a></h2>`,4),v=n("ul",null,[n("li",null,"存储hashtable和embedding的数据结构是什么？"),n("li",null,"为什么使用hash可以节省空间??"),n("li",null,"是每一个分类特征对应一个hashtable吗？（但是示例合成数据里面的key都是全局的key，而不是分特征从0开始累计的）")],-1),y=n("li",null,[n("p",null,"relevant:"),n("ul",null,[n("li",null,"<thrust/pairs.h> : 用于封装异构元素对（实现k-v）")])],-1),f={href:"https://cloud.tencent.com/developer/article/1871846",target:"_blank",rel:"noopener noreferrer"},x=n("ul",null,[n("li",null,"用于压缩embedding（将n维one-hot特征编码为m维one-hot特征，且m<n）：如果不用hash，使用one-hot full embedding 的方式，则embedding将会非常庞大，因为许多低频特征也将占据大量embedding空间"),n("li",null,"当出现新特征时可动态扩容embedding")],-1),T=n("p",null,"什么hash函数（non-cryptographic hash function）",-1),q=n("li",null,"Identity hash function：当数据足够小的时候（如key小于int64时）可以直接将数据作为hash value。也即直接将分类特征的key作为value用于查embedding？",-1),R={href:"https://github.com/aappleby/smhasher/blob/master/src/MurmurHash3.cpp",target:"_blank",rel:"noopener noreferrer"},C=p('<li><p>如何查（怎么分布式）</p><ul><li><p>每一个GPU上存放着不同slot对应的hashtable，用于压缩embedding matrix，在进行数据并行，每个GPU获得输入数据后，先做all-to-all将需要查询的数据对应特征传输到存储其特征域（slot）embedding的GPU上，再在对应GPU上查表（lookup）得到embedding vector，再使用all-to-all返回查询结果到原来的GPU中，每个GPU再通过寄存器合并不同特征域的embedding作为最终输入前馈网络的数据<img src="'+d+'" alt="image-20221108171540235" loading="lazy"></p></li><li><p>embedding前的输入数据为64位int哈希值，只有训练数据出现新的key而hashtable找不到时才在运行时插入一对k-v:</p></li><li><blockquote><p>Embedding initialization is not required before training takes place since the input training data are hash values (64-bit signed integer type) instead of original indices. A pair of &lt;key,value&gt; (random small weight) will be inserted during runtime only when a new key appears in the training data and the hash table cannot find it.</p></blockquote></li></ul></li><li><p>每一个GPU中的hashtable是一样的吗？</p><ul><li></li></ul></li>',2),w=n("p",null,"输出hashing 的是什么，是需要传入embedding table 中的值还是直接输出embedding vector？且输出的hash是指向CPU mem还是GPU cache？",-1),N=n("li",null,[n("p",null,"发生hash冲突如何处理？"),n("ul",null,[n("li",null,[s("业界处理方法： "),n("ul",null,[n("li",null,"double hash：使用两个hash函数分别计算编码，再聚合（e.g. sum）"),n("li",null,"frequency hash：只对低频特征做hashing，高频特征直接查表（identity hash？）"),n("li",null,"其他方法：Bloom Emb、Compositional Emb、Hash Emb")])]),n("li",null,"Hugectr处理方法：")])],-1),H=n("li",null,null,-1),I=n("h2",{id:"_3-embedding",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#_3-embedding"},[n("span",null,"3. Embedding")])],-1),O=n("li",null,[n("p",null,"embedding的插入查询先后顺序问题如何解决（读后写问题）？"),n("ul",null,[n("li",null,"若当前thread准备插入一个slot，发现此处key已存入但是value暂未存入，说明有其他线程正在操作当前slot，则当前thread不操作，等待其他thread插入value")])],-1),P=n("li",null,[n("p",null,"embedding和hashtable内是如何搜索的？（什么搜索策略or直接计算得到?）")],-1),D=n("li",null,[n("p",null,"embedding是如何划分的，与梯度数据的关系为何？"),n("ul",null,[n("li",null,"embedding是按照slot进行划分成一个个embedding table，然后将这些slot分布式存储在不同GPU上，每一个slot代表一个特征域，比如说用户的国籍作为一个category特征可以组成一个特征域（这里的特征域可以是多种特征融合而成的一个大的特征域）"),n("li",null,[s("而embedding层之上的前馈网络梯度数据是另外存储在GPU上的，可以看见使用SOK的代码将他们分别存储"),n("img",{src:r,alt:"image-20221108170653755",loading:"lazy"})])])],-1),z=n("p",null,[n("em",null,"参考实现：")],-1),K={href:"https://mp.weixin.qq.com/s/rEHhf32L09KXGJ9bbB2LEA",target:"_blank",rel:"noopener noreferrer"},F=n("strong",null,"实现embedding查找??(查找什么？查embedding吗？假如没有hashtable又会有什么不同？)",-1),G=p('<li><blockquote><p>The total number of embedding parameters is tens of billions, and there are thousands of feature fields in each sample. As the range of input features is not fixed and unknown in advance, the team uses hash tables to uniquely identify each input feature before feeding into an embedding layer</p></blockquote></li><li><p>hashtable只是一种存储稀疏特征embedding的方式，其他特征的存储可使用Variable存储（也即使用hash压缩embedding）</p></li><li><blockquote><p><strong>稀疏特征</strong>（ID类特征，规模较大，使用HashTable存储）：由于每张卡的输入样本数据不同，因此输入的稀疏特征对应的特征向量，可能存放在其他GPU卡上。具体流程上，训练的前向我们通过卡间AllToAll通信，将每张卡的ID特征以Modulo的方式Partition到其他卡中，每张卡再去卡内的GPUHashTable查询稀疏特征向量，然后再通过卡间AllToAll通信，将第一次AllToAll从其他卡上拿到的ID特征以及对应的特征向量原路返回，通过两次卡间AllToAll通信，每张卡样本输入的ID特征都拿到对应的特征向量。训练的反向则会再次通过卡间AllToAll通信，将稀疏参数的梯度以Modulo的方式Partition到其他卡中，每张卡拿到自己的稀疏梯度后再执行稀疏优化器，完成大规模稀疏特征的优化。详细流程如下图所示：<img src="'+k+'" alt="图片" loading="lazy"></p></blockquote></li><li><p>传统embedding方法：对特征进行编码，得到ID（key），用ID去embedding里面查表，得到对应的embedding（需要存放非常大的embedding），使用hashtable做压缩：将ID传入hash function，得到hashed indices，再传入embedding table得到embedding</p></li><li><blockquote><p>压缩方法的话也有几个分类，这里简单提几个比较有趣的工作，第一个就是twitter在Recsys 2021发表的Double hash的方法。这种方法首先把特征分成了高频和低频，因为高频特征相对比例比较小，给每一个高频特征分配一个独立的embedding，它所占的空间也不是很大。对于低频特征，使用Double hash方法进行压缩，该hash方法是为了尽可能地减少冲突<img src="'+m+'" alt="图片" loading="lazy"></p></blockquote></li><li><p>对于ids不大的sparse特征，直接使用数据副本的方式在每个gpu上存放所有特征；对于dense特征，也是使用replica方式在每个gpu上存放所有特征。<img src="'+b+'" alt="图片" style="zoom:200%;"></p></li>',6),E=p('<h2 id="_4-other" tabindex="-1"><a class="header-anchor" href="#_4-other"><span>4. Other</span></a></h2><ul><li><p><strong>Training Steps</strong>:</p><ol><li>Create the solver, reader and optimizer, then initialize the model.</li><li>Construct the model graph by adding input, sparse embedding and dense layers in order.</li><li>Compile the model and have an overview of the model graph.</li><li>Dump the model graph to the JSON file.</li><li>Fit the model, save the model weights and optimizer states implicitly.</li></ol></li><li><p>参数服务器是如何布置的（在做数据并行时是否有某个server做master，以及master和worker的关系）</p><ul><li>CPU做PS，GPU做worker</li><li><img src="'+h+'" alt="image-20221108165507297" tabindex="0" loading="lazy"><figcaption>image-20221108165507297</figcaption></li></ul></li><li><p>Embedding Training Cache (ETC)：</p><ul><li>用于解决embedding太大无法放入GPU显存的问题</li><li>将数据集划分为一个个子集，训练每个子集的过程称为一个pass，每个数据集都有从category特征中提取出的keyset</li><li>所有key都使用与数据集分类特征相同的数据类型（uint，ll等）</li><li>key可以以任何顺序存储</li></ul></li></ul>',2),U={id:"_5-sok",tabindex:"-1"},A={class:"header-anchor",href:"#_5-sok"},S=p(`<ul><li><p>SOK项目结构（包含从父文件夹获取的HugeCTR等）</p><table><thead><tr><th style="text-align:center;">DIR</th><th style="text-align:center;">Discription</th></tr></thead><tbody><tr><td style="text-align:center;">cmakes</td><td style="text-align:center;">用于构建项目时查找NCCL、NVTX、Tensorflow组件及判断版本号</td></tr><tr><td style="text-align:center;">documents</td><td style="text-align:center;">用于生成文档，包含示例代码和benchmark</td></tr><tr><td style="text-align:center;">experiment</td><td style="text-align:center;">SOK的实验性功能更新</td></tr><tr><td style="text-align:center;">HugeCTR</td><td style="text-align:center;">HugeCTR核心功能</td></tr><tr><td style="text-align:center;">kit_cc</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">kit_cc_impl</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">notebooks</td><td style="text-align:center;">SOK jupyter 示例</td></tr><tr><td style="text-align:center;">sparse_operation_kit</td><td style="text-align:center;">sok核心功能</td></tr><tr><td style="text-align:center;">third_party</td><td style="text-align:center;">其他依赖项，json</td></tr><tr><td style="text-align:center;">unit_test</td><td style="text-align:center;">单元测试，包含tf1&amp;2单卡多卡测试</td></tr></tbody></table></li><li><p>从setup.py开始编译安装sok，需要依赖于父文件夹中的HugeCTR和third_party/json</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>os.system(&quot;cp -r ../HugeCTR ./&quot;)
os.system(&quot;mkdir third_party&quot;)
os.system(&quot;cp -r ../third_party/json ./third_party/&quot;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>Notes：</strong></p><ul><li><p>使用hvd时，hvd的初始化需要在最前面</p></li><li><p>使用tf1时，sok初始化要在其他变量初始化之前</p></li></ul></li><li><p>sok如何使用hctr的so库，从何处编译:</p><ul><li><p>hugectr/sparse_operation_kit/sparse_operation_kit/kit_lib.py: 导入libsparse_operation_kit.so</p></li><li><p>hugectr/sparse_operation_kit/sparse_operation_kit/operations/compat_ops_lib.py：导入libsparse_operation_kit_compat_ops.so</p></li></ul></li><li><p>HCTR加速embedding的方法：重新实现embedding层，GPU加速的hashtable（基于RAPIDS cuDF，可实现相对CPUx35倍加速），节省内存的sparse optimizer，各种embedding分布策略，NCCL通信</p></li><li><p>sok实现了多种embedding层，部分参数有</p><ul><li>SparseEmbedding： <ul><li>combiner：如何合并slot内的embedding：mean或sum</li><li>[max_vocabulary_size_per_gpu, embedding_vec_size]：embedding变量的大小</li><li>slot_num：slot的总数，也即特征域的数量</li><li>max_nnz：一个slot中key 的最大数量</li><li>max_feature_num：特征的最大数，为slot_num*max_nnz</li><li>use_hashtable：是否使用哈希表存储嵌入向量，若为False，则输入embedding层的key作为索引值查找embedding（key需在[0, max_vocabulary_size_per_gpu * gpu_num)]范围内）</li></ul></li><li>DenseEmbedding： <ul><li>[max_vocabulary_size_per_gpu, embedding_vec_size]：embedding变量的大小</li><li>slot_num：slot的总数，也即特征域的数量</li><li>nnz_per_slot：每个slot中key 的数量，且都相等（nnz：number of non zero非零实例，我的理解：nnz为1，则是one-hot, nnz大于1则是multi-hot）</li><li>dynamic_input：是否输入张量的大小是动态的（非固定值）</li><li>use_hashtable：是否使用哈希表存储嵌入向量，若为False，则输入embedding层的key作为索引值查找embedding</li></ul></li></ul></li><li><p>分布式embedding的相关函数：</p><ul><li>sparse_operation_kit.experiment.lookup.lookup_sparse(<em>params</em>, <em>sp_ids</em>, <em>hotness</em>, <em>combiners</em>)： <ul><li>支持分布式lookup</li><li>支持融合查找，同时查找多个参数</li><li><strong>params</strong>：<em>sok.Variable</em>列表</li><li><strong>sp_ids</strong> (<em>list</em>*,* <em>tuple</em>) – tf.SparseTensor or tf.RaggedTensor的列表</li><li><strong>hotness</strong> (<em>list</em>*,* <em>tuple</em>) – a list or tuple of int to specify the max hotness of each lookup.？？</li><li><strong>combiners</strong> (<em>list</em>*,* <em>tuple</em>) – 每次lookup的合并策略的列表</li></ul></li></ul></li></ul>`,1);function L(B,V){const t=l("font"),o=l("ExternalLinkIcon");return u(),i("div",null,[_,n("ul",null,[n("li",null,[a(t,{color:"orange"},{default:e(()=>[s("**TODO**:")]),_:1}),v]),y,n("li",null,[n("p",null,[s("为什么用hashing （参考："),n("a",f,[s("Deep Hash Embedding"),a(o)]),s("）")]),x]),n("li",null,[T,n("ul",null,[q,n("li",null,[n("a",R,[s("murmurhash function"),a(o)])])])]),C,n("li",null,[w,n("ul",null,[n("li",null,[a(t,{color:"orange"},{default:e(()=>[s("TODO: 输出hash查找后的value和输入前的key做比较，再和embedding vector做比较")]),_:1})])])]),N,H]),I,n("ul",null,[n("li",null,[a(t,{color:"red"},{default:e(()=>[s("怎么存embedding？")]),_:1})]),n("li",null,[n("p",null,[n("strong",null,[a(t,{color:"red"},{default:e(()=>[s("hashtable是如何结合embedding的，embedding kernel是如何实现的（后续结合CNCard上hashtable）")]),_:1})]),s("："),a(t,{color:"green"},{default:e(()=>[s("ps: 可以通过unit test快速了解逻辑实现方式")]),_:1})])]),O,P,D,n("li",null,[z,n("ul",null,[n("li",null,[n("p",null,[n("a",K,[s("美团的实现"),a(o)]),s("是对于ids庞大的sparse特征，将embedding分布式存储到gpus的显存中，使用gpu内hash表"),a(t,{color:"red"},{default:e(()=>[F]),_:1}),s("；")])]),n("li",null,[a(t,{color:"purple"},{default:e(()=>[s("[THINKING]: 因为每一个数据样本的特征域数量不同且非常庞大，所以使用hash来查找对应的embedding table的位置从而查找对应的embedding向量，再送入后续DNN中？？")]),_:1})]),G])])]),E,n("h2",U,[n("a",A,[n("span",null,[a(t,{color:"red"},{default:e(()=>[s("5. SOK")]),_:1})])])]),S])}const j=c(g,[["render",L],["__file","hugectr_src_blog.html.vue"]]),J=JSON.parse(`{"path":"/blogs/hugectr_src_blog.html","title":"HugeCTR源码阅读笔记","lang":"zh-CN","frontmatter":{"date":"2023-10-25T00:00:00.000Z","tag":["CUDA","HugeCTR"],"category":["推荐系统"],"description":"HugeCTR源码阅读笔记 1. Data 深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例： 数值特征（numeric feature、dense feature）： 分类特征...","head":[["meta",{"property":"og:url","content":"https://bradzhone.github.io/blogs/hugectr_src_blog.html"}],["meta",{"property":"og:site_name","content":"BradZhone's Blog"}],["meta",{"property":"og:title","content":"HugeCTR源码阅读笔记"}],["meta",{"property":"og:description","content":"HugeCTR源码阅读笔记 1. Data 深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例： 数值特征（numeric feature、dense feature）： 分类特征..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"BradZhone"}],["meta",{"property":"article:tag","content":"CUDA"}],["meta",{"property":"article:tag","content":"HugeCTR"}],["meta",{"property":"article:published_time","content":"2023-10-25T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"HugeCTR源码阅读笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-10-25T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BradZhone\\",\\"url\\":\\"https://github.com/BradZhone\\"}]}"]]},"headers":[{"level":2,"title":"1. Data","slug":"_1-data","link":"#_1-data","children":[]},{"level":2,"title":"2. Hashing","slug":"_2-hashing","link":"#_2-hashing","children":[]},{"level":2,"title":"3. Embedding","slug":"_3-embedding","link":"#_3-embedding","children":[]},{"level":2,"title":"4. Other","slug":"_4-other","link":"#_4-other","children":[]},{"level":2,"title":"5. SOK","slug":"_5-sok","link":"#_5-sok","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":12.77,"words":3832},"filePathRelative":"blogs/hugectr_src_blog.md","localizedDate":"2023年10月25日","excerpt":"\\n<h2>1. Data</h2>\\n<ul>\\n<li>\\n<p>深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例：</p>\\n</li>\\n<li>\\n<p><strong>数值特征</strong>（numeric feature、dense feature）：</p>\\n<ul>\\n<li>\\n<table>\\n<thead>\\n<tr>\\n<th></th>\\n<th>_col0</th>\\n<th>_col1</th>\\n<th>_col2</th>\\n<th>_col3</th>\\n<th>_col4</th>\\n<th>_col5</th>\\n<th>_col6</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>0</td>\\n<td>0.080380</td>\\n<td>0.435741</td>\\n<td>0.078185</td>\\n<td>0.194161</td>\\n<td>0.087724</td>\\n<td>0.845081</td>\\n<td>0.937019</td>\\n</tr>\\n<tr>\\n<td>1</td>\\n<td>0.310647</td>\\n<td>0.669963</td>\\n<td>0.218886</td>\\n<td>0.945537</td>\\n<td>0.735421</td>\\n<td>0.637027</td>\\n<td>0.007011</td>\\n</tr>\\n<tr>\\n<td>2</td>\\n<td>0.337267</td>\\n<td>0.908792</td>\\n<td>0.795987</td>\\n<td>0.608301</td>\\n<td>0.290421</td>\\n<td>0.012273</td>\\n<td>0.671650</td>\\n</tr>\\n<tr>\\n<td>3</td>\\n<td>0.873908</td>\\n<td>0.694296</td>\\n<td>0.796788</td>\\n<td>0.553089</td>\\n<td>0.872149</td>\\n<td>0.502299</td>\\n<td>0.114150</td>\\n</tr>\\n<tr>\\n<td>4</td>\\n<td>0.333109</td>\\n<td>0.456773</td>\\n<td>0.403027</td>\\n<td>0.091778</td>\\n<td>0.215718</td>\\n<td>0.729457</td>\\n<td>0.941204</td>\\n</tr>\\n</tbody>\\n</table>\\n</li>\\n<li>\\n<table>\\n<thead>\\n<tr>\\n<th></th>\\n<th>_col7</th>\\n<th>_col8</th>\\n<th>_col9</th>\\n<th>_col10</th>\\n<th>_col11</th>\\n<th>_col12</th>\\n<th>_col13</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>0</td>\\n<td>0.977882</td>\\n<td>0.042342</td>\\n<td>0.054632</td>\\n<td>0.855919</td>\\n<td>0.264451</td>\\n<td>0.224891</td>\\n<td>0.467242</td>\\n</tr>\\n<tr>\\n<td>1</td>\\n<td>0.204856</td>\\n<td>0.307856</td>\\n<td>0.775143</td>\\n<td>0.265654</td>\\n<td>0.301945</td>\\n<td>0.066413</td>\\n<td>0.499416</td>\\n</tr>\\n<tr>\\n<td>2</td>\\n<td>0.960113</td>\\n<td>0.018073</td>\\n<td>0.639101</td>\\n<td>0.229013</td>\\n<td>0.645756</td>\\n<td>0.123180</td>\\n<td>0.894010</td>\\n</tr>\\n<tr>\\n<td>3</td>\\n<td>0.444433</td>\\n<td>0.001794</td>\\n<td>0.147979</td>\\n<td>0.083302</td>\\n<td>0.744487</td>\\n<td>0.971924</td>\\n<td>0.362019</td>\\n</tr>\\n<tr>\\n<td>4</td>\\n<td>0.997079</td>\\n<td>0.563684</td>\\n<td>0.811862</td>\\n<td>0.457039</td>\\n<td>0.133213</td>\\n<td>0.169442</td>\\n<td>0.124149</td>\\n</tr>\\n</tbody>\\n</table>\\n</li>\\n</ul>\\n</li>\\n<li>\\n<p><strong>分类特征</strong>（sparse feature、category feature）：</p>\\n<ul>\\n<li>\\n<table>\\n<thead>\\n<tr>\\n<th></th>\\n<th>_col14</th>\\n<th>_col15</th>\\n<th>_col16</th>\\n<th>_col17</th>\\n<th>_col18</th>\\n<th>_col19</th>\\n<th>_col20</th>\\n<th>_col21</th>\\n<th>_col22</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>0</td>\\n<td>151</td>\\n<td>0</td>\\n<td>9</td>\\n<td>13</td>\\n<td>1</td>\\n<td>1</td>\\n<td>1</td>\\n<td>9</td>\\n<td>4</td>\\n</tr>\\n<tr>\\n<td>1</td>\\n<td>0</td>\\n<td>0</td>\\n<td>11</td>\\n<td>4801</td>\\n<td>44</td>\\n<td>2</td>\\n<td>160</td>\\n<td>9</td>\\n<td>0</td>\\n</tr>\\n<tr>\\n<td>2</td>\\n<td>4549</td>\\n<td>3</td>\\n<td>1</td>\\n<td>10</td>\\n<td>31</td>\\n<td>2</td>\\n<td>485</td>\\n<td>2</td>\\n<td>10</td>\\n</tr>\\n<tr>\\n<td>3</td>\\n<td>0</td>\\n<td>0</td>\\n<td>1</td>\\n<td>1</td>\\n<td>1</td>\\n<td>0</td>\\n<td>3</td>\\n<td>111</td>\\n<td>10</td>\\n</tr>\\n<tr>\\n<td>4</td>\\n<td>2</td>\\n<td>5</td>\\n<td>160</td>\\n<td>0</td>\\n<td>72</td>\\n<td>0</td>\\n<td>13</td>\\n<td>53</td>\\n<td>0</td>\\n</tr>\\n</tbody>\\n</table>\\n</li>\\n<li>\\n<table>\\n<thead>\\n<tr>\\n<th></th>\\n<th>_col23</th>\\n<th>_col24</th>\\n<th>_col25</th>\\n<th>_col26</th>\\n<th>_col27</th>\\n<th>_col28</th>\\n<th>_col29</th>\\n<th>_col30</th>\\n<th>_col31</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>0</td>\\n<td>2</td>\\n<td>395</td>\\n<td>41</td>\\n<td>1</td>\\n<td>14</td>\\n<td>5</td>\\n<td>2</td>\\n<td>7</td>\\n<td>0</td>\\n</tr>\\n<tr>\\n<td>1</td>\\n<td>101</td>\\n<td>3</td>\\n<td>1</td>\\n<td>1</td>\\n<td>4</td>\\n<td>1</td>\\n<td>1</td>\\n<td>1</td>\\n<td>1</td>\\n</tr>\\n<tr>\\n<td>2</td>\\n<td>2</td>\\n<td>19</td>\\n<td>6</td>\\n<td>6</td>\\n<td>1</td>\\n<td>0</td>\\n<td>4</td>\\n<td>1</td>\\n<td>2</td>\\n</tr>\\n<tr>\\n<td>3</td>\\n<td>1</td>\\n<td>2</td>\\n<td>38</td>\\n<td>6</td>\\n<td>1</td>\\n<td>7</td>\\n<td>1</td>\\n<td>2</td>\\n<td>0</td>\\n</tr>\\n<tr>\\n<td>4</td>\\n<td>63</td>\\n<td>616</td>\\n<td>7</td>\\n<td>1</td>\\n<td>175</td>\\n<td>23</td>\\n<td>4</td>\\n<td>0</td>\\n<td>1</td>\\n</tr>\\n</tbody>\\n</table>\\n</li>\\n<li>\\n<table>\\n<thead>\\n<tr>\\n<th></th>\\n<th>_col32</th>\\n<th>_col33</th>\\n<th>_col34</th>\\n<th>_col35</th>\\n<th>_col36</th>\\n<th>_col37</th>\\n<th>_col38</th>\\n<th>_col39</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>0</td>\\n<td>1</td>\\n<td>1</td>\\n<td>5283</td>\\n<td>4</td>\\n<td>0</td>\\n<td>21</td>\\n<td>33</td>\\n<td>1</td>\\n</tr>\\n<tr>\\n<td>1</td>\\n<td>2</td>\\n<td>3</td>\\n<td>204</td>\\n<td>310</td>\\n<td>1640</td>\\n<td>6</td>\\n<td>4</td>\\n<td>6</td>\\n</tr>\\n<tr>\\n<td>2</td>\\n<td>4</td>\\n<td>7</td>\\n<td>29</td>\\n<td>2</td>\\n<td>11</td>\\n<td>66</td>\\n<td>2</td>\\n<td>22</td>\\n</tr>\\n<tr>\\n<td>3</td>\\n<td>9</td>\\n<td>43</td>\\n<td>2</td>\\n<td>10</td>\\n<td>286</td>\\n<td>6</td>\\n<td>2</td>\\n<td>0</td>\\n</tr>\\n<tr>\\n<td>4</td>\\n<td>0</td>\\n<td>477</td>\\n<td>10</td>\\n<td>6</td>\\n<td>0</td>\\n<td>2</td>\\n<td>0</td>\\n<td>30</td>\\n</tr>\\n</tbody>\\n</table>\\n</li>\\n</ul>\\n</li>\\n<li>\\n<p>数据相关属性：</p>\\n<ul>\\n<li>\\n<p>以生成模拟数据为例：</p>\\n<ul>\\n<li>\\n<div class=\\"language-python\\" data-ext=\\"py\\" data-title=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token comment\\"># generate_data.py</span>\\n\\n<span class=\\"token keyword\\">import</span> hugectr\\n<span class=\\"token keyword\\">from</span> hugectr<span class=\\"token punctuation\\">.</span>tools <span class=\\"token keyword\\">import</span> DataGenerator<span class=\\"token punctuation\\">,</span> DataGeneratorParams\\n<span class=\\"token keyword\\">from</span> mpi4py <span class=\\"token keyword\\">import</span> MPI\\n<span class=\\"token keyword\\">import</span> argparse\\nparser <span class=\\"token operator\\">=</span> argparse<span class=\\"token punctuation\\">.</span>ArgumentParser<span class=\\"token punctuation\\">(</span>description<span class=\\"token operator\\">=</span><span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"Data Generation\\"</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n\\nparser<span class=\\"token punctuation\\">.</span>add_argument<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"--num_files\\"</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">type</span><span class=\\"token operator\\">=</span><span class=\\"token builtin\\">int</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">help</span><span class=\\"token operator\\">=</span><span class=\\"token string\\">\\"number of files in training data\\"</span><span class=\\"token punctuation\\">,</span> default <span class=\\"token operator\\">=</span> <span class=\\"token number\\">8</span><span class=\\"token punctuation\\">)</span>\\nparser<span class=\\"token punctuation\\">.</span>add_argument<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"--eval_num_files\\"</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">type</span><span class=\\"token operator\\">=</span><span class=\\"token builtin\\">int</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">help</span><span class=\\"token operator\\">=</span><span class=\\"token string\\">\\"number of files in validation data\\"</span><span class=\\"token punctuation\\">,</span> default <span class=\\"token operator\\">=</span> <span class=\\"token number\\">2</span><span class=\\"token punctuation\\">)</span>\\nparser<span class=\\"token punctuation\\">.</span>add_argument<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'--num_samples_per_file'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">type</span><span class=\\"token operator\\">=</span><span class=\\"token builtin\\">int</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">help</span><span class=\\"token operator\\">=</span><span class=\\"token string\\">\\"number of samples per file\\"</span><span class=\\"token punctuation\\">,</span> default<span class=\\"token operator\\">=</span><span class=\\"token number\\">1000000</span><span class=\\"token punctuation\\">)</span>\\nparser<span class=\\"token punctuation\\">.</span>add_argument<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'--dir_name'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">type</span><span class=\\"token operator\\">=</span><span class=\\"token builtin\\">str</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">help</span><span class=\\"token operator\\">=</span><span class=\\"token string\\">\\"data directory name(Required)\\"</span><span class=\\"token punctuation\\">)</span>\\nargs <span class=\\"token operator\\">=</span> parser<span class=\\"token punctuation\\">.</span>parse_args<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n\\ndata_generator_params <span class=\\"token operator\\">=</span> DataGeneratorParams<span class=\\"token punctuation\\">(</span>\\n  <span class=\\"token builtin\\">format</span> <span class=\\"token operator\\">=</span> hugectr<span class=\\"token punctuation\\">.</span>DataReaderType_t<span class=\\"token punctuation\\">.</span>Parquet<span class=\\"token punctuation\\">,</span>\\n  label_dim <span class=\\"token operator\\">=</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span>\\n  dense_dim <span class=\\"token operator\\">=</span> <span class=\\"token number\\">13</span><span class=\\"token punctuation\\">,</span>\\n  num_slot <span class=\\"token operator\\">=</span> <span class=\\"token number\\">26</span><span class=\\"token punctuation\\">,</span>\\n  num_files <span class=\\"token operator\\">=</span> args<span class=\\"token punctuation\\">.</span>num_files<span class=\\"token punctuation\\">,</span>\\n  eval_num_files <span class=\\"token operator\\">=</span> args<span class=\\"token punctuation\\">.</span>eval_num_files<span class=\\"token punctuation\\">,</span>\\n  i64_input_key <span class=\\"token operator\\">=</span> <span class=\\"token boolean\\">True</span><span class=\\"token punctuation\\">,</span>\\n  num_samples_per_file <span class=\\"token operator\\">=</span> args<span class=\\"token punctuation\\">.</span>num_samples_per_file<span class=\\"token punctuation\\">,</span>\\n  source <span class=\\"token operator\\">=</span> <span class=\\"token string\\">\\"./etc_data/\\"</span> <span class=\\"token operator\\">+</span> args<span class=\\"token punctuation\\">.</span>dir_name <span class=\\"token operator\\">+</span> <span class=\\"token string\\">\\"/file_list.txt\\"</span><span class=\\"token punctuation\\">,</span>\\n  eval_source <span class=\\"token operator\\">=</span> <span class=\\"token string\\">\\"./etc_data/\\"</span> <span class=\\"token operator\\">+</span> args<span class=\\"token punctuation\\">.</span>dir_name <span class=\\"token operator\\">+</span> <span class=\\"token string\\">\\"/file_list_test.txt\\"</span><span class=\\"token punctuation\\">,</span>\\n  slot_size_array <span class=\\"token operator\\">=</span> <span class=\\"token punctuation\\">[</span><span class=\\"token number\\">12988</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">7129</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">8720</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">5820</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">15196</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">4</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">4914</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1020</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">30</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">14274</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">10220</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">15088</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">10</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1518</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">3672</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">48</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">4</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">820</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">15</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">12817</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">13908</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">13447</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">9447</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">5867</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">45</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">33</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span>\\n  nnz_array <span class=\\"token operator\\">=</span> <span class=\\"token punctuation\\">[</span><span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span>\\n  <span class=\\"token comment\\"># for parquet, check_type doesn't make any difference</span>\\n  check_type <span class=\\"token operator\\">=</span> hugectr<span class=\\"token punctuation\\">.</span>Check_t<span class=\\"token punctuation\\">.</span>Non<span class=\\"token punctuation\\">,</span>\\n  dist_type <span class=\\"token operator\\">=</span> hugectr<span class=\\"token punctuation\\">.</span>Distribution_t<span class=\\"token punctuation\\">.</span>PowerLaw<span class=\\"token punctuation\\">,</span>\\n  power_law_type <span class=\\"token operator\\">=</span> hugectr<span class=\\"token punctuation\\">.</span>PowerLaw_t<span class=\\"token punctuation\\">.</span>Short<span class=\\"token punctuation\\">)</span>\\ndata_generator <span class=\\"token operator\\">=</span> DataGenerator<span class=\\"token punctuation\\">(</span>data_generator_params<span class=\\"token punctuation\\">)</span>\\ndata_generator<span class=\\"token punctuation\\">.</span>generate<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n</code></pre></div></li>\\n<li>\\n<p>num_files：即数据集分为几个子集，也是使用ETC训练时每一个pass所用到的数据，子集数等于训练所需pass数</p>\\n</li>\\n<li>\\n<p>num_samples_per_file：也即每个子数据集的样本数</p>\\n</li>\\n<li>\\n<p>label_dim：每一个sample的标签维度</p>\\n</li>\\n<li>\\n<p>dense_dim：连续特征的数量</p>\\n</li>\\n<li>\\n<p>num_slot：分类特征的数量，也即slot数（特征域数量）</p>\\n</li>\\n<li>\\n<p>slot_size_array：每一个slot中的最大特征数量（也就是特征域的大小）</p>\\n</li>\\n<li>\\n<p>nnz_array： 样本在对应的slot (特征域)中最多可同时有几个特征（用于选择是one-hot还是multi-hot）</p>\\n</li>\\n</ul>\\n</li>\\n<li>\\n<p>执行脚本生成模拟数据（总共产生8个训练数据子集和2个测试子集）：</p>\\n<ul>\\n<li>\\n<div class=\\"language-python\\" data-ext=\\"py\\" data-title=\\"py\\"><pre class=\\"language-python\\"><code>python generate_data<span class=\\"token punctuation\\">.</span>py <span class=\\"token operator\\">-</span><span class=\\"token operator\\">-</span>dir_name <span class=\\"token string\\">\\"file0\\"</span>\\n</code></pre></div><div class=\\"language-bash\\" data-ext=\\"sh\\" data-title=\\"sh\\"><pre class=\\"language-bash\\"><code><span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:28.823<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: Generate Parquet dataset\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:28.823<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: train data folder: ./etc_data/file0, <span class=\\"token builtin class-name\\">eval</span> data folder: ./etc_data/file0, slot_size_array: <span class=\\"token number\\">12988</span>, <span class=\\"token number\\">7129</span>, <span class=\\"token number\\">8720</span>, <span class=\\"token number\\">5820</span>, <span class=\\"token number\\">15196</span>, <span class=\\"token number\\">4</span>, <span class=\\"token number\\">4914</span>, <span class=\\"token number\\">1020</span>, <span class=\\"token number\\">30</span>, <span class=\\"token number\\">14274</span>, <span class=\\"token number\\">10220</span>, <span class=\\"token number\\">15088</span>, <span class=\\"token number\\">10</span>, <span class=\\"token number\\">1518</span>, <span class=\\"token number\\">3672</span>, <span class=\\"token number\\">48</span>, <span class=\\"token number\\">4</span>, <span class=\\"token number\\">820</span>, <span class=\\"token number\\">15</span>, <span class=\\"token number\\">12817</span>, <span class=\\"token number\\">13908</span>, <span class=\\"token number\\">13447</span>, <span class=\\"token number\\">9447</span>, <span class=\\"token number\\">5867</span>, <span class=\\"token number\\">45</span>, <span class=\\"token number\\">33</span>, nnz array: <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token number\\">1</span>, <span class=\\"token comment\\">#files for train: 8, #files for eval: 2, #samples per file: 1000000, Use power law distribution: 1, alpha of power law: 1.3</span>\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:28.823<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0 exist\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:28.823<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_0.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:33.757<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_1.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:36.560<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_2.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:39.337<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_3.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:42.083<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_4.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:44.807<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_5.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:47.641<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_6.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:50.377<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/train/gen_7.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:53.131<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/file_list.txt done<span class=\\"token operator\\">!</span>\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:53.132<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/val/gen_0.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:55.941<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/val/gen_1.parquet\\n<span class=\\"token punctuation\\">[</span>HCTR<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>03:28:58.788<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>INFO<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>RK0<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">[</span>main<span class=\\"token punctuation\\">]</span>: ./etc_data/file0/file_list_test.txt done<span class=\\"token operator\\">!</span>\\n</code></pre></div></li>\\n<li>\\n<p>输出keysets（以gen_0为例）：</p>\\n<ul>\\n<li>\\n<p>每一个子数据集（每个pass用的数据集）会生成一个keysets，所有数据的keysets构成一个更大的集合all_keysets，最终将根据all_keysets生成keysets文件xxx.keyset供GPU在t时刻预读取t+1时刻的数据到ETC中</p>\\n</li>\\n<li>\\n<div class=\\"language-bash\\" data-ext=\\"sh\\" data-title=\\"sh\\"><pre class=\\"language-bash\\"><code>  ------------------------\\n  unique_keys:\\n  <span class=\\"token number\\">0</span>            <span class=\\"token number\\">0</span>\\n  <span class=\\"token number\\">1</span>            <span class=\\"token number\\">1</span>\\n  <span class=\\"token number\\">2</span>            <span class=\\"token number\\">2</span>\\n  <span class=\\"token number\\">3</span>            <span class=\\"token number\\">3</span>\\n  <span class=\\"token number\\">4</span>            <span class=\\"token number\\">4</span>\\n          <span class=\\"token punctuation\\">..</span>.  \\n  <span class=\\"token number\\">12115</span>    <span class=\\"token number\\">12978</span>\\n  <span class=\\"token number\\">12116</span>    <span class=\\"token number\\">12979</span>\\n  <span class=\\"token number\\">12117</span>    <span class=\\"token number\\">12981</span>\\n  <span class=\\"token number\\">12118</span>    <span class=\\"token number\\">12983</span>\\n  <span class=\\"token number\\">12119</span>    <span class=\\"token number\\">12986</span>\\n  Name: _col14, Length: <span class=\\"token number\\">12120</span>, dtype: int64\\n  ------------------------\\n  unique_keys:\\n  <span class=\\"token number\\">0</span>       <span class=\\"token number\\">12988</span>\\n  <span class=\\"token number\\">1</span>       <span class=\\"token number\\">12989</span>\\n  <span class=\\"token number\\">2</span>       <span class=\\"token number\\">12990</span>\\n  <span class=\\"token number\\">3</span>       <span class=\\"token number\\">12991</span>\\n  <span class=\\"token number\\">4</span>       <span class=\\"token number\\">12992</span>\\n          <span class=\\"token punctuation\\">..</span>.  \\n  <span class=\\"token number\\">7077</span>    <span class=\\"token number\\">20111</span>\\n  <span class=\\"token number\\">7078</span>    <span class=\\"token number\\">20112</span>\\n  <span class=\\"token number\\">7079</span>    <span class=\\"token number\\">20113</span>\\n  <span class=\\"token number\\">7080</span>    <span class=\\"token number\\">20114</span>\\n  <span class=\\"token number\\">7081</span>    <span class=\\"token number\\">20116</span>\\n  Name: _col15, Length: <span class=\\"token number\\">7082</span>, dtype: int64\\n  ------------------------\\n  unique_keys:\\n  <span class=\\"token number\\">0</span>       <span class=\\"token number\\">20117</span>\\n  <span class=\\"token number\\">1</span>       <span class=\\"token number\\">20118</span>\\n  <span class=\\"token number\\">2</span>       <span class=\\"token number\\">20119</span>\\n  <span class=\\"token number\\">3</span>       <span class=\\"token number\\">20120</span>\\n  <span class=\\"token number\\">4</span>       <span class=\\"token number\\">20121</span>\\n          <span class=\\"token punctuation\\">..</span>.  \\n  <span class=\\"token number\\">8554</span>    <span class=\\"token number\\">28827</span>\\n  <span class=\\"token number\\">8555</span>    <span class=\\"token number\\">28828</span>\\n  <span class=\\"token number\\">8556</span>    <span class=\\"token number\\">28830</span>\\n  <span class=\\"token number\\">8557</span>    <span class=\\"token number\\">28831</span>\\n  <span class=\\"token number\\">8558</span>    <span class=\\"token number\\">28834</span>\\n  Name: _col16, Length: <span class=\\"token number\\">8559</span>, dtype: int64\\n  ------------------------\\n  unique_keys:\\n  <span class=\\"token number\\">0</span>       <span class=\\"token number\\">28837</span>\\n  <span class=\\"token number\\">1</span>       <span class=\\"token number\\">28838</span>\\n  <span class=\\"token number\\">2</span>       <span class=\\"token number\\">28839</span>\\n  <span class=\\"token number\\">3</span>       <span class=\\"token number\\">28840</span>\\n  <span class=\\"token number\\">4</span>       <span class=\\"token number\\">28841</span>\\n          <span class=\\"token punctuation\\">..</span>.  \\n  <span class=\\"token number\\">5798</span>    <span class=\\"token number\\">34652</span>\\n  <span class=\\"token number\\">5799</span>    <span class=\\"token number\\">34653</span>\\n  <span class=\\"token number\\">5800</span>    <span class=\\"token number\\">34654</span>\\n  <span class=\\"token number\\">5801</span>    <span class=\\"token number\\">34655</span>\\n  <span class=\\"token number\\">5802</span>    <span class=\\"token number\\">34656</span>\\n  Name: _col17, Length: <span class=\\"token number\\">5803</span>, dtype: int64\\n</code></pre></div></li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n<li>\\n<p>使用ETC分pass训练示例(与上例不同，此例使用10个pass来训练)：</p>\\n<ul>\\n<li>\\n<table>\\n<thead>\\n<tr>\\n<th style=\\"text-align:right\\">Pass ID</th>\\n<th style=\\"text-align:right\\">Number of Unique Keys</th>\\n<th style=\\"text-align:right\\">Embedding size (GB)</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td style=\\"text-align:right\\">#0</td>\\n<td style=\\"text-align:right\\">24199179</td>\\n<td style=\\"text-align:right\\">11.54</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#1</td>\\n<td style=\\"text-align:right\\">26015075</td>\\n<td style=\\"text-align:right\\">12.40</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#2</td>\\n<td style=\\"text-align:right\\">27387817</td>\\n<td style=\\"text-align:right\\">13.06</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#3</td>\\n<td style=\\"text-align:right\\">23672542</td>\\n<td style=\\"text-align:right\\">11.29</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#4</td>\\n<td style=\\"text-align:right\\">26053910</td>\\n<td style=\\"text-align:right\\">12.42</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#5</td>\\n<td style=\\"text-align:right\\">27697628</td>\\n<td style=\\"text-align:right\\">13.21</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#6</td>\\n<td style=\\"text-align:right\\">24727672</td>\\n<td style=\\"text-align:right\\">11.79</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#7</td>\\n<td style=\\"text-align:right\\">25643779</td>\\n<td style=\\"text-align:right\\">12.23</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#8</td>\\n<td style=\\"text-align:right\\">26374086</td>\\n<td style=\\"text-align:right\\">12.58</td>\\n</tr>\\n<tr>\\n<td style=\\"text-align:right\\">#9</td>\\n<td style=\\"text-align:right\\">26580983</td>\\n<td style=\\"text-align:right\\">12.67</td>\\n</tr>\\n</tbody>\\n</table>\\n</li>\\n</ul>\\n</li>\\n<li>\\n<p>数据预处理时，HugeCTR将分类特征转换为整型序列的方法：</p>\\n<ul>\\n<li>\\n<p>使用NVTabular：</p>\\n</li>\\n<li>\\n<div class=\\"language-python\\" data-ext=\\"py\\" data-title=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token comment\\"># e.g. using NVTabular</span>\\n\\ntarget_encode <span class=\\"token operator\\">=</span> <span class=\\"token punctuation\\">(</span>\\n    <span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'brand'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'user_id'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'product_id'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'cat_2'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'ts_weekday'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'ts_day'</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">]</span> <span class=\\"token operator\\">&gt;&gt;</span>\\n    nvt<span class=\\"token punctuation\\">.</span>ops<span class=\\"token punctuation\\">.</span>TargetEncoding<span class=\\"token punctuation\\">(</span>\\n        nvt<span class=\\"token punctuation\\">.</span>ColumnGroup<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'target'</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">,</span>\\n        kfold<span class=\\"token operator\\">=</span><span class=\\"token number\\">5</span><span class=\\"token punctuation\\">,</span>\\n        p_smooth<span class=\\"token operator\\">=</span><span class=\\"token number\\">20</span><span class=\\"token punctuation\\">,</span>\\n        out_dtype<span class=\\"token operator\\">=</span><span class=\\"token string\\">\\"float32\\"</span><span class=\\"token punctuation\\">,</span>\\n        <span class=\\"token punctuation\\">)</span>\\n</code></pre></div></li>\\n<li>\\n<blockquote>\\n<p>https://nvidia-merlin.github.io/NVTabular/v0.7.1/api/ops/targetencoding.html</p>\\n<p>Target encoding is a common feature-engineering technique for categorical columns in tabular datasets. For each categorical group, the mean of a continuous target column is calculated, and the group-specific mean of each row is used to create a new feature (column). To prevent overfitting, the following additional logic is applied:</p>\\n<blockquote>\\n<ol>\\n<li>\\n<p>Cross Validation: To prevent overfitting in training data, a cross-validation strategy is used - The data is split into k random “folds”, and the mean values within the i-th fold are calculated with data from all other folds. The cross-validation strategy is only employed when the dataset is used to update recorded statistics. For transformation-only workflow execution, global-mean statistics are used instead.</p>\\n</li>\\n<li>\\n<p>Smoothing: To prevent overfitting for low cardinality categories, the means are smoothed with the overall mean of the target variable.</p>\\n</li>\\n</ol>\\n</blockquote>\\n</blockquote>\\n</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}`);export{j as comp,J as data};
