<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.9" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.32" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://bradzhone.github.io/tag/cuda/"><meta property="og:site_name" content="BradZhone's Blog"><meta property="og:title" content="标签: CUDA"><meta property="og:type" content="website"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="BradZhone"><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebPage","name":"标签: CUDA"}</script><title>标签: CUDA | BradZhone's Blog</title><meta name="description" content="">
    <link rel="preload" href="/assets/style-BkjCpNEe.css" as="style"><link rel="stylesheet" href="/assets/style-BkjCpNEe.css">
    <link rel="modulepreload" href="/assets/app-Coh1oo3x.js"><link rel="modulepreload" href="/assets/index.html-D57wSldI.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/intro.html-D9dwEpHI.js" as="script"><link rel="prefetch" href="/assets/index.html-D5LnkeFh.js" as="script"><link rel="prefetch" href="/assets/CRNN_blog.html-Cb6b7OD4.js" as="script"><link rel="prefetch" href="/assets/cucollection_blog.html-DLix_uWp.js" as="script"><link rel="prefetch" href="/assets/cuda_blog.html-CBZ1Rex-.js" as="script"><link rel="prefetch" href="/assets/distributed_embeddings_blog.html-Cw7oBr-d.js" as="script"><link rel="prefetch" href="/assets/howToBuildThisBlog.html-Dxn0xRj3.js" as="script"><link rel="prefetch" href="/assets/hugectr_blog.html-BrFINEES.js" as="script"><link rel="prefetch" href="/assets/hugectr_src_blog.html-d9qgPAFk.js" as="script"><link rel="prefetch" href="/assets/index.html-DI16Z1C4.js" as="script"><link rel="prefetch" href="/assets/torchrec_cn_embedding_note.html-YEVLbIAq.js" as="script"><link rel="prefetch" href="/assets/warpcore_blog.html-Cz_5IJvA.js" as="script"><link rel="prefetch" href="/assets/c___note.html-BYbhq9Nq.js" as="script"><link rel="prefetch" href="/assets/deep_learning.html-b-b3zdJE.js" as="script"><link rel="prefetch" href="/assets/linux_command.html-G4dNyKFL.js" as="script"><link rel="prefetch" href="/assets/LLM.html-9hu1pKVY.js" as="script"><link rel="prefetch" href="/assets/loss.html-CJxfnubw.js" as="script"><link rel="prefetch" href="/assets/markdown.html-DJcQDvEC.js" as="script"><link rel="prefetch" href="/assets/metrics.html-DKJGeFbq.js" as="script"><link rel="prefetch" href="/assets/PLAN_Z.html-B9yJBwFA.js" as="script"><link rel="prefetch" href="/assets/precision.html-B_dd_MdY.js" as="script"><link rel="prefetch" href="/assets/index.html-D1wTsZoY.js" as="script"><link rel="prefetch" href="/assets/torchrec_note.html-B-i_O6mg.js" as="script"><link rel="prefetch" href="/assets/uml_note.html-IaIR5y-b.js" as="script"><link rel="prefetch" href="/assets/index.html-Cgwhpoct.js" as="script"><link rel="prefetch" href="/assets/404.html-DYVdKbdY.js" as="script"><link rel="prefetch" href="/assets/index.html-1jQ9-Uww.js" as="script"><link rel="prefetch" href="/assets/index.html-BEDqx9YQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BltlhrdK.js" as="script"><link rel="prefetch" href="/assets/index.html-C0yITs6x.js" as="script"><link rel="prefetch" href="/assets/index.html-maJbTduo.js" as="script"><link rel="prefetch" href="/assets/index.html-BPQ9UPx_.js" as="script"><link rel="prefetch" href="/assets/index.html-BQB6pLKG.js" as="script"><link rel="prefetch" href="/assets/index.html-Be8HnZrW.js" as="script"><link rel="prefetch" href="/assets/index.html-DzX6xTUq.js" as="script"><link rel="prefetch" href="/assets/index.html-BxZ6QV-X.js" as="script"><link rel="prefetch" href="/assets/index.html-Dl0UMf-I.js" as="script"><link rel="prefetch" href="/assets/index.html-xBRd_OsE.js" as="script"><link rel="prefetch" href="/assets/index.html-BTkUZ9Ws.js" as="script"><link rel="prefetch" href="/assets/index.html-Dqr1foaP.js" as="script"><link rel="prefetch" href="/assets/index.html-CSGzSmAq.js" as="script"><link rel="prefetch" href="/assets/index.html-BnBAmG4V.js" as="script"><link rel="prefetch" href="/assets/index.html-d2G8e39M.js" as="script"><link rel="prefetch" href="/assets/index.html-CpCodvQl.js" as="script"><link rel="prefetch" href="/assets/index.html-hEB5WJuD.js" as="script"><link rel="prefetch" href="/assets/index.html-DX2Ijbyk.js" as="script"><link rel="prefetch" href="/assets/index.html-Da6Vp1bl.js" as="script"><link rel="prefetch" href="/assets/index.html-CGr0tdaC.js" as="script"><link rel="prefetch" href="/assets/index.html-D5fEOhj5.js" as="script"><link rel="prefetch" href="/assets/index.html-C1vK6J6C.js" as="script"><link rel="prefetch" href="/assets/index.html-DgD_mq8U.js" as="script"><link rel="prefetch" href="/assets/index.html-Demc7CPi.js" as="script"><link rel="prefetch" href="/assets/index.html-D31kcDwM.js" as="script"><link rel="prefetch" href="/assets/index.html-COTqqkDG.js" as="script"><link rel="prefetch" href="/assets/index.html-DtZDr4LJ.js" as="script"><link rel="prefetch" href="/assets/index.html-BYDcpP-H.js" as="script"><link rel="prefetch" href="/assets/index.html-QpKn8zOy.js" as="script"><link rel="prefetch" href="/assets/index.html-Fd1nQRc_.js" as="script"><link rel="prefetch" href="/assets/index.html-BEVLRn0k.js" as="script"><link rel="prefetch" href="/assets/giscus-7BMGhbDA.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo light" src="/light.png" alt><img class="vp-nav-logo dark" src="/dark.png" alt><span class="vp-site-name hide-in-pad">BradZhone&#39;s Blog</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/" aria-label="Home"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/blogs/" aria-label="Blogs"><span class="font-icon icon fa-fw fa-sm fas fa-blog" style=""></span>Blogs<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/notes/" aria-label="Notes"><span class="font-icon icon fa-fw fa-sm fas fa-note-sticky" style=""></span>Notes<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/thinking/" aria-label="Thinking"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Thinking<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/intro.html" aria-label="About Me"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>About Me<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><!----><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-blog" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/blogs/" aria-label="Blogs"><!---->Blogs<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/howToBuildThisBlog.html" aria-label="如何搭建本博客"><!---->如何搭建本博客<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/CRNN_blog.html" aria-label="CRNN网络调研适配记录"><!---->CRNN网络调研适配记录<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/cucollection_blog.html" aria-label="cuCollections性能测试"><!---->cuCollections性能测试<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/cuda_blog.html" aria-label="CUDA学习笔记"><!---->CUDA学习笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/distributed_embeddings_blog.html" aria-label="Distributed_embeddings"><!---->Distributed_embeddings<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/hugectr_blog.html" aria-label="HugeCTR 学习笔记"><!---->HugeCTR 学习笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/hugectr_src_blog.html" aria-label="HugeCTR源码阅读笔记"><!---->HugeCTR源码阅读笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/torchrec_cn_embedding_note.html" aria-label="torchrec cn_embedding模块设计方案"><!---->torchrec cn_embedding模块设计方案<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/warpcore_blog.html" aria-label="WARPCORE 学习笔记"><!---->WARPCORE 学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-note-sticky" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/notes/" aria-label="Notes"><!---->Notes<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/c___note.html" aria-label="C++ note"><!---->C++ note<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/deep_learning.html" aria-label="DL相关"><!---->DL相关<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/precision.html" aria-label="Floating Point precision formats"><!---->Floating Point precision formats<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/linux_command.html" aria-label="Linux 快捷指令"><!---->Linux 快捷指令<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/LLM.html" aria-label="LLM"><!---->LLM<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/loss.html" aria-label="Loss 相关问题"><!---->Loss 相关问题<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/markdown.html" aria-label="Markdown 语法"><!---->Markdown 语法<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/metrics.html" aria-label="Metrics"><!---->Metrics<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/PLAN_Z.html" aria-label="TODO LIST"><!---->TODO LIST<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/torchrec_note.html" aria-label="Torchrec调研"><!---->Torchrec调研<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/uml_note.html" aria-label="UML学习笔记"><!---->UML学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/thinking/" aria-label="Thinking"><!---->Thinking<!----></a><!----></p><ul class="vp-sidebar-links"></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><div class="vp-page vp-blog"><div class="blog-page-wrapper"><main id="main-content" class="vp-blog-main"><ul class="tag-list-wrapper"><li class="tag tag4 active"><a class="route-link" href="/tag/cuda/">CUDA<span class="tag-num">6</span></a></li><li class="tag tag6"><a class="route-link" href="/tag/hash/">Hash<span class="tag-num">2</span></a></li><li class="tag tag4"><a class="route-link" href="/tag/embedding/">Embedding<span class="tag-num">2</span></a></li><li class="tag tag8"><a class="route-link" href="/tag/hugectr/">HugeCTR<span class="tag-num">2</span></a></li><li class="tag tag5"><a class="route-link" href="/tag/crnn/">CRNN<span class="tag-num">1</span></a></li><li class="tag tag8"><a class="route-link" href="/tag/tensorflow/">Tensorflow<span class="tag-num">1</span></a></li><li class="tag tag5"><a class="route-link" href="/tag/vuepress/">Vuepress<span class="tag-num">1</span></a></li><li class="tag tag0"><a class="route-link" href="/tag/cncard/">CNCard<span class="tag-num">1</span></a></li><li class="tag tag8"><a class="route-link" href="/tag/c++/">C++<span class="tag-num">1</span></a></li><li class="tag tag4"><a class="route-link" href="/tag/deeplearning/">DeepLearning<span class="tag-num">1</span></a></li><li class="tag tag0"><a class="route-link" href="/tag/linux/">Linux<span class="tag-num">1</span></a></li><li class="tag tag6"><a class="route-link" href="/tag/llm/">LLM<span class="tag-num">1</span></a></li><li class="tag tag3"><a class="route-link" href="/tag/loss/">Loss<span class="tag-num">1</span></a></li><li class="tag tag1"><a class="route-link" href="/tag/markdown/">Markdown<span class="tag-num">1</span></a></li><li class="tag tag3"><a class="route-link" href="/tag/metics/">Metics<span class="tag-num">1</span></a></li><li class="tag tag5"><a class="route-link" href="/tag/todo/">TODO<span class="tag-num">1</span></a></li><li class="tag tag3"><a class="route-link" href="/tag/precision/">precision<span class="tag-num">1</span></a></li><li class="tag tag1"><a class="route-link" href="/tag/torchrec/">Torchrec<span class="tag-num">1</span></a></li><li class="tag tag2"><a class="route-link" href="/tag/uml/">UML<span class="tag-num">1</span></a></li></ul><div id="article-list" class="vp-article-list" role="feed"><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/blogs/cuda_blog.html"><header class="vp-article-title"><!----><!----><span property="headline">CUDA学习笔记</span></header></a><div class="vp-article-excerpt">
<h2>0 目标</h2>
<ul>
<li>快速掌握<code>CUDA</code>编程的大致方式</li>
<li>了解<code>CUDA</code>软硬件组织架构与关系</li>
<li>了解如何查找文档</li>
</ul>
<h2>1 介绍</h2>
<h3>1.1 架构</h3>
<ul>
<li>
<p><strong>CUDA (Compute Unified Device Architecture)</strong>：统一计算设备架构，在 GPU 上发布的一个新的硬件和软件架构,它不需要映射到一个图形 API 便可在 GPU 上管理和进行并行数据计算</p>
</li>
<li>
<p><strong>CPU、GPU架构对比</strong>：GPU 被设计用于高密度和并行计算,更确切地说是用于图形渲染，因此更多的晶体管被投入到数据处理而不是数据缓存和流量控制</p>
</li>
<li>
<p><strong>CUDA软件堆栈</strong>：CUDA 软件堆栈由几层组成:一个硬件驱动程序,一个应用程序编程接口(API)和它的Runtime, 还有二个高级的通用数学库,CUFFT 和CUBLAS</p>
</li>
<li>
<p><strong>CUDA内存操作</strong>：CUDA 提供一般 DRAM 内存寻址方式: Gather 和 Scatter内存操作，它可以在 DRAM的任何区域进行读写数据的操作</p>
</li>
<li>
<p>允许并行数据缓冲或者在 On-chip 内存共享使数据更接近ALU，可以进行快速的常规读写存取,在线程之间共享数据。应用程序可以最小化数据到 DRAM 的 overfetch 和 round-trips, 从而减少对 DRAM 内存带宽的依赖</p>
</li>
</ul></div><hr class="vp-article-hr"><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-11-24T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 5 分钟</span><meta property="timeRequired" content="PT5M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category1 clickable" role="navigation">硬件</span><!--]--><meta property="articleSection" content="硬件"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><!--]--><meta property="keywords" content="CUDA"></span></div></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/blogs/hugectr_src_blog.html"><header class="vp-article-title"><!----><!----><span property="headline">HugeCTR源码阅读笔记</span></header></a><div class="vp-article-excerpt">
<h2>1. Data</h2>
<ul>
<li>
<p>深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例：</p>
</li>
<li>
<p><strong>数值特征</strong>（numeric feature、dense feature）：</p>
<ul>
<li>
<table>
<thead>
<tr>
<th></th>
<th>_col0</th>
<th>_col1</th>
<th>_col2</th>
<th>_col3</th>
<th>_col4</th>
<th>_col5</th>
<th>_col6</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0.080380</td>
<td>0.435741</td>
<td>0.078185</td>
<td>0.194161</td>
<td>0.087724</td>
<td>0.845081</td>
<td>0.937019</td>
</tr>
<tr>
<td>1</td>
<td>0.310647</td>
<td>0.669963</td>
<td>0.218886</td>
<td>0.945537</td>
<td>0.735421</td>
<td>0.637027</td>
<td>0.007011</td>
</tr>
<tr>
<td>2</td>
<td>0.337267</td>
<td>0.908792</td>
<td>0.795987</td>
<td>0.608301</td>
<td>0.290421</td>
<td>0.012273</td>
<td>0.671650</td>
</tr>
<tr>
<td>3</td>
<td>0.873908</td>
<td>0.694296</td>
<td>0.796788</td>
<td>0.553089</td>
<td>0.872149</td>
<td>0.502299</td>
<td>0.114150</td>
</tr>
<tr>
<td>4</td>
<td>0.333109</td>
<td>0.456773</td>
<td>0.403027</td>
<td>0.091778</td>
<td>0.215718</td>
<td>0.729457</td>
<td>0.941204</td>
</tr>
</tbody>
</table>
</li>
<li>
<table>
<thead>
<tr>
<th></th>
<th>_col7</th>
<th>_col8</th>
<th>_col9</th>
<th>_col10</th>
<th>_col11</th>
<th>_col12</th>
<th>_col13</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0.977882</td>
<td>0.042342</td>
<td>0.054632</td>
<td>0.855919</td>
<td>0.264451</td>
<td>0.224891</td>
<td>0.467242</td>
</tr>
<tr>
<td>1</td>
<td>0.204856</td>
<td>0.307856</td>
<td>0.775143</td>
<td>0.265654</td>
<td>0.301945</td>
<td>0.066413</td>
<td>0.499416</td>
</tr>
<tr>
<td>2</td>
<td>0.960113</td>
<td>0.018073</td>
<td>0.639101</td>
<td>0.229013</td>
<td>0.645756</td>
<td>0.123180</td>
<td>0.894010</td>
</tr>
<tr>
<td>3</td>
<td>0.444433</td>
<td>0.001794</td>
<td>0.147979</td>
<td>0.083302</td>
<td>0.744487</td>
<td>0.971924</td>
<td>0.362019</td>
</tr>
<tr>
<td>4</td>
<td>0.997079</td>
<td>0.563684</td>
<td>0.811862</td>
<td>0.457039</td>
<td>0.133213</td>
<td>0.169442</td>
<td>0.124149</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p><strong>分类特征</strong>（sparse feature、category feature）：</p>
<ul>
<li>
<table>
<thead>
<tr>
<th></th>
<th>_col14</th>
<th>_col15</th>
<th>_col16</th>
<th>_col17</th>
<th>_col18</th>
<th>_col19</th>
<th>_col20</th>
<th>_col21</th>
<th>_col22</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>151</td>
<td>0</td>
<td>9</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>9</td>
<td>4</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
<td>11</td>
<td>4801</td>
<td>44</td>
<td>2</td>
<td>160</td>
<td>9</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>4549</td>
<td>3</td>
<td>1</td>
<td>10</td>
<td>31</td>
<td>2</td>
<td>485</td>
<td>2</td>
<td>10</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>111</td>
<td>10</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>5</td>
<td>160</td>
<td>0</td>
<td>72</td>
<td>0</td>
<td>13</td>
<td>53</td>
<td>0</td>
</tr>
</tbody>
</table>
</li>
<li>
<table>
<thead>
<tr>
<th></th>
<th>_col23</th>
<th>_col24</th>
<th>_col25</th>
<th>_col26</th>
<th>_col27</th>
<th>_col28</th>
<th>_col29</th>
<th>_col30</th>
<th>_col31</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2</td>
<td>395</td>
<td>41</td>
<td>1</td>
<td>14</td>
<td>5</td>
<td>2</td>
<td>7</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>101</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>19</td>
<td>6</td>
<td>6</td>
<td>1</td>
<td>0</td>
<td>4</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>2</td>
<td>38</td>
<td>6</td>
<td>1</td>
<td>7</td>
<td>1</td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>63</td>
<td>616</td>
<td>7</td>
<td>1</td>
<td>175</td>
<td>23</td>
<td>4</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
<li>
<table>
<thead>
<tr>
<th></th>
<th>_col32</th>
<th>_col33</th>
<th>_col34</th>
<th>_col35</th>
<th>_col36</th>
<th>_col37</th>
<th>_col38</th>
<th>_col39</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td>5283</td>
<td>4</td>
<td>0</td>
<td>21</td>
<td>33</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>3</td>
<td>204</td>
<td>310</td>
<td>1640</td>
<td>6</td>
<td>4</td>
<td>6</td>
</tr>
<tr>
<td>2</td>
<td>4</td>
<td>7</td>
<td>29</td>
<td>2</td>
<td>11</td>
<td>66</td>
<td>2</td>
<td>22</td>
</tr>
<tr>
<td>3</td>
<td>9</td>
<td>43</td>
<td>2</td>
<td>10</td>
<td>286</td>
<td>6</td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>477</td>
<td>10</td>
<td>6</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>30</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>数据相关属性：</p>
<ul>
<li>
<p>以生成模拟数据为例：</p>
<ul>
<li>
<div class="language-python" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># generate_data.py</span>

<span class="token keyword">import</span> hugectr
<span class="token keyword">from</span> hugectr<span class="token punctuation">.</span>tools <span class="token keyword">import</span> DataGenerator<span class="token punctuation">,</span> DataGeneratorParams
<span class="token keyword">from</span> mpi4py <span class="token keyword">import</span> MPI
<span class="token keyword">import</span> argparse
parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"Data Generation"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--num_files"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of files in training data"</span><span class="token punctuation">,</span> default <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--eval_num_files"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of files in validation data"</span><span class="token punctuation">,</span> default <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--num_samples_per_file'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"number of samples per file"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1000000</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dir_name'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"data directory name(Required)"</span><span class="token punctuation">)</span>
args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

data_generator_params <span class="token operator">=</span> DataGeneratorParams<span class="token punctuation">(</span>
  <span class="token builtin">format</span> <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>DataReaderType_t<span class="token punctuation">.</span>Parquet<span class="token punctuation">,</span>
  label_dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
  dense_dim <span class="token operator">=</span> <span class="token number">13</span><span class="token punctuation">,</span>
  num_slot <span class="token operator">=</span> <span class="token number">26</span><span class="token punctuation">,</span>
  num_files <span class="token operator">=</span> args<span class="token punctuation">.</span>num_files<span class="token punctuation">,</span>
  eval_num_files <span class="token operator">=</span> args<span class="token punctuation">.</span>eval_num_files<span class="token punctuation">,</span>
  i64_input_key <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
  num_samples_per_file <span class="token operator">=</span> args<span class="token punctuation">.</span>num_samples_per_file<span class="token punctuation">,</span>
  source <span class="token operator">=</span> <span class="token string">"./etc_data/"</span> <span class="token operator">+</span> args<span class="token punctuation">.</span>dir_name <span class="token operator">+</span> <span class="token string">"/file_list.txt"</span><span class="token punctuation">,</span>
  eval_source <span class="token operator">=</span> <span class="token string">"./etc_data/"</span> <span class="token operator">+</span> args<span class="token punctuation">.</span>dir_name <span class="token operator">+</span> <span class="token string">"/file_list_test.txt"</span><span class="token punctuation">,</span>
  slot_size_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">12988</span><span class="token punctuation">,</span> <span class="token number">7129</span><span class="token punctuation">,</span> <span class="token number">8720</span><span class="token punctuation">,</span> <span class="token number">5820</span><span class="token punctuation">,</span> <span class="token number">15196</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4914</span><span class="token punctuation">,</span> <span class="token number">1020</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">14274</span><span class="token punctuation">,</span> <span class="token number">10220</span><span class="token punctuation">,</span> <span class="token number">15088</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1518</span><span class="token punctuation">,</span> <span class="token number">3672</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">820</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">12817</span><span class="token punctuation">,</span> <span class="token number">13908</span><span class="token punctuation">,</span> <span class="token number">13447</span><span class="token punctuation">,</span> <span class="token number">9447</span><span class="token punctuation">,</span> <span class="token number">5867</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  nnz_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token comment"># for parquet, check_type doesn't make any difference</span>
  check_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>Check_t<span class="token punctuation">.</span>Non<span class="token punctuation">,</span>
  dist_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>Distribution_t<span class="token punctuation">.</span>PowerLaw<span class="token punctuation">,</span>
  power_law_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>PowerLaw_t<span class="token punctuation">.</span>Short<span class="token punctuation">)</span>
data_generator <span class="token operator">=</span> DataGenerator<span class="token punctuation">(</span>data_generator_params<span class="token punctuation">)</span>
data_generator<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></li>
<li>
<p>num_files：即数据集分为几个子集，也是使用ETC训练时每一个pass所用到的数据，子集数等于训练所需pass数</p>
</li>
<li>
<p>num_samples_per_file：也即每个子数据集的样本数</p>
</li>
<li>
<p>label_dim：每一个sample的标签维度</p>
</li>
<li>
<p>dense_dim：连续特征的数量</p>
</li>
<li>
<p>num_slot：分类特征的数量，也即slot数（特征域数量）</p>
</li>
<li>
<p>slot_size_array：每一个slot中的最大特征数量（也就是特征域的大小）</p>
</li>
<li>
<p>nnz_array： 样本在对应的slot (特征域)中最多可同时有几个特征（用于选择是one-hot还是multi-hot）</p>
</li>
</ul>
</li>
<li>
<p>执行脚本生成模拟数据（总共产生8个训练数据子集和2个测试子集）：</p>
<ul>
<li>
<div class="language-python" data-ext="py" data-title="py"><pre class="language-python"><code>python generate_data<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>dir_name <span class="token string">"file0"</span>
</code></pre></div><div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: Generate Parquet dataset
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: train data folder: ./etc_data/file0, <span class="token builtin class-name">eval</span> data folder: ./etc_data/file0, slot_size_array: <span class="token number">12988</span>, <span class="token number">7129</span>, <span class="token number">8720</span>, <span class="token number">5820</span>, <span class="token number">15196</span>, <span class="token number">4</span>, <span class="token number">4914</span>, <span class="token number">1020</span>, <span class="token number">30</span>, <span class="token number">14274</span>, <span class="token number">10220</span>, <span class="token number">15088</span>, <span class="token number">10</span>, <span class="token number">1518</span>, <span class="token number">3672</span>, <span class="token number">48</span>, <span class="token number">4</span>, <span class="token number">820</span>, <span class="token number">15</span>, <span class="token number">12817</span>, <span class="token number">13908</span>, <span class="token number">13447</span>, <span class="token number">9447</span>, <span class="token number">5867</span>, <span class="token number">45</span>, <span class="token number">33</span>, nnz array: <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token comment">#files for train: 8, #files for eval: 2, #samples per file: 1000000, Use power law distribution: 1, alpha of power law: 1.3</span>
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0 exist
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_0.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:33.757<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_1.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:36.560<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_2.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:39.337<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_3.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:42.083<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_4.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:44.807<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_5.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:47.641<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_6.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:50.377<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_7.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:53.131<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/file_list.txt done<span class="token operator">!</span>
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:53.132<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/val/gen_0.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:55.941<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/val/gen_1.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:58.788<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/file_list_test.txt done<span class="token operator">!</span>
</code></pre></div></li>
<li>
<p>输出keysets（以gen_0为例）：</p>
<ul>
<li>
<p>每一个子数据集（每个pass用的数据集）会生成一个keysets，所有数据的keysets构成一个更大的集合all_keysets，最终将根据all_keysets生成keysets文件xxx.keyset供GPU在t时刻预读取t+1时刻的数据到ETC中</p>
</li>
<li>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code>  ------------------------
  unique_keys:
  <span class="token number">0</span>            <span class="token number">0</span>
  <span class="token number">1</span>            <span class="token number">1</span>
  <span class="token number">2</span>            <span class="token number">2</span>
  <span class="token number">3</span>            <span class="token number">3</span>
  <span class="token number">4</span>            <span class="token number">4</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">12115</span>    <span class="token number">12978</span>
  <span class="token number">12116</span>    <span class="token number">12979</span>
  <span class="token number">12117</span>    <span class="token number">12981</span>
  <span class="token number">12118</span>    <span class="token number">12983</span>
  <span class="token number">12119</span>    <span class="token number">12986</span>
  Name: _col14, Length: <span class="token number">12120</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">12988</span>
  <span class="token number">1</span>       <span class="token number">12989</span>
  <span class="token number">2</span>       <span class="token number">12990</span>
  <span class="token number">3</span>       <span class="token number">12991</span>
  <span class="token number">4</span>       <span class="token number">12992</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">7077</span>    <span class="token number">20111</span>
  <span class="token number">7078</span>    <span class="token number">20112</span>
  <span class="token number">7079</span>    <span class="token number">20113</span>
  <span class="token number">7080</span>    <span class="token number">20114</span>
  <span class="token number">7081</span>    <span class="token number">20116</span>
  Name: _col15, Length: <span class="token number">7082</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">20117</span>
  <span class="token number">1</span>       <span class="token number">20118</span>
  <span class="token number">2</span>       <span class="token number">20119</span>
  <span class="token number">3</span>       <span class="token number">20120</span>
  <span class="token number">4</span>       <span class="token number">20121</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">8554</span>    <span class="token number">28827</span>
  <span class="token number">8555</span>    <span class="token number">28828</span>
  <span class="token number">8556</span>    <span class="token number">28830</span>
  <span class="token number">8557</span>    <span class="token number">28831</span>
  <span class="token number">8558</span>    <span class="token number">28834</span>
  Name: _col16, Length: <span class="token number">8559</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">28837</span>
  <span class="token number">1</span>       <span class="token number">28838</span>
  <span class="token number">2</span>       <span class="token number">28839</span>
  <span class="token number">3</span>       <span class="token number">28840</span>
  <span class="token number">4</span>       <span class="token number">28841</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">5798</span>    <span class="token number">34652</span>
  <span class="token number">5799</span>    <span class="token number">34653</span>
  <span class="token number">5800</span>    <span class="token number">34654</span>
  <span class="token number">5801</span>    <span class="token number">34655</span>
  <span class="token number">5802</span>    <span class="token number">34656</span>
  Name: _col17, Length: <span class="token number">5803</span>, dtype: int64
</code></pre></div></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>使用ETC分pass训练示例(与上例不同，此例使用10个pass来训练)：</p>
<ul>
<li>
<table>
<thead>
<tr>
<th style="text-align:right">Pass ID</th>
<th style="text-align:right">Number of Unique Keys</th>
<th style="text-align:right">Embedding size (GB)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">#0</td>
<td style="text-align:right">24199179</td>
<td style="text-align:right">11.54</td>
</tr>
<tr>
<td style="text-align:right">#1</td>
<td style="text-align:right">26015075</td>
<td style="text-align:right">12.40</td>
</tr>
<tr>
<td style="text-align:right">#2</td>
<td style="text-align:right">27387817</td>
<td style="text-align:right">13.06</td>
</tr>
<tr>
<td style="text-align:right">#3</td>
<td style="text-align:right">23672542</td>
<td style="text-align:right">11.29</td>
</tr>
<tr>
<td style="text-align:right">#4</td>
<td style="text-align:right">26053910</td>
<td style="text-align:right">12.42</td>
</tr>
<tr>
<td style="text-align:right">#5</td>
<td style="text-align:right">27697628</td>
<td style="text-align:right">13.21</td>
</tr>
<tr>
<td style="text-align:right">#6</td>
<td style="text-align:right">24727672</td>
<td style="text-align:right">11.79</td>
</tr>
<tr>
<td style="text-align:right">#7</td>
<td style="text-align:right">25643779</td>
<td style="text-align:right">12.23</td>
</tr>
<tr>
<td style="text-align:right">#8</td>
<td style="text-align:right">26374086</td>
<td style="text-align:right">12.58</td>
</tr>
<tr>
<td style="text-align:right">#9</td>
<td style="text-align:right">26580983</td>
<td style="text-align:right">12.67</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>数据预处理时，HugeCTR将分类特征转换为整型序列的方法：</p>
<ul>
<li>
<p>使用NVTabular：</p>
</li>
<li>
<div class="language-python" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># e.g. using NVTabular</span>

target_encode <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token string">'brand'</span><span class="token punctuation">,</span> <span class="token string">'user_id'</span><span class="token punctuation">,</span> <span class="token string">'product_id'</span><span class="token punctuation">,</span> <span class="token string">'cat_2'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'ts_weekday'</span><span class="token punctuation">,</span> <span class="token string">'ts_day'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span>
    nvt<span class="token punctuation">.</span>ops<span class="token punctuation">.</span>TargetEncoding<span class="token punctuation">(</span>
        nvt<span class="token punctuation">.</span>ColumnGroup<span class="token punctuation">(</span><span class="token string">'target'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        kfold<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
        p_smooth<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
        out_dtype<span class="token operator">=</span><span class="token string">"float32"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
</code></pre></div></li>
<li>
<blockquote>
<p>https://nvidia-merlin.github.io/NVTabular/v0.7.1/api/ops/targetencoding.html</p>
<p>Target encoding is a common feature-engineering technique for categorical columns in tabular datasets. For each categorical group, the mean of a continuous target column is calculated, and the group-specific mean of each row is used to create a new feature (column). To prevent overfitting, the following additional logic is applied:</p>
<blockquote>
<ol>
<li>
<p>Cross Validation: To prevent overfitting in training data, a cross-validation strategy is used - The data is split into k random “folds”, and the mean values within the i-th fold are calculated with data from all other folds. The cross-validation strategy is only employed when the dataset is used to update recorded statistics. For transformation-only workflow execution, global-mean statistics are used instead.</p>
</li>
<li>
<p>Smoothing: To prevent overfitting for low cardinality categories, the means are smoothed with the overall mean of the target variable.</p>
</li>
</ol>
</blockquote>
</blockquote>
</li>
</ul>
</li>
</ul></div><hr class="vp-article-hr"><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-10-25T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 13 分钟</span><meta property="timeRequired" content="PT13M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category8 clickable" role="navigation">推荐系统</span><!--]--><meta property="articleSection" content="推荐系统"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag8 clickable" role="navigation">HugeCTR</span><!--]--><meta property="keywords" content="CUDA,HugeCTR"></span></div></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/blogs/distributed_embeddings_blog.html"><header class="vp-article-title"><!----><!----><span property="headline">Distributed_embeddings</span></header></a><div class="vp-article-excerpt">
<h2>1. Introduce</h2>
<ul>
<li>
<p>参考链接：</p>
<ul>
<li>项目地址：https://github.com/NVIDIA-Merlin/distributed-embeddings</li>
<li>相关blog：https://developer.nvidia.com/blog/fast-terabyte-scale-recommender-training-made-easy-with-nvidia-merlin-distributed-embeddings/</li>
<li>相关项目：https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow2/Recommendation/DLRM#hybrid-parallel-training-with-merlin-distributed-embeddings</li>
<li>项目文档：https://nvidia-merlin.github.io/distributed-embeddings/index.html</li>
</ul>
</li>
<li>
<p>基于TF2构建大embedding，提供可伸缩模型并行封装器，能够自动将嵌入表分布到多GPU上（目前支持table-wise和column-wise）</p>
</li>
<li>
<p>支持混合模型并行（dist_model_parallel）：</p>
<figure><figcaption></figcaption></figure>
</li>
<li>
<p>仅需修改少量代码即可使用</p>
<div class="language-python" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> dist_model_parallel <span class="token keyword">as</span> dmp
 
<span class="token keyword">class</span> <span class="token class-name">MyEmbeddingModel</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span>  <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> table_sizes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    self<span class="token punctuation">.</span>embedding_layers <span class="token operator">=</span> <span class="token punctuation">[</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span> <span class="token keyword">for</span> input_dim<span class="token punctuation">,</span> output_dim <span class="token keyword">in</span> table_sizes<span class="token punctuation">]</span>
    <span class="token comment"># 1. Add this line to wrap list of embedding layers used in the model</span>
    self<span class="token punctuation">.</span>embedding_layers <span class="token operator">=</span> dmp<span class="token punctuation">.</span>DistributedEmbedding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_layers<span class="token punctuation">)</span>
  <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># embedding_outputs = [e(i) for e, i in zip(self.embedding_layers, inputs)]</span>
    embedding_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_layers<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
     
<span class="token decorator annotation punctuation">@tf<span class="token punctuation">.</span>function</span>
<span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> first_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
    probs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss_value <span class="token operator">=</span> loss<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> probs<span class="token punctuation">)</span>
 
  <span class="token comment"># 2. Change Horovod Gradient Tape to dmp tape</span>
  <span class="token comment"># tape = hvd.DistributedGradientTape(tape)</span>
  tape <span class="token operator">=</span> dmp<span class="token punctuation">.</span>DistributedGradientTape<span class="token punctuation">(</span>tape<span class="token punctuation">)</span>
  grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss_value<span class="token punctuation">,</span> model<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">)</span>
  opt<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>grads<span class="token punctuation">,</span> model<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">)</span><span class="token punctuation">)</span>
 
  <span class="token keyword">if</span> first_batch<span class="token punctuation">:</span>
    <span class="token comment"># 3. Change Horovod broadcast_variables to dmp's</span>
    <span class="token comment"># hvd.broadcast_variables(model.variables, root_rank=0)</span>
    dmp<span class="token punctuation">.</span>broadcast_variables<span class="token punctuation">(</span>model<span class="token punctuation">.</span>variables<span class="token punctuation">,</span> root_rank<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> loss_value
</code></pre></div></li>
<li>
<p>示例</p>
<div class="language-python" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> distributed_embeddings<span class="token punctuation">.</span>python<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dist_model_parallel <span class="token keyword">as</span> dmp
<span class="token keyword">from</span> distributed_embeddings<span class="token punctuation">.</span>python<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dist_model_parallel <span class="token keyword">import</span> Embedding<span class="token punctuation">,</span> DistributedEmbedding
layer0 <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"emb_0"</span><span class="token punctuation">)</span>
layer1 <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> combiner<span class="token operator">=</span><span class="token string">"mean"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"emb_1"</span><span class="token punctuation">)</span>
layer2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"emb_2"</span><span class="token punctuation">)</span>
layer3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"emb_3"</span><span class="token punctuation">)</span>
layers0 <span class="token operator">=</span> <span class="token punctuation">[</span>layer0<span class="token punctuation">,</span> layer1<span class="token punctuation">]</span>
layers1 <span class="token operator">=</span> <span class="token punctuation">[</span>layer2<span class="token punctuation">,</span> layer3<span class="token punctuation">]</span>
emb_layers0 <span class="token operator">=</span> DistributedEmbedding<span class="token punctuation">(</span>layers0<span class="token punctuation">,</span> column_slice_threshold<span class="token operator">=</span><span class="token number">32000</span><span class="token punctuation">)</span>
emb_layers1 <span class="token operator">=</span> DistributedEmbedding<span class="token punctuation">(</span>layers1<span class="token punctuation">,</span> column_slice_threshold<span class="token operator">=</span><span class="token number">32000</span><span class="token punctuation">)</span>
</code></pre></div></li>
<li>
<p>API:</p>
<ul>
<li>
<p>distributed_embeddings.python.layers.embedding.</p>
<p>Embedding</p>
<ul>
<li>接口基本上对齐 tf.keras.layers.Embedding，且增加了支持同时lookup多个embedding 再将它们combine（sum/mean）为一个vector输出</li>
<li>支持多种数据类型：onehot/fixed hotness (multihot, 输入tensor维度相同)/variable hotness（multihot，  输入tensor维度不同，使用tf.RaggedTensor）/sparse tensor(multihot,  使用tf.sparse.SparseTensor，按照csr格式存储稀疏tensor)</li>
</ul>
</li>
<li>
<p>distributed_embeddings.python.layers.dist_model_parallel.</p>
<p>DistributedEmbedding</p>
<ul>
<li>支持按列切分embedding table，适用于emb table规模庞大且无法存入单张卡内存的情况</li>
<li>可设置column_slice_threshold参数确定切分阈值（elements num）</li>
<li>可封装共享embedding table，如两个特征域，一个表示watched_video, 一个表示browsed_video，他们的特征都是videos,因此可公用同一个emb table</li>
</ul>
</li>
</ul>
<p>性能表现：</p>
<ul>
<li>DLRM model with 113 billion parameters (421 GiB model size) trained on the <a href="https://labs.criteo.com/2013/12/download-terabyte-click-logs/" target="_blank" rel="noopener noreferrer">Criteo Terabyte Click Logs</a> dataset（官方数据，未实测）</li>
</ul>
<table>
<thead>
<tr>
<th>Hardware</th>
<th>Description</th>
<th>Training Throughput (samples/second)</th>
<th>Speedup over CPU</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>2 x AMD EPYC 7742</strong></td>
<td>Both MLP layers and embeddings on CPU</td>
<td>17.7k</td>
<td>1x</td>
</tr>
<tr>
<td><strong>1 x A100-80GB</strong>; 2 x AMD EPYC 7742</td>
<td>Large embeddings on CPU, everything else on GPU</td>
<td>768k</td>
<td>43x</td>
</tr>
<tr>
<td><strong>DGX A100 (8xA100-80GB)</strong></td>
<td>Hybrid parallel with NVIDIA Merlin <strong>Distributed-Embeddings,</strong> whole model on GPU</td>
<td>12.1M</td>
<td><strong>683x</strong></td>
</tr>
</tbody>
</table>
<p>Synthetic models benchmark （见第三节test部分benchmarks测试）</p>
<ul>
<li>模型规模定义</li>
</ul>
<table>
<thead>
<tr>
<th>Model</th>
<th>Total number of embedding tables</th>
<th>Total embedding size (GiB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tiny</td>
<td>55</td>
<td>4.2</td>
</tr>
<tr>
<td>Small</td>
<td>107</td>
<td>26.3</td>
</tr>
<tr>
<td>Medium</td>
<td>311</td>
<td>206.2</td>
</tr>
<tr>
<td>Large</td>
<td>612</td>
<td>773.8</td>
</tr>
<tr>
<td>Jumbo</td>
<td>1,022</td>
<td>3,109.5</td>
</tr>
</tbody>
</table>
<ul>
<li>官方性能(DGX-A100-80GB, batchsize=65536, optimizer=adagrad )</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center"><strong>Model</strong></th>
<th style="text-align:center"><strong>Training step time (ms)</strong></th>
<th style="text-align:center"><strong>Training step time (ms)</strong></th>
<th style="text-align:center"><strong>Training step time (ms)</strong></th>
<th style="text-align:center"><strong>Training step time (ms)</strong></th>
<th><strong>Training step time (ms)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>Model</strong></td>
<td style="text-align:center"><strong>1 GPU</strong></td>
<td style="text-align:center"><strong>8 GPU</strong></td>
<td style="text-align:center"><strong>16 GPU</strong></td>
<td style="text-align:center"><strong>32 GPU</strong></td>
<td><strong>128 GPU</strong></td>
</tr>
<tr>
<td style="text-align:center"><strong>Tiny</strong></td>
<td style="text-align:center">17.6</td>
<td style="text-align:center">3.6</td>
<td style="text-align:center">3.2</td>
<td style="text-align:center"></td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><strong>Small</strong></td>
<td style="text-align:center">57.8</td>
<td style="text-align:center">14.0</td>
<td style="text-align:center">11.6</td>
<td style="text-align:center">7.4</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><strong>Medium</strong></td>
<td style="text-align:center"></td>
<td style="text-align:center">64.4</td>
<td style="text-align:center">44.9</td>
<td style="text-align:center">31.1</td>
<td>17.2</td>
</tr>
<tr>
<td style="text-align:center"><strong>Large</strong></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">65.0</td>
<td>33.4</td>
</tr>
<tr>
<td style="text-align:center"><strong>Jumbo</strong></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td>102.3</td>
</tr>
</tbody>
</table>
<ul>
<li>实测性能(Tesla T4, batchsize=65536, optimizer=adagrad)</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center"><strong>Model</strong></th>
<th style="text-align:center"><strong>Training step time (ms)</strong></th>
<th><strong>Training step time (ms)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>Model</strong></td>
<td style="text-align:center">1 GPU</td>
<td>4 GPU</td>
</tr>
<tr>
<td style="text-align:center"><strong>Tiny</strong></td>
<td style="text-align:center">42.703</td>
<td>82.856</td>
</tr>
</tbody>
</table>
<ul>
<li>对比TF原生数据并行</li>
</ul>
<table>
<thead>
<tr>
<th><strong>Solution</strong></th>
<th style="text-align:center"><strong>Training step time (ms)</strong></th>
<th><strong>Training step time (ms)</strong></th>
<th><strong>Training step time (ms)</strong></th>
<th><strong>Training step time (ms)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Solution</strong></td>
<td style="text-align:center"><strong>1 GPU</strong></td>
<td><strong>2 GPU</strong></td>
<td><strong>4 GPU</strong></td>
<td><strong>8 GPU</strong></td>
</tr>
<tr>
<td>NVIDIA Merlin Distributed Embeddings <strong>Model Parallel</strong></td>
<td style="text-align:center">17.7</td>
<td><strong>11.6</strong></td>
<td><strong>6.4</strong></td>
<td><strong>4.2</strong></td>
</tr>
<tr>
<td>Native TensorFlow <strong>Data Parallel</strong></td>
<td style="text-align:center">19.9</td>
<td>20.2</td>
<td>21.2</td>
<td>22.3</td>
</tr>
</tbody>
</table>
</li>
</ul></div><hr class="vp-article-hr"><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-08-03T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 4 分钟</span><meta property="timeRequired" content="PT4M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">高性能</span><!--]--><meta property="articleSection" content="高性能"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag8 clickable" role="navigation">Tensorflow</span><span class="page-tag-item tag4 clickable" role="navigation">Embedding</span><!--]--><meta property="keywords" content="CUDA,Tensorflow,Embedding"></span></div></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/blogs/hugectr_blog.html"><header class="vp-article-title"><!----><!----><span property="headline">HugeCTR 学习笔记</span></header></a><div class="vp-article-excerpt">
<h2>1 背景</h2>
<h3>1.1 推荐系统与深度学习</h3>
<ul>
<li>
<p>随着互联网的发展，受益于数据爆炸式地增长，用户获取信息的途径与方式越来越轻松多样，但也因为其中夹杂着大量庞杂冗余甚至无用的信息，如何提供用户真正感兴趣的内容也成为了各大企业尤其是商业领域重点关的问题。<strong>推荐系统就是从海量的数据中，根据用户偏好为其选择出可能感兴趣的内容并推送给用户</strong></p>
</li>
<li>
<p><strong>CTR（Click-trough  rate）也即点击率</strong>，是用于评估广告、搜索内容、博文等质量、搜索相关程度以及用户喜爱程度的重要指标，也能反馈给信息提供者所推荐给用户的内容是否合适、质量是否上乘、该内容是否选对了潜在受众。<strong>CTR的定义为内容被用户点击的次数除以内容展示给用户的次数</strong>，e.g. 一条广告被用户刷到了100次，但用户只点进去了1次，那么点击率就是1%</p>
</li>
<li>
<p>从技术架构上，可将推荐系统分为数据与模型部分：</p>
<ul>
<li><strong>数据部分</strong>主要负责“用户”“物品”“场景”的信息收集与处理；</li>
<li><strong>模型部分</strong>是推荐系统的主体，模型的结构一般由“召回层”“排序层”“补充策略与算法层”组成：
<ul>
<li><strong>召回层</strong>：一般利用高效的召回规则、算法或简单的模型,快速从海量的候选集中召回用户可能感兴趣的物品</li>
<li><strong>排序层</strong>：利用排序模型对初筛的候选集进行精排序</li>
<li><strong>补充策略与算法层</strong>：也被称为“再排序层”,可以在将推荐列表返回用户之前,为兼顾结果的“多样性”“流行度”“新鲜度”等指标,结合一些补充的策略和算法对推荐列表进行一定的调整,最终形成用户可见的推荐列表</li>
</ul>
</li>
</ul>
</li>
<li>
<figure><figcaption>img</figcaption></figure>
</li>
<li>
<p>与传统推荐系统实现方式相比，深度学习推荐模型具有更强的表达能力，模型结构更加灵活能够适应不同的使用场景，但现代推荐系统及使用场景有以下<strong>特点与难点</strong>：</p>
<ul>
<li>
<p>现代推荐模型合并了<strong>TB级别的嵌入表</strong>，传统推理服务架构无法将整个模型部署到单个服务器上（高时延、高存储占用）</p>
</li>
<li>
<p>许多推荐场景<strong>需要支持在线推理与模型更新</strong>，要求低时延</p>
</li>
<li>
<p>查找embedding的过程是独立的，因此<strong>容易实现并行化</strong>（GPU：higher  bandwidth &amp; throughput），但也需要占用大量内存资源和少量的计算资源（<strong>不平衡的资源需求</strong>降低了GPU在推理系统中的吸引力）→ 大多现存解决方案将嵌入查找操作与在GPU中的稠密计算相解耦，放入CPU中进行（放弃GPU带宽优势，CPU与GPU间的<strong>通信带宽成为首要瓶颈</strong>）</p>
</li>
<li>
<p>现实世界推荐数据集的经验证据表明，在 CTR 和其他推荐任务的推理过程中嵌入key访问通常表现出很强的局部性，并且大致遵循<strong>幂律分布</strong>，具有<strong>长尾效应</strong> <em>（大量特征的embedding总和占据了整个模型的大部分，但是他们出现的频率非常低，因此将这种特征长期存储在CPU和GPU中是低效的）</em></p>
<figure><figcaption>Visualization of power law distribution representing the likelihood of embedding key accesses. A few embeddings are accessed far more often than the others.</figcaption></figure>
</li>
</ul>
</li>
</ul></div><hr class="vp-article-hr"><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-08-03T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category8 clickable" role="navigation">推荐系统</span><!--]--><meta property="articleSection" content="推荐系统"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag8 clickable" role="navigation">HugeCTR</span><!--]--><meta property="keywords" content="CUDA,HugeCTR"></span></div></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/blogs/cucollection_blog.html"><header class="vp-article-title"><!----><!----><span property="headline">cuCollections性能测试</span></header></a><div class="vp-article-excerpt">
<h2>0. 测试目标</h2>
<ul>
<li>cucollection性能分析（测试在负载因子为0.8/0.9时的性能，以及空载时的插入性能，吞吐量，带宽 etc）key为64bit int，数据使用均匀分布</li>
<li>
<ul>
<li>[x] 阅读benchmark代码，修改benchmark中的参数，测试不同负载因子下的性能( dynamic, static)</li>
<li>[x] 弄清example中的示例，基本用法，可参考test</li>
<li>[x] 根据所需测试性能参数修改benchmark测试</li>
</ul>
</li>
</ul>
<h2>1. 环境配置</h2></div><hr class="vp-article-hr"><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2022-11-30T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 14 分钟</span><meta property="timeRequired" content="PT14M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">高性能</span><!--]--><meta property="articleSection" content="高性能"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag6 clickable" role="navigation">Hash</span><!--]--><meta property="keywords" content="CUDA,Hash"></span></div></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/blogs/warpcore_blog.html"><header class="vp-article-title"><!----><!----><span property="headline">WARPCORE 学习笔记</span></header></a><div class="vp-article-excerpt">
<p>项目链接：<a href="https://github.com/sleeepyjack/warpcore" target="_blank" rel="noopener noreferrer">https://github.com/sleeepyjack/warpcore</a></p>
<p>文档：<a href="https://sleeepyjack.github.io/warpcore/index.html" target="_blank" rel="noopener noreferrer">https://sleeepyjack.github.io/warpcore/index.html</a></p></div><hr class="vp-article-hr"><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2022-11-10T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 10 分钟</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">高性能</span><!--]--><meta property="articleSection" content="高性能"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag6 clickable" role="navigation">Hash</span><!--]--><meta property="keywords" content="CUDA,Hash"></span></div></article></div><div class="vp-pagination"></div></div></main><aside class="vp-blog-info-wrapper"><div class="vp-blogger-info" vocab="https://schema.org/" typeof="Person"><div class="vp-blogger" style="cursor:pointer;" aria-label="个人介绍" data-balloon-pos="down" role="link"><img class="vp-blogger-avatar" src="/light.png" property="image" alt="Blogger Avatar" loading="lazy"><div class="vp-blogger-name" property="name">BradZhone</div><!----><meta property="url" content="/intro.html"></div><div class="vp-blog-counts"><a class="route-link vp-blog-count" href="/article/"><div class="count">24</div><div>文章</div></a><a class="route-link vp-blog-count" href="/category/"><div class="count">10</div><div>分类</div></a><a class="route-link vp-blog-count" href="/tag/"><div class="count">19</div><div>标签</div></a><a class="route-link vp-blog-count" href="/timeline/"><div class="count">21</div><div>时间轴</div></a></div><div class="vp-social-medias"><a class="vp-social-media" href="mailto:callmezxz@gmail.com" rel="noopener noreferrer" target="_blank" aria-label="Email" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon email-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#1384FF"/><path fill="#fff" d="M270.077 286.233H751.99c32.933 0 59.86 24.855 60.274 55.51l-301.023 157L210.217 341.88c.207-30.723 26.927-55.717 59.86-55.717zm-59.929 115.714-.276 277.756c0 30.931 27.134 56.2 60.205 56.2H751.99c33.14 0 60.274-25.269 60.274-56.2V401.81L518.283 551.492a15.88 15.88 0 0 1-14.43 0L210.148 401.947z"/></svg></a><a class="vp-social-media" href="https://github.com/BradZhone" rel="noopener noreferrer" target="_blank" aria-label="GitHub" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#171515"/><path fill="#fff" d="M509.423 146.442c-200.317 0-362.756 162.42-362.756 362.8 0 160.266 103.936 296.24 248.109 344.217 18.139 3.327 24.76-7.872 24.76-17.486 0-8.613-.313-31.427-.49-61.702-100.912 21.923-122.205-48.63-122.205-48.63-16.495-41.91-40.28-53.067-40.28-53.067-32.937-22.51 2.492-22.053 2.492-22.053 36.407 2.566 55.568 37.386 55.568 37.386 32.362 55.438 84.907 39.43 105.58 30.143 3.296-23.444 12.667-39.43 23.032-48.498-80.557-9.156-165.246-40.28-165.246-179.297 0-39.604 14.135-71.988 37.342-97.348-3.731-9.178-16.18-46.063 3.556-96.009 0 0 30.46-9.754 99.76 37.19 28.937-8.048 59.97-12.071 90.823-12.211 30.807.14 61.843 4.165 90.822 12.21 69.26-46.944 99.663-37.189 99.663-37.189 19.792 49.946 7.34 86.831 3.61 96.01 23.25 25.359 37.29 57.742 37.29 97.347 0 139.366-84.82 170.033-165.637 179.013 13.026 11.2 24.628 33.342 24.628 67.182 0 48.498-.445 87.627-.445 99.521 0 9.702 6.535 20.988 24.945 17.444 144.03-48.067 247.881-183.95 247.881-344.175 0-200.378-162.442-362.798-362.802-362.798z"/></svg></a></div></div><div class="vp-blog-infos"><div class="vp-blog-type-switcher"><button type="button" class="vp-blog-type-button"><div class="icon-wrapper active" aria-label="文章" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon article-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="article icon"><path d="M853.333 938.667H170.667A42.667 42.667 0 0 1 128 896V128a42.667 42.667 0 0 1 42.667-42.667h682.666A42.667 42.667 0 0 1 896 128v768a42.667 42.667 0 0 1-42.667 42.667zm-42.666-85.334V170.667H213.333v682.666h597.334zM298.667 256h170.666v170.667H298.667V256zm0 256h426.666v85.333H298.667V512zm0 170.667h426.666V768H298.667v-85.333zm256-384h170.666V384H554.667v-85.333z"></path></svg></div></button><button type="button" class="vp-blog-type-button"><div class="icon-wrapper" aria-label="分类" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg></div></button><button type="button" class="vp-blog-type-button"><div class="icon-wrapper" aria-label="标签" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg></div></button><button type="button" class="vp-blog-type-button"><div class="icon-wrapper" aria-label="时间轴" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timeline-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timeline icon"><path d="M511.997 70.568c-243.797 0-441.429 197.633-441.429 441.435 0 243.797 197.632 441.429 441.43 441.429S953.431 755.8 953.431 512.002c0-243.796-197.637-441.434-441.435-441.434zm150.158 609.093-15.605 15.61c-8.621 8.615-22.596 8.615-31.215 0L472.197 552.126c-4.95-4.944-4.34-14.888-4.34-24.677V247.14c0-12.19 9.882-22.07 22.07-22.07h22.07c12.19 0 22.07 9.882 22.07 22.07v273.218l128.088 128.088c8.62 8.62 8.62 22.595 0 31.215zm0 0"></path></svg></div></button></div><div class="vp-star-article-wrapper"><div class="title"><svg xmlns="http://www.w3.org/2000/svg" class="icon article-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="article icon"><path d="M853.333 938.667H170.667A42.667 42.667 0 0 1 128 896V128a42.667 42.667 0 0 1 42.667-42.667h682.666A42.667 42.667 0 0 1 896 128v768a42.667 42.667 0 0 1-42.667 42.667zm-42.666-85.334V170.667H213.333v682.666h597.334zM298.667 256h170.666v170.667H298.667V256zm0 256h426.666v85.333H298.667V512zm0 170.667h426.666V768H298.667v-85.333zm256-384h170.666V384H554.667v-85.333z"></path></svg><span class="num">24</span>文章</div><hr><div class="vp-star-article-empty">星标 为空</div></div></div></aside></div></div><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">BradZhone's Blog</div><div class="vp-copyright">Copyright © 2024 BradZhone </div></footer></div><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-Coh1oo3x.js" defer></script>
  </body>
</html>
