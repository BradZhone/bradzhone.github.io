<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.9" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.32" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://bradzhone.github.io/blogs/hugectr_blog.html"><meta property="og:site_name" content="BradZhone's Blog"><meta property="og:title" content="HugeCTR 学习笔记"><meta property="og:description" content="HugeCTR 学习笔记 1 背景 1.1 推荐系统与深度学习 随着互联网的发展，受益于数据爆炸式地增长，用户获取信息的途径与方式越来越轻松多样，但也因为其中夹杂着大量庞杂冗余甚至无用的信息，如何提供用户真正感兴趣的内容也成为了各大企业尤其是商业领域重点关的问题。推荐系统就是从海量的数据中，根据用户偏好为其选择出可能感兴趣的内容并推送给用户 CTR（C..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="BradZhone"><meta property="article:tag" content="CUDA"><meta property="article:tag" content="HugeCTR"><meta property="article:published_time" content="2023-08-03T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"HugeCTR 学习笔记","image":[""],"datePublished":"2023-08-03T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"BradZhone","url":"https://github.com/BradZhone"}]}</script><title>HugeCTR 学习笔记 | BradZhone's Blog</title><meta name="description" content="HugeCTR 学习笔记 1 背景 1.1 推荐系统与深度学习 随着互联网的发展，受益于数据爆炸式地增长，用户获取信息的途径与方式越来越轻松多样，但也因为其中夹杂着大量庞杂冗余甚至无用的信息，如何提供用户真正感兴趣的内容也成为了各大企业尤其是商业领域重点关的问题。推荐系统就是从海量的数据中，根据用户偏好为其选择出可能感兴趣的内容并推送给用户 CTR（C...">
    <link rel="preload" href="/assets/style-BkjCpNEe.css" as="style"><link rel="stylesheet" href="/assets/style-BkjCpNEe.css">
    <link rel="modulepreload" href="/assets/app-Coh1oo3x.js"><link rel="modulepreload" href="/assets/hugectr_blog.html-BrFINEES.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/intro.html-D9dwEpHI.js" as="script"><link rel="prefetch" href="/assets/index.html-D5LnkeFh.js" as="script"><link rel="prefetch" href="/assets/CRNN_blog.html-Cb6b7OD4.js" as="script"><link rel="prefetch" href="/assets/cucollection_blog.html-DLix_uWp.js" as="script"><link rel="prefetch" href="/assets/cuda_blog.html-CBZ1Rex-.js" as="script"><link rel="prefetch" href="/assets/distributed_embeddings_blog.html-Cw7oBr-d.js" as="script"><link rel="prefetch" href="/assets/howToBuildThisBlog.html-Dxn0xRj3.js" as="script"><link rel="prefetch" href="/assets/hugectr_src_blog.html-d9qgPAFk.js" as="script"><link rel="prefetch" href="/assets/index.html-DI16Z1C4.js" as="script"><link rel="prefetch" href="/assets/torchrec_cn_embedding_note.html-YEVLbIAq.js" as="script"><link rel="prefetch" href="/assets/warpcore_blog.html-Cz_5IJvA.js" as="script"><link rel="prefetch" href="/assets/c___note.html-BYbhq9Nq.js" as="script"><link rel="prefetch" href="/assets/deep_learning.html-b-b3zdJE.js" as="script"><link rel="prefetch" href="/assets/linux_command.html-G4dNyKFL.js" as="script"><link rel="prefetch" href="/assets/LLM.html-9hu1pKVY.js" as="script"><link rel="prefetch" href="/assets/loss.html-CJxfnubw.js" as="script"><link rel="prefetch" href="/assets/markdown.html-DJcQDvEC.js" as="script"><link rel="prefetch" href="/assets/metrics.html-DKJGeFbq.js" as="script"><link rel="prefetch" href="/assets/PLAN_Z.html-B9yJBwFA.js" as="script"><link rel="prefetch" href="/assets/precision.html-B_dd_MdY.js" as="script"><link rel="prefetch" href="/assets/index.html-D1wTsZoY.js" as="script"><link rel="prefetch" href="/assets/torchrec_note.html-B-i_O6mg.js" as="script"><link rel="prefetch" href="/assets/uml_note.html-IaIR5y-b.js" as="script"><link rel="prefetch" href="/assets/index.html-Cgwhpoct.js" as="script"><link rel="prefetch" href="/assets/404.html-DYVdKbdY.js" as="script"><link rel="prefetch" href="/assets/index.html-1jQ9-Uww.js" as="script"><link rel="prefetch" href="/assets/index.html-BEDqx9YQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BltlhrdK.js" as="script"><link rel="prefetch" href="/assets/index.html-C0yITs6x.js" as="script"><link rel="prefetch" href="/assets/index.html-maJbTduo.js" as="script"><link rel="prefetch" href="/assets/index.html-BPQ9UPx_.js" as="script"><link rel="prefetch" href="/assets/index.html-BQB6pLKG.js" as="script"><link rel="prefetch" href="/assets/index.html-Be8HnZrW.js" as="script"><link rel="prefetch" href="/assets/index.html-DzX6xTUq.js" as="script"><link rel="prefetch" href="/assets/index.html-BxZ6QV-X.js" as="script"><link rel="prefetch" href="/assets/index.html-Dl0UMf-I.js" as="script"><link rel="prefetch" href="/assets/index.html-xBRd_OsE.js" as="script"><link rel="prefetch" href="/assets/index.html-BTkUZ9Ws.js" as="script"><link rel="prefetch" href="/assets/index.html-D57wSldI.js" as="script"><link rel="prefetch" href="/assets/index.html-Dqr1foaP.js" as="script"><link rel="prefetch" href="/assets/index.html-CSGzSmAq.js" as="script"><link rel="prefetch" href="/assets/index.html-BnBAmG4V.js" as="script"><link rel="prefetch" href="/assets/index.html-d2G8e39M.js" as="script"><link rel="prefetch" href="/assets/index.html-CpCodvQl.js" as="script"><link rel="prefetch" href="/assets/index.html-hEB5WJuD.js" as="script"><link rel="prefetch" href="/assets/index.html-DX2Ijbyk.js" as="script"><link rel="prefetch" href="/assets/index.html-Da6Vp1bl.js" as="script"><link rel="prefetch" href="/assets/index.html-CGr0tdaC.js" as="script"><link rel="prefetch" href="/assets/index.html-D5fEOhj5.js" as="script"><link rel="prefetch" href="/assets/index.html-C1vK6J6C.js" as="script"><link rel="prefetch" href="/assets/index.html-DgD_mq8U.js" as="script"><link rel="prefetch" href="/assets/index.html-Demc7CPi.js" as="script"><link rel="prefetch" href="/assets/index.html-D31kcDwM.js" as="script"><link rel="prefetch" href="/assets/index.html-COTqqkDG.js" as="script"><link rel="prefetch" href="/assets/index.html-DtZDr4LJ.js" as="script"><link rel="prefetch" href="/assets/index.html-BYDcpP-H.js" as="script"><link rel="prefetch" href="/assets/index.html-QpKn8zOy.js" as="script"><link rel="prefetch" href="/assets/index.html-Fd1nQRc_.js" as="script"><link rel="prefetch" href="/assets/index.html-BEVLRn0k.js" as="script"><link rel="prefetch" href="/assets/giscus-7BMGhbDA.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo light" src="/light.png" alt><img class="vp-nav-logo dark" src="/dark.png" alt><span class="vp-site-name hide-in-pad">BradZhone&#39;s Blog</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/" aria-label="Home"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link active" href="/blogs/" aria-label="Blogs"><span class="font-icon icon fa-fw fa-sm fas fa-blog" style=""></span>Blogs<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/notes/" aria-label="Notes"><span class="font-icon icon fa-fw fa-sm fas fa-note-sticky" style=""></span>Notes<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/thinking/" aria-label="Thinking"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Thinking<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/intro.html" aria-label="About Me"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>About Me<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><!----><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable active"><span class="font-icon icon fa-fw fa-sm fas fa-blog" style=""></span><a class="route-link nav-link active vp-sidebar-title" href="/blogs/" aria-label="Blogs"><!---->Blogs<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/howToBuildThisBlog.html" aria-label="如何搭建本博客"><!---->如何搭建本博客<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/CRNN_blog.html" aria-label="CRNN网络调研适配记录"><!---->CRNN网络调研适配记录<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/cucollection_blog.html" aria-label="cuCollections性能测试"><!---->cuCollections性能测试<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/cuda_blog.html" aria-label="CUDA学习笔记"><!---->CUDA学习笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/distributed_embeddings_blog.html" aria-label="Distributed_embeddings"><!---->Distributed_embeddings<!----></a></li><li><a class="route-link nav-link active vp-sidebar-link vp-sidebar-page active" href="/blogs/hugectr_blog.html" aria-label="HugeCTR 学习笔记"><!---->HugeCTR 学习笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/hugectr_src_blog.html" aria-label="HugeCTR源码阅读笔记"><!---->HugeCTR源码阅读笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/torchrec_cn_embedding_note.html" aria-label="torchrec cn_embedding模块设计方案"><!---->torchrec cn_embedding模块设计方案<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/warpcore_blog.html" aria-label="WARPCORE 学习笔记"><!---->WARPCORE 学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-note-sticky" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/notes/" aria-label="Notes"><!---->Notes<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/c___note.html" aria-label="C++ note"><!---->C++ note<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/deep_learning.html" aria-label="DL相关"><!---->DL相关<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/precision.html" aria-label="Floating Point precision formats"><!---->Floating Point precision formats<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/linux_command.html" aria-label="Linux 快捷指令"><!---->Linux 快捷指令<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/LLM.html" aria-label="LLM"><!---->LLM<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/loss.html" aria-label="Loss 相关问题"><!---->Loss 相关问题<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/markdown.html" aria-label="Markdown 语法"><!---->Markdown 语法<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/metrics.html" aria-label="Metrics"><!---->Metrics<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/PLAN_Z.html" aria-label="TODO LIST"><!---->TODO LIST<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/torchrec_note.html" aria-label="Torchrec调研"><!---->Torchrec调研<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/uml_note.html" aria-label="UML学习笔记"><!---->UML学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/thinking/" aria-label="Thinking"><!---->Thinking<!----></a><!----></p><ul class="vp-sidebar-links"></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->HugeCTR 学习笔记</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-08-03T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category8 clickable" role="navigation">推荐系统</span><!--]--><meta property="articleSection" content="推荐系统"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag8 clickable" role="navigation">HugeCTR</span><!--]--><meta property="keywords" content="CUDA,HugeCTR"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!--[--><!----><!--]--><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-背景">1 背景</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-推荐系统与深度学习">1.1 推荐系统与深度学习</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-merlin">1.2 Merlin</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-介绍">2 介绍</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-特性-发布记录">2.1 特性&amp;发布记录</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-性能">2.2 性能</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-3-架构-模块设计">2.3 架构&amp;模块设计</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-安装hugectr">3 安装HugeCTR</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-1-hugectr-api">3.1 HugeCTR API</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-2-hugectr-sok">3.2 HugeCTR SOK</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#项目">项目：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#文档-paper">文档 &amp; paper：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#blogs">blogs：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#性能数据来源">性能数据来源：</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="hugectr-学习笔记" tabindex="-1"><a class="header-anchor" href="#hugectr-学习笔记"><span>HugeCTR 学习笔记</span></a></h1><h2 id="_1-背景" tabindex="-1"><a class="header-anchor" href="#_1-背景"><span>1 背景</span></a></h2><h3 id="_1-1-推荐系统与深度学习" tabindex="-1"><a class="header-anchor" href="#_1-1-推荐系统与深度学习"><span>1.1 推荐系统与深度学习</span></a></h3><ul><li><p>随着互联网的发展，受益于数据爆炸式地增长，用户获取信息的途径与方式越来越轻松多样，但也因为其中夹杂着大量庞杂冗余甚至无用的信息，如何提供用户真正感兴趣的内容也成为了各大企业尤其是商业领域重点关的问题。<strong>推荐系统就是从海量的数据中，根据用户偏好为其选择出可能感兴趣的内容并推送给用户</strong></p></li><li><p><strong>CTR（Click-trough rate）也即点击率</strong>，是用于评估广告、搜索内容、博文等质量、搜索相关程度以及用户喜爱程度的重要指标，也能反馈给信息提供者所推荐给用户的内容是否合适、质量是否上乘、该内容是否选对了潜在受众。<strong>CTR的定义为内容被用户点击的次数除以内容展示给用户的次数</strong>，e.g. 一条广告被用户刷到了100次，但用户只点进去了1次，那么点击率就是1%</p></li><li><p>从技术架构上，可将推荐系统分为数据与模型部分：</p><ul><li><strong>数据部分</strong>主要负责“用户”“物品”“场景”的信息收集与处理；</li><li><strong>模型部分</strong>是推荐系统的主体，模型的结构一般由“召回层”“排序层”“补充策略与算法层”组成： <ul><li><strong>召回层</strong>：一般利用高效的召回规则、算法或简单的模型,快速从海量的候选集中召回用户可能感兴趣的物品</li><li><strong>排序层</strong>：利用排序模型对初筛的候选集进行精排序</li><li><strong>补充策略与算法层</strong>：也被称为“再排序层”,可以在将推荐列表返回用户之前,为兼顾结果的“多样性”“流行度”“新鲜度”等指标,结合一些补充的策略和算法对推荐列表进行一定的调整,最终形成用户可见的推荐列表</li></ul></li></ul></li><li><figure><img src="/assets/modle-CvJFDzzM.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li><li><p>与传统推荐系统实现方式相比，深度学习推荐模型具有更强的表达能力，模型结构更加灵活能够适应不同的使用场景，但现代推荐系统及使用场景有以下<strong>特点与难点</strong>：</p><ul><li><p>现代推荐模型合并了<strong>TB级别的嵌入表</strong>，传统推理服务架构无法将整个模型部署到单个服务器上（高时延、高存储占用）</p></li><li><p>许多推荐场景<strong>需要支持在线推理与模型更新</strong>，要求低时延</p></li><li><p>查找embedding的过程是独立的，因此<strong>容易实现并行化</strong>（GPU：higher bandwidth &amp; throughput），但也需要占用大量内存资源和少量的计算资源（<strong>不平衡的资源需求</strong>降低了GPU在推理系统中的吸引力）→ 大多现存解决方案将嵌入查找操作与在GPU中的稠密计算相解耦，放入CPU中进行（放弃GPU带宽优势，CPU与GPU间的<strong>通信带宽成为首要瓶颈</strong>）</p></li><li><p>现实世界推荐数据集的经验证据表明，在 CTR 和其他推荐任务的推理过程中嵌入key访问通常表现出很强的局部性，并且大致遵循<strong>幂律分布</strong>，具有<strong>长尾效应</strong> <em>（大量特征的embedding总和占据了整个模型的大部分，但是他们出现的频率非常低，因此将这种特征长期存储在CPU和GPU中是低效的）</em></p><figure><img src="/assets/hps_1-DiD4u6H1.png" alt="Visualization of power law distribution representing the likelihood of embedding key accesses. A few embeddings are accessed far more often than the others." tabindex="0" loading="lazy"><figcaption>Visualization of power law distribution representing the likelihood of embedding key accesses. A few embeddings are accessed far more often than the others.</figcaption></figure></li></ul></li></ul><h3 id="_1-2-merlin" tabindex="-1"><a class="header-anchor" href="#_1-2-merlin"><span>1.2 Merlin</span></a></h3><ul><li>Merlin 是NVIDIA为<strong>推荐系统模型推理训练</strong>专门构建的一套端到端解决方案，包括库、方法和工具，通过解决常见的<strong>预处理、特征工程、训练、推理和部署到生产</strong>来简化推荐系统的构建。Merlin 组件和功能经过优化，可支持数百 TB 数据的检索、过滤、评分和排序，所有这些都可通过易于使用的 API 访问。</li><li>它包括<strong>NVTabular、HugeCTR、Merlin Models、Merlin Systems、Merlin Core</strong>等组件： <ul><li><p><strong><a href="https://github.com/NVIDIA-Merlin/NVTabular" target="_blank" rel="noopener noreferrer">NVTabular<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></strong>：NVTabular 是一个表格数据的<strong>特征工程和预处理库</strong>。该库可以快速轻松地操作用于训练基于深度学习的推荐系统的 TB 级数据集。该库提供了一个高级 API，可以定义复杂的数据转换工作流程</p></li><li><p><strong><a href="https://github.com/NVIDIA-Merlin/HugeCTR" target="_blank" rel="noopener noreferrer">HugeCTR<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></strong>：HugeCTR 是一个 <strong>GPU 加速的训练框架</strong>，可以通过跨多个 GPU 和节点分布训练来扩展大型深度学习推荐模型。 HugeCTR 包含具有 GPU 加速的优化数据加载器，并提供了将大型嵌入表扩展到可用内存之外的策略</p></li><li><p><strong><a href="https://github.com/NVIDIA-Merlin/models" target="_blank" rel="noopener noreferrer">Merlin Models<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></strong>：Merlin 模型库为推荐系统<strong>提供标准模型</strong>，旨在实现从经典机器学习模型到高度先进的深度学习模型的高质量实现</p></li><li><p><strong><a href="https://github.com/NVIDIA-Merlin/systems" target="_blank" rel="noopener noreferrer">Merlin Systems<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></strong>：Merlin Systems 提供的工具可将推荐模型与生产推荐系统的其他元素（如特征存储、最近邻搜索和探索策略）<strong>组合成端到端的推荐管道</strong>，这些管道可以通过 Triton 推理服务器提供服务</p></li><li><p><strong><a href="https://github.com/NVIDIA-Merlin/core" target="_blank" rel="noopener noreferrer">Merlin Core<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></strong>：Merlin Core 提供在整个 Merlin 生态系统中使用的功能</p></li><li><figure><img src="/assets/merlin_arch-DYuMNAo9.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li><li><figure><img src="/assets/merlin-Ckv9LWRS.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li></ul></li></ul><h2 id="_2-介绍" tabindex="-1"><a class="header-anchor" href="#_2-介绍"><span>2 介绍</span></a></h2><ul><li>HugeCTR是由NVIDIA发布开源的使用 CUDA C++ 编写<strong>专用于大型推荐系统模型使用GPU进行训练与推理的深度学习框架</strong>，利用了 GPU 加速库，例如<a href="https://developer.nvidia.com/cublas" target="_blank" rel="noopener noreferrer">cuBLAS<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>、<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>和<a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>，针对 NVIDIA GPU 的性能进行了高度优化，同时允许用户以 JSON 格式自定义模型</li></ul><h3 id="_2-1-特性-发布记录" tabindex="-1"><a class="header-anchor" href="#_2-1-特性-发布记录"><span>2.1 特性&amp;发布记录</span></a></h3><ul><li><p><strong>速度</strong>：单节点A100设备上可在1.7min内训练<a href="https://mlcommons.org/en/training-normal-20/" target="_blank" rel="noopener noreferrer">mlperf v2.0<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> DLRM</p></li><li><p><strong>规模</strong>：多节点模型并行、hierarchical解决方案</p></li><li><p><strong>使用</strong>：类似Keras的 Python API</p></li><li><p><strong>核心特征</strong>：使用GPU中的哈希表和动态插入实现分布式embedding、异步与多线程数据流水、分层参数服务器(HPS)做推理、Tensorflow embedding插件(SOK)</p></li><li><p>2019 v1.x 发布原型系统来展示网络训练加速效果</p></li><li><p>2020 v2.x 作为组件加入Merlin中，并获得了同年的<a href="https://mlcommons.org/en/training-normal-07/" target="_blank" rel="noopener noreferrer">mlperf v0.7<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> DLRM 8卡测试第一</p></li><li><p>2021 v3.x 支持使用hierarchical 参数服务器做推理，支持作为tensorflow插件使用其embedding方法</p></li><li><p>2022 v4.0 发布新的解耦embedding组件来支持其生态</p></li></ul><h3 id="_2-2-性能" tabindex="-1"><a class="header-anchor" href="#_2-2-性能"><span>2.2 性能</span></a></h3><ul><li><p><strong>HugeCTR vs Tensorflow</strong>：</p><ul><li><p>HugeCTR 在<strong>Criteo数据集</strong>（广告点击率数据集）上20-core Intel Xeon CPU E5-2698 v4 和 V100 16GB GPU 训练2X1024 FC layers WDL（Wide Deep Learning）的性能：在batchsize为512时相对Tensorflow-CPU实现了<strong>114倍</strong>加速，相对Tensorflow-GPU实现<strong>7.4倍</strong>加速</p></li><li><p><img src="/assets/perf_1-D6jLQ9sU.png" alt="img" loading="lazy"><img src="/assets/perf_2-Bnywqno2.png" alt="img" loading="lazy"></p></li><li><p>在<a href="https://hpc-wiki.info/hpc/Scaling" target="_blank" rel="noopener noreferrer">强伸缩<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>（也即问题规模不变，只有设备数量伸缩）下训练WDL的结果：</p><figure><img src="/assets/perf_3-BEQ3i99n.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li><li><p>HugeCTR 在Criteo数据集上20-core Intel Xeon CPU E5-2698 v4 和 V100 16GB GPU 训练2X1024 FC layers DCN （Deep Cross Network）的性能：在batchsize为512时相对Tensorflow-CPU实现了<strong>83倍</strong>加速，相对Tensorflow-GPU实现<strong>8.3倍</strong>加速</p></li><li><p><img src="/assets/perf_4-ByCIfvHr.png" alt="HugeCTR single GPU performance for DCN model." loading="lazy"><img src="/assets/perf_5-CXf9T4gf.png" alt="Training loss curves of the DCN model with HugeCTR and TensorFlow." loading="lazy"></p></li><li><p>在<a href="https://hpc-wiki.info/hpc/Scaling" target="_blank" rel="noopener noreferrer">强伸缩<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>（也即问题规模不变，只有设备数量伸缩）下训练DCN的结果：</p></li><li><figure><img src="/assets/perf_6-xam8gjK4.png" alt="Scalability of HugeCTR from 1 GPU to 8 GPUs (DCN)." tabindex="0" loading="lazy"><figcaption>Scalability of HugeCTR from 1 GPU to 8 GPUs (DCN).</figcaption></figure></li></ul></li><li><p><strong>HugeCTR vs Pytorch：</strong></p><ul><li><p>Criteo数据集1下对使用Pytorch 训练DLR做对比：</p></li><li><figure><img src="/assets/perf_10-Ch7g9rjt.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li><li><p>HugeCTR在 NVIDIA DGX A100 80GB 上使用TensorFlow嵌入插件，单卡达到<strong>7.9倍</strong>加速</p></li><li><figure><img src="/assets/perf_7-B22kve21.png" alt="HugeCTR TensorFlow plugin provides a 7.9x speedup over native TensorFlow 2.5 embedding lookup layer." tabindex="0" loading="lazy"><figcaption>HugeCTR TensorFlow plugin provides a 7.9x speedup over native TensorFlow 2.5 embedding lookup layer.</figcaption></figure></li><li><p>美团数据上 NVIDIA DGX A100 80GB 上的 HugeCTR TensorFlow 嵌入插件性能（<a href="https://hpc-wiki.info/hpc/Scaling" target="_blank" rel="noopener noreferrer">弱伸缩<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>，也即问题规模和设备规模同时伸缩），达到<strong>11.6倍</strong>加速</p></li><li><figure><img src="/assets/perf_8-BDAGQSbY.png" alt="On a real use case, HugeCTR TensorFlow plugin provides a 11.6x speedup over native TensorFlow 2.5 embedding lookup layer." tabindex="0" loading="lazy"><figcaption>On a real use case, HugeCTR TensorFlow plugin provides a 11.6x speedup over native TensorFlow 2.5 embedding lookup layer.</figcaption></figure></li></ul></li><li><p><strong>HugeCTR vs HugeCTR SOK</strong>：</p><ul><li>使用 MLPerf 的推荐领域标准模型 DLRM 来对 SOK 的性能进行测试,相比于 NVIDIA 的 DeepLearning Examples，使用 SOK 可以获得更快的训练速度以及更高的吞吐量</li><li><img src="/assets/perf_9-N8K3cVhK.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li><li><p><strong>MLPerf v2.0</strong>:</p><ul><li><table><thead><tr><th>ID</th><th>System</th><th>Processor</th><th>#</th><th>Accelerator</th><th>#</th><th>Software</th><th>DLRM</th></tr></thead><tbody><tr><td>2.0-2120</td><td>tpu-v4-256</td><td>AMD Rome</td><td>64</td><td>TPU-v4</td><td>128</td><td>Tensorflow</td><td>0.561</td></tr><tr><td>2.0-2098</td><td>dgxa100_n14_ngc22.04_merlin_hugectr</td><td>AMD EPYC 7742</td><td>28</td><td>NVIDIA A100-SXM-80GB</td><td>112</td><td>merlin_hugectr NVIDIA Release 22.04</td><td>0.588</td></tr><tr><td>2.0-2093</td><td>dgxa100_n8_ngc22.04_merlin_hugectr</td><td>AMD EPYC 7742</td><td>16</td><td>NVIDIA A100-SXM-80GB</td><td>64</td><td>merlin_hugectr NVIDIA Release 22.04</td><td>0.653</td></tr><tr><td>2.0-2068</td><td>NF5688M6</td><td>Intel(R) Xeon(R) Platinum 8358</td><td>2</td><td>NVIDIA A100-SXM-80GB CTS</td><td>8</td><td>hugectr</td><td>1.597</td></tr><tr><td>2.0-2064</td><td>NF5488A5</td><td>AMD EPYC 7713 64-Core Processor</td><td>2</td><td>NVIDIA A100-SXM-80GB CTS</td><td>8</td><td>hugectr</td><td>1.604</td></tr><tr><td>2.0-2060</td><td>R5500G5-Intelx8A100-SXM-80GB</td><td>Intel(R) Xeon(R) Platinum 8378A CPU @ 3.00GHz</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>8</td><td>NGC MXNet 22.04 , NGC PyTorch 22.04 , NGC TensorFlow 22.04-tf1</td><td>1.611</td></tr><tr><td>2.0-2038</td><td>PRIMERGY-GX2570M6-hugectr</td><td>Intel(R) Xeon (R) Platinum 8352V</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>8</td><td>Hugectr NVIDIA Release 22.04</td><td>1.628</td></tr><tr><td>2.0-2041</td><td>G492-ID0</td><td>Intel(R) Xeon(R) Platinum 8380</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>8</td><td>hugectr</td><td>1.637</td></tr><tr><td>2.0-2089</td><td>dgxa100_ngc22.04_merlin_hugectr</td><td>AMD EPYC 7742</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>8</td><td>merlin_hugectr NVIDIA Release 22.04</td><td>1.697</td></tr><tr><td>2.0-2116</td><td>SYS-420GP-TNAR</td><td>Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>8</td><td>Hugectr NVIDIA Release 22.04</td><td>1.729</td></tr><tr><td>2.0-2000</td><td>ND96amsr_A100_v4_n1</td><td>AMD EPYC 7V12 64-Core Processor</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>8</td><td>merlin_hugectr NVIDIA Release 22.04</td><td>1.849</td></tr><tr><td>2.0-2015</td><td>ESCN4A-E11</td><td>AMD EPYC 7773X</td><td>1</td><td>NVIDIA A100-SXM-80GB</td><td>4</td><td>NVIDIA Release 22.04 Tensorflow, MxNet, pytorch, hugectr</td><td>3.143</td></tr><tr><td>2.0-2058</td><td>R5300G5x4A100-SXM-80GB</td><td>Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz</td><td>2</td><td>NVIDIA A100-SXM-80GB</td><td>4</td><td>NGC MXNet 22.04 , NGC PyTorch 22.04 , NGC TensorFlow 22.04-tf1</td><td>3.144</td></tr><tr><td>2.0-2076</td><td>Lenovo ThinkSystem SR670 V2 Server with 4x 80GB SXM4 A100</td><td>Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz</td><td>2</td><td>NVIDIA A100-SXM-80GB CTS</td><td>4</td><td>NGC MXNet 20211013</td><td>3.303</td></tr><tr><td>2.0-2034</td><td>XE8545x4A100-SXM-80GB</td><td>AMD EPYC 7763 64-Core Processor</td><td>2</td><td>NVIDIA A100-SXM-80GB CTS</td><td>4</td><td>NGC MXNet 22.05 , NGC PyTorch 22.05 , NGC TensorFlow 22.05-tf1</td><td>4.309</td></tr><tr><td>2.0-2057</td><td>R5300G5x8A100-PCIE-80GB</td><td>Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz</td><td>2</td><td>NVIDIA A100-PCIe-80GB</td><td>8</td><td>NGC MXNet 22.04 , NGC PyTorch 22.04 , NGC TensorFlow 22.04-tf1</td><td>5.281</td></tr><tr><td>2.0-2086</td><td>X640G40_8xA30_hugectr</td><td>Intel(R) Xeon(R) Platinum 8380 CPU</td><td>2</td><td>NVIDIA A30</td><td>8</td><td>hugectr</td><td>5.468</td></tr></tbody></table></li></ul></li></ul><h3 id="_2-3-架构-模块设计" tabindex="-1"><a class="header-anchor" href="#_2-3-架构-模块设计"><span>2.3 架构&amp;模块设计</span></a></h3><figure><img src="/assets/arch-BBoVv9yT.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h4 id="_2-3-1-training" tabindex="-1"><a class="header-anchor" href="#_2-3-1-training"><span>2.3.1 Training</span></a></h4><ul><li><p><strong>CTR估计的DL模型</strong>(a)：</p><ul><li><p>分批读取包含高维、极其稀疏特征的数据</p></li><li><p>使用Embedding层压缩输入特征为低维、稠密的嵌入向量</p></li><li><p>使用前馈神经网络估计点击率</p></li></ul></li><li><figure><img src="/assets/dl_arch-SOhp_LLV.png" alt="The left figure (a) shows a typical CTR model including data reader, embedding, and a fully connected layer. The right figure (b) depicts the HugeCTR architecture extensible to multiple GPUs and nodes." tabindex="0" loading="lazy"><figcaption>The left figure (a) shows a typical CTR model including data reader, embedding, and a fully connected layer. The right figure (b) depicts the HugeCTR architecture extensible to multiple GPUs and nodes.</figcaption></figure></li><li><p><strong>HugeCTR结构</strong>（基于CTR DL模型）(b)：</p><ul><li><p>HugeCTR 利用数据和模型并行来扩展训练，并将一个嵌入表分布于多个 GPU 之上：</p><ul><li><p><strong>数据并行</strong>：作用于前馈神经网络部分，适用于当前流行的WDL、DCN、DeepFM、DLRM等</p></li><li><p><strong>模型并行</strong>：作用于embedding层，利用ETC模块及存储在GPU中的哈希表可支持单设备训练TB级模型</p></li></ul></li></ul></li><li><p><strong>Embedding Training Cache (ETC)</strong></p><ul><li><p><strong>特点</strong>:</p><ul><li>可重新或<strong>增量训练</strong>模型</li><li>解决单个GPU无法存放整个模型的问题（训练前预取嵌入表所需部分，i.e. <strong>hot-embedding</strong>）</li><li>实现<strong>模型并行</strong></li></ul></li><li><p><strong>概念</strong>:</p><ul><li><p><strong>pass</strong>：HugeCTR数据集被划分为多个文件，训练一组文件的过程称为一个pass，每个pass能够训练的embedding子集最大大小为所有GPU内存总和</p><figure><img src="/assets/etc_preprocessing-mOpc-m8S.png" alt="_images/etc_preprocessing.png" tabindex="0" loading="lazy"><figcaption>_images/etc_preprocessing.png</figcaption></figure></li><li><p><strong>keyset</strong>：从每个pass中提取的key集合，用于ETC预取所需embedding特征（分配对应大小内存）</p></li><li><p><strong>slot</strong>: 特征字段或表，同一关联特征的集合，一个slot中的特征可以是one-hot或multi-hot，不同slot中的特征不能有交集</p></li><li><p><strong>基于GPU的参数服务器</strong>：</p><ul><li><p>用于加载和管理嵌入表，对于超过 GPU 显存的嵌入表，参数服务器将嵌入表存储在 CPU 内存上。对于每个子数据集，将加载所需的嵌入向量并执行多个批量更新。之后，在参数服务器中同步模型参数。</p></li><li><figure><img src="/assets/ps_arch-C48T9JSV.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li></ul></li></ul></li><li><p><strong>Embedding</strong>:</p><ul><li><img src="/assets/image-20221028092530696-DHmfCFMg.png" alt="image-20221028092530696" tabindex="0" loading="lazy"><figcaption>image-20221028092530696</figcaption></li><li><img src="/assets/slot-DBVXc7I0.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></li><li>嵌入表可以分割成多个slot，在嵌入查找过程中，属于同一个slot的输入稀疏特征在独立转换为相应的密集嵌入向量后，被规约为单个嵌入向量。之后，不同slot的嵌入向量将拼接在一起（all-to-all）</li><li>HugeCTR支持三种embedding方式： <ul><li><strong>Localized slot embedding hash</strong>：所有属于同一slot的embedding存储在同一个GPU中，适用于单个slot恰好能存入GPU内存的情况，slot规约时无需做GPU间通信</li><li><strong>Distributed slot embedding hash</strong>：所有特征都分布式存储在不同GPU中，适用于单个slot embedding大于GPU内存的情况，但也因此需要更多的GPU间通信</li><li><strong>Hybrid sparse embedding</strong>：实现工业级性能推荐系统训练的关键技术，结合了数据与模型并行。 <ul><li><strong>数据并行</strong>：前向反向传播时，本地缓存用于加速高频embedding避免了GPU间通信</li><li><strong>模型并行</strong>：对于低频embedding，利用所有可用的GPU内存实现负载均衡存储embedding</li></ul></li></ul></li></ul></li><li><p><strong>训练过程</strong>：按顺序执行pass，每个pass先从PS载入embedding子集，进行训练，然后将训练好的嵌入表传回PS</p><figure><img src="/assets/etc_pipeline-YEaK0z47.png" alt="_images/etc_pipeline.png" tabindex="0" loading="lazy"><figcaption>_images/etc_pipeline.png</figcaption></figure></li><li><p><strong>Parameter Server</strong>：</p><ul><li><strong>Staged-PS</strong>：从SSD载入整个嵌入表到host内存中（支持分布式），整个ETC生命周期无需再次访问（高带宽低时延），训练完成后再存回SSD</li><li><strong>Cached-PS</strong>：host内存只缓存几个pass的嵌入表（克服内存对模型规模的限制）</li></ul></li><li><p><strong>异步和多线程的数据读取器</strong>：</p><ul><li>为了防止数据加载成为训练中的主要瓶颈，Hugectr实现了多线程数据读取器隐藏数据获取延时，worker用于并行读取一批训练数据，collector用于分发数据到多卡，worker、collector、model training都在不同的线程中运行</li><li><img src="/assets/data_load-DthrOkND.png" alt="This figure shows how four data readers read data from disk to host memory, and a collector reads one of them to feed the model training pipe." tabindex="0" loading="lazy"><figcaption>This figure shows how four data readers read data from disk to host memory, and a collector reads one of them to feed the model training pipe.</figcaption></li><li>除了多线程读取数据，还使用流水线来将不同batch的数据读取、分发与训练堆叠起来，进一步缩短数据加载耗时</li><li><img src="/assets/data_para-DpHzibxX.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li></ul></li></ul><h4 id="_2-3-2-inference" tabindex="-1"><a class="header-anchor" href="#_2-3-2-inference"><span>2.3.2 Inference</span></a></h4><ul><li><p><strong>Hierarchical Parameter Server (HPS)</strong>：</p><ul><li>用于解决推理时embedding受GPU内存大小的限制问题</li><li>引入<strong>GPU嵌入缓存数据结构</strong>将热嵌入存储在GPU内存中</li><li>缓存从参数服务器获取热嵌入，参数服务器存放整个嵌入表</li></ul></li><li><p><strong>存储结构</strong>：使用三级分层缓存，利用GPU内存、分布式CPU内存以及本地SSD存储，按照数据的使用频率，存储等级由低到高为SSD→ CPU内存→ GPU内存</p><ul><li><p><strong>Embedding inference cache (level 1)</strong>：使用<strong>GPU内存</strong>，动态缓存，优化的查询和操作运算符，以及动态插入和异步刷新机制，从而在在线推理期间保持高缓存命中率（利用数据局部性将常用特征（即热嵌入）保留在 GPU 内存中来减少额外/重复的参数移动）</p></li><li><p><strong>Volatile database (VDB; level 2)</strong>：使用<strong>CPU内存</strong>，当未命中GPU中参数时，在其中查询。相对于GPU内存扩展成本更低。可使用分布式Redis实例作为存储后端</p></li><li><p><strong>Persistent database (PDB; level 3)</strong>：使用<strong>SSD</strong>，保存所有模型参数，能够高效地存储长尾分布数据，提升预测精度。可使用RockDB作为存储后端</p><figure><img src="/assets/hps_2-DhB98c8C.png" alt="A high-level illustration of the Hierarchical Parameter Server architecture including the GPU embedding cache, a CPU memory layer, and a SSD layer." tabindex="0" loading="lazy"><figcaption>A high-level illustration of the Hierarchical Parameter Server architecture including the GPU embedding cache, a CPU memory layer, and a SSD layer.</figcaption></figure><figure><img src="/assets/image-20221025110729581-CGIjQKVz.png" alt="image-20221025110729581" tabindex="0" loading="lazy"><figcaption>image-20221025110729581</figcaption></figure><ol><li>管理消息流，获取更新应用与VDB和PDB</li><li>Dump GPU嵌入缓存的key值到CPU 对应缓冲区中</li><li>从CPU内存和SSD中查找缓冲区中的key</li><li>复制对应的embedding到CPU的Query KV Buffer中</li><li>GPU从缓冲区中读取数据与更新嵌入缓存</li></ol></li></ul></li><li><p><strong>GPU嵌入缓存数据结构</strong>：</p><ul><li><p><strong>slots</strong>：基本存储单元，每个包含一组嵌入键，相关嵌入向量和访问计数器</p></li><li><p><strong>slabs</strong>：将GPU warp线程数的slot打包为一个slab，warp中的每个线程负责一个slot，便可线性探测slabs，当发现了想要的key就可执行寄存器级的warp内通信（shuffle，ballot）来终止探测</p></li><li><p><strong>slabsets</strong>： 多个slabs组合为一个slabset，线性探测时可先定位Slabset再定位某个具体Slab，不同Slabset之间就可避免冲突，增大并行性。每个warp在插入和查询时独占整个slabset，保证线程安全，而整个slabset总数远大于warp数，即便是互斥操作也不会明显卡顿</p><figure><img src="/assets/image-20221025113529836-CGC1JiRL.png" alt="image-20221025113529836" tabindex="0" loading="lazy"><figcaption>image-20221025113529836</figcaption></figure></li></ul></li><li><p><strong>GPU嵌入缓存API</strong>：所有API都异步执行CUDA kernels，因此能同时执行</p><ul><li><p><strong>Query</strong>：检索对应key的嵌入向量，未命中的key以列表形式返回，后续在level 2 CPU内存中继续获取</p><figure><img src="/assets/image-20221025144004296-U3W2DqNe.png" alt="image-20221025144004296" tabindex="0" loading="lazy"><figcaption>image-20221025144004296</figcaption></figure></li><li><p><strong>Replace</strong>：即插入操作，若有空的slot，则插入embedding，若无，则遵从最近最少使用原则least recently used (LRU) 替换slot内的值</p><figure><img src="/assets/image-20221025144031116-34YQONVj.png" alt="image-20221025144031116" tabindex="0" loading="lazy"><figcaption>image-20221025144031116</figcaption></figure></li><li><p><strong>Update</strong>：确定待更新key和已缓存key的交集，再替换对应嵌入向量</p><figure><img src="/assets/image-20221025144057260-C_dcyXn4.png" alt="image-20221025144057260" tabindex="0" loading="lazy"><figcaption>image-20221025144057260</figcaption></figure></li><li><p><strong>Dump</strong>：输出当前在缓存中的keys</p></li></ul></li><li><p><strong>嵌入缓存插入</strong>：在GPU嵌入缓存中查找失败时，将触发level 2的CPU内存或level 3的SSD执行嵌入缓存插入操作</p><ul><li><p><strong>同步插入</strong>：缓存命中率低于定义的阈值时，阻塞其余部分，直到获取所需embedding（用于初始化和模型更新）</p></li><li><p><strong>异步插入</strong>：缓存命中率高于定义的阈值时，立即获取缺失值，而插入GPU缓存操作异步执行供未来使用，确保高命中率（惰性插入机制）</p><figure><img src="/assets/image-20221025150554697-CYWCX9Wp.png" alt="image-20221025150554697" tabindex="0" loading="lazy"><figcaption>image-20221025150554697</figcaption></figure></li></ul></li><li><p><strong>在线模型更新</strong>：</p><ul><li><figure><img src="/assets/image-20221025155124162-Bk6wCzel.png" alt="image-20221025155124162" tabindex="0" loading="lazy"><figcaption>image-20221025155124162</figcaption></figure><ul><li><!----><ul><li>因为这是模型的更新过程而不是embedding的查询过程，如果是像查询过程那样从PDB获取embedding来更新VDB，则还存在查询的开销，且负载都集中于PDB（既要自身更新，又要负载上层VDB的更新），相对于VDB，PDB相关操作速度更慢，所需时间开销更大</li></ul></li><li><p>CPU内存和SSD数据库更新：</p><ul><li><p>模型训练是资源密集型的，训练（<!---->）和推理（<!---->）使用不同节点进行，训练集被分为多个文件顺序加载到缓存中执行训练。</p></li><li><p>在线更新机制为辅助过程（<!---->），可随时启停，且更新过程无需停机，因此可实现持续性模型更新</p></li><li><p>当训练节点训练得到新的模型参数后，将会调用生产者API将更新dump到消息缓冲区（可使用Kafka实现），而推理节点可调用消费者API订阅消息队列获取更新（保证更新有序且完整，保证最终一致性）</p></li><li><p>在线更新会增加开销，但可通过lazy更新方式使用后台进程更新（可限制更新频率与获取速度），虽然lazy策略会带来模型更新过程中稍微不一致，但在实践中发现学习率在模型retraining过程中非常小，只要optimization足够平滑就不会带来预测性能下降。</p></li></ul></li><li><p>GPU嵌入缓存更新：</p><ul><li>不像VDB和PDB那样直接从Kafka获取更新，而是定期轮询VDB、PDB更新（直接从Kafka更新会产生难以预测的GPU负载峰值，可能缩短响应时间）</li></ul></li></ul></li></ul></li></ul><h4 id="_2-3-3-sparse-operation-kit-sok" tabindex="-1"><a class="header-anchor" href="#_2-3-3-sparse-operation-kit-sok"><span>2.3.3 Sparse Operation Kit (SOK)</span></a></h4><ul><li><p>用于提供HugeCTR对稀疏模型训练的GPU加速op的python包，能在tensorflow中使用，并能兼容horovod和tensorflow的分布式策略</p></li><li><p><strong>SOK训练的数据并行(DP)-模型并行(MP)-数据并行(DP)流程</strong>：</p><ul><li><figure><img src="/assets/sok_dp-B1BNhH0K.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li><li><p>输入调度(DP→ MP)</p><ul><li><p>将数据并行地输入，按照其求余 GPU 数量的结果，分配到了不同对应的 GPU 上，完成了 input key 从数据并行到模型并行的转化。虽然用户往每个 GPU 上输入的都可以是 embedding table 里的任何一个 key，但是经过上述的转化过程后，每个 GPU 上则只需要处理 embedding table 里 1/GPU_NUMBER 的 lookup</p></li><li><p>第一步：对每个 GPU 接收到的数据并行的 category key，按照 key 求余 GPU 的数量计算出其对应的 GPU ID，并分成和 GPU 数量相同的组；同时计算出每组内有多少 key。例如图 2 中，GPU 的总数为 2，GPU 0 获取的输入为[0, 1, 2, 3]，根据前面所讲的规则，它将会被分成[0, 2], [1, 3]两组。注意，在这一步，我们还会为每个分组产生一个 order 信息，用于 output dispacher 的重排序。</p></li><li><p>第二步：通过 NCCL 交换各个 GPU 上每组 key 的数量。由于每个 GPU 获取的输入，按照 key 求余 GPU 数量不一定能够均分，如图 3 所示，提前在各个 GPU 上交换 key 的总数，可以在后面交换 key 的时候减少通信量。</p></li><li><figure><img src="/assets/2-BXYdCSVd.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li><li><p>第三步：使用 NCCL，在各个 GPU 间按照 GPU ID 交换前面分好的各组 key<img src="/assets/3-1024x554-BrXsh39M.png" alt="" loading="lazy"></p></li><li><p>第四步：对交换后的所有 key 除以 GPU 总数，这一步是为了让每个 GPU 上的 key的数值范围都小于 embedding table size 整除 GPU 的数量，保证后续在每个 worker 上执行 lookup 时不会越界</p><figure><img src="/assets/4-1024x354-BMVcNniY.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure></li></ul></li><li><p>查表(Lookup)</p><ul><li>使用输入调度输出的key在本地嵌入表中查询对应的嵌入向量</li><li>图中 Global Index 代表每个 embedding vector 在实际的 embedding table 中对应的 key，而 Index 则是当前 GPU 的“部分”embedding table 中的 key</li><li><img src="/assets/5-1024x475-CPd23ID3.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li><li><p>输出调度(MP→ DP)</p><ul><li>将 embedding vector 按照和 input dispatcher 相同的路径、相反的方向将 embedding vector 返回给各个 GPU，让模型并行的 lookup 结果重新变成数据并行</li><li>第一步：复用 input dispatcher 中的分组信息，将 embedding vector 进行分组，如图 7 所示。</li><li><img src="/assets/6-1024x734-DdOXrBK2.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li><li>第二步：通过 NCCL 将 embedding vector 按 input dispatcher 的路径返还，如图 8 所示。</li><li><img src="/assets/7-1024x519-Bs3YUnsW.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li><li>第三步：复用 input dispatcher 第一步骤的结果，将 embedding vector 进行重排序，让其和输入的 key 顺序保持一致，如图 9 所示。</li><li><img src="/assets/8-1024x629-B6s7HCu8.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li><li>可以看到， GPU 0 上输入的[0, 1, 3, 5]，最终被转化为了[0.0, …], [0.1, …], [0.3, …], [0.5, …] 四个 embedding vector</li><li>虽然其中有 3 个 embedding vector 被存储在 GPU 1 上，但是以一种对用户透明的方式，在 GPU 0 上拿到了对应的 vector</li><li>在用户看来，就好像整个 embedding table 都存在 GPU 0 上一样</li></ul></li><li><p>Backword:</p><ul><li>与前向的工作流程和路径相同，需要做GPU之间的梯度交换，只是数据回传更新梯度的方向与前向相反</li></ul></li></ul></li><li><p><strong>使用Steps</strong>：</p><ul><li><strong>定义模型结构</strong>: 使用 SOK 来搭建模型的时候，只需要将 TensorFlow 中的 Embedding Layer 替换为 SOK 对应的 API 即可 <ul><li><img src="/assets/sok_1-CqPv4E70.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li><li><strong>使用 Horovod 来定义 training loop</strong>: 使用 SOK 时，只需要对 Embedding Variables 和 Dense Variables 进行分别处理即可, Embedding Variables 部分由 SOK 管理，Dense Variables 由 TensorFlow 管理 <ul><li><img src="/assets/sok_hvd-BljgkwuD.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li><li><strong>使用 tf.distribute.MirroredStrategy 来定义 training loop</strong>: <ul><li><img src="/assets/tf_dist-Ci9z5mR5.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li><li><strong>执行训练</strong>：使用 SOK 与使用 TensorFlow 时所用代码一致 <ul><li><img src="/assets/sok_train-BYMSdiwX.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></li></ul></li></ul></li></ul><h2 id="_3-安装hugectr" tabindex="-1"><a class="header-anchor" href="#_3-安装hugectr"><span>3 安装HugeCTR</span></a></h2><h3 id="_3-1-hugectr-api" tabindex="-1"><a class="header-anchor" href="#_3-1-hugectr-api"><span>3.1 HugeCTR API</span></a></h3><h4 id="_3-1-1-使用ngc容器" tabindex="-1"><a class="header-anchor" href="#_3-1-1-使用ngc容器"><span>3.1.1 使用NGC容器</span></a></h4><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code># 可根据需要挂载文件路径
# 此容器直接使用hugectr框架训练推理，未安装tensorflow等其他框架
docker run --name=&quot;hugectr-api&quot; -v /data:/data --shm-size &#39;64gb&#39; --gpus all -it -p 8888:8888 -p 8797:8787 -p 8796:8786 --ipc=host --cap-add SYS_NICE nvcr.io/nvidia/merlin/merlin-hugectr:nightly /bin/bash
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-1-2-使用源码" tabindex="-1"><a class="header-anchor" href="#_3-1-2-使用源码"><span>3.1.2 使用源码</span></a></h4><p>Pending</p><h3 id="_3-2-hugectr-sok" tabindex="-1"><a class="header-anchor" href="#_3-2-hugectr-sok"><span>3.2 HugeCTR SOK</span></a></h3><h4 id="_3-2-1-使用ngc容器-tf2" tabindex="-1"><a class="header-anchor" href="#_3-2-1-使用ngc容器-tf2"><span>3.2.1 使用NGC容器（tf2）</span></a></h4><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code># 容器中已安装SOK
docker run nvcr.io/nvidia/merlin/merlin-tensorflow-training:22.04
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-2-2-使用pip-tf1或2-目前tf1不推荐" tabindex="-1"><a class="header-anchor" href="#_3-2-2-使用pip-tf1或2-目前tf1不推荐"><span>3.2.2 使用pip（tf1或2， 目前tf1不推荐）</span></a></h4><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>pip install sparse_operation_kit
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="_3-2-3-使用源码" tabindex="-1"><a class="header-anchor" href="#_3-2-3-使用源码"><span>3.2.3 使用源码</span></a></h4><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>git clone https://github.com/NVIDIA-Merlin/HugeCTR.git
python setup.py install
python -c &quot;import sparse_operation_kit as sok&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><!---->：<ul><li><p>SOK从1.1.0开始支持tf1.15，对应HCTR 3.3</p></li><li><p>SOK基于tf1.15只支持结合horovod使用</p></li><li><p>可使用最新NVIDIA Tensorflow镜像安装SOK：（<!---->：也可参考<a href="https://github.com/NVIDIA-Merlin/Merlin/blob/main/docker/dockerfile.tf" target="_blank" rel="noopener noreferrer">Merlin Dockerfile<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>自定义镜像）</p></li><li><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow/tags </span>
<span class="token function">docker</span> run <span class="token parameter variable">-it</span> <span class="token parameter variable">--name</span><span class="token operator">=</span><span class="token string">&quot;sok-tf1.15&quot;</span> <span class="token parameter variable">--privileged</span> <span class="token parameter variable">--runtime</span><span class="token operator">=</span>nvidia <span class="token parameter variable">--net</span><span class="token operator">=</span>host <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token parameter variable">--ulimit</span> <span class="token assign-left variable">memlock</span><span class="token operator">=</span>-1 <span class="token parameter variable">--ulimit</span> <span class="token assign-left variable">stack</span><span class="token operator">=</span><span class="token number">67108864</span> <span class="token parameter variable">-v</span> /data:/data <span class="token parameter variable">-w</span> / nvcr.io/nvidia/tensorflow:22.10-tf1-py3 /bin/bash
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>基于此镜像只能用源码安装SOK，不能使用pip安装（用pip只能安装1.1.2版本，且会出现无法初始化问题）</li><li><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 升级cmake(至少3.17)</span>
<span class="token function">apt-get</span> autoremove cmake <span class="token operator">&amp;&amp;</span><span class="token punctuation">\</span>
<span class="token function">apt</span> <span class="token function">install</span> build-essential libssl-dev <span class="token operator">&amp;&amp;</span><span class="token punctuation">\</span>
<span class="token function">wget</span> https://cmake.org/files/v3.20/cmake-3.20.6-linux-x86_64.tar.gz <span class="token operator">&amp;&amp;</span><span class="token punctuation">\</span>
<span class="token function">tar</span> xf cmake-3.20.6-linux-x86_64.tar.gz <span class="token operator">&amp;&amp;</span><span class="token punctuation">\</span>
<span class="token function">mv</span> cmake-3.20.6-linux-x86_64 /opt/cmake-3.20.6 <span class="token operator">&amp;&amp;</span><span class="token punctuation">\</span>
<span class="token function">ln</span> <span class="token parameter variable">-sf</span> /opt/cmake-3.20.6/bin/* /usr/bin

<span class="token function">vim</span> ~/.bashrc
<span class="token comment"># 添加下面一行内容</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span>:/opt/cmake-3.20.6/bin
<span class="token builtin class-name">source</span> ~/.bashrc

<span class="token comment"># 安装相关依赖库</span>
pip <span class="token function">install</span> scikit-build <span class="token parameter variable">-i</span> https://pypi.tuna.tsinghua.edu.cn/simple

<span class="token comment"># 源码安装SOK</span>
<span class="token function">git</span> clone https://github.com/NVIDIA-Merlin/HugeCTR hugectr
<span class="token builtin class-name">cd</span> hugectr/sparse_operation_kit/
python setup.py <span class="token function">install</span>

<span class="token comment"># 复制so库到/usr/local/lib下（此镜像下源码安装的bug）</span>
<span class="token function">cp</span> ./_skbuild/linux-x86_64-3.8/cmake-install/sparse_operation_kit/lib/*.so /usr/local/lib/

<span class="token comment"># 测试安装情况</span>
python <span class="token parameter variable">-c</span> <span class="token string">&quot;import sparse_operation_kit as sok; print(sok.__version__)&quot;</span>

<span class="token comment"># 执行测例(多卡测试默认为8卡，可在unit_test/test_scripts/tf1/script.sh脚本中修改 ... -np &lt;gpu_number&gt; )</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span>,2,3,4,5,6,7
<span class="token function">bash</span> <span class="token punctuation">..</span>/unit_test/test_scripts/script.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li></ul></li></ul><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span><strong>参考资料：</strong></span></a></h1><h2 id="项目" tabindex="-1"><a class="header-anchor" href="#项目"><span><strong>项目</strong>：</span></a></h2><p><a href="https://github.com/NVIDIA-Merlin/HugeCTR" target="_blank" rel="noopener noreferrer">NVIDIA-Merlin/HugeCTR<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank" rel="noopener noreferrer">NVIDIA-Merlin/Merlin<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-hugectr" target="_blank" rel="noopener noreferrer">Merlin HugeCTR Containers<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="文档-paper" tabindex="-1"><a class="header-anchor" href="#文档-paper"><span><strong>文档 &amp; paper</strong>：</span></a></h2><p><a href="https://nvidia-merlin.github.io/HugeCTR/master/index.html" target="_blank" rel="noopener noreferrer">Merlin HugeCTR‘s documentation <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://nvidia-merlin.github.io/HugeCTR/sparse_operation_kit/master/index.html" target="_blank" rel="noopener noreferrer">SparseOperationKit’s documentation<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://dl.acm.org/doi/abs/10.1145/3523227.3547405" target="_blank" rel="noopener noreferrer">Merlin HugeCTR: GPU-accelerated Recommender System Training and Inference<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://dl.acm.org/doi/abs/10.1145/3523227.3546765" target="_blank" rel="noopener noreferrer">A GPU-specialized Inference Parameter Server for Large-Scale Deep Recommendation Models<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="blogs" tabindex="-1"><a class="header-anchor" href="#blogs"><span><strong>blogs</strong>：</span></a></h2><p><a href="https://blog.csdn.net/weixin_42717258/article/details/115643706" target="_blank" rel="noopener noreferrer">HugeCTR源码阅读<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>[<a href="https://www.cnblogs.com/rossiXYZ/p/15897877.html" target="_blank" rel="noopener noreferrer">源码解析] NVIDIA HugeCTR，GPU版本参数服务器<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/scaling-and-accelerating-large-deep-learning-recommender-systems-hugectr-series-part-1/" target="_blank" rel="noopener noreferrer">扩展和加速大型深度学习推荐系统 – HugeCTR 系列第 1 部分<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/training-large-deep-learning-recommender-models-with-merlin-hugectrs-python-apis-hugectr-series-part2/" target="_blank" rel="noopener noreferrer">使用 Merlin HugeCTR 的 Python API 训练大型深度学习推荐模型 – HugeCTR 系列第 2 部分<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/scaling-recommendation-system-inference-with-merlin-hierarchical-parameter-server/" target="_blank" rel="noopener noreferrer">使用 Merlin 分层参数服务器扩展推荐系统推理<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/merlin-hugectr-sparse-operation-kit-part-1/" target="_blank" rel="noopener noreferrer">Merlin HugeCTR Sparse Operation Kit 系列之一<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/merlin-hugectr-sparse-operation-kit-series-2/" target="_blank" rel="noopener noreferrer">Merlin HugeCTR Sparse Operation Kit 系列之二<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/merlin-hugectr-hierarchical-parameter-server-intro/" target="_blank" rel="noopener noreferrer">Merlin HugeCTR 分级参数服务器简介<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/merlin-hugectr-hierarchical-parameter-server-part2/" target="_blank" rel="noopener noreferrer">Merlin HugeCTR 分级参数服务器系列之二<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/blog/introducing-merlin-hugectr-training-framework-dedicated-to-recommender-systems/" target="_blank" rel="noopener noreferrer">Introducing NVIDIA Merlin HugeCTR: A Training Framework Dedicated to Recommender Systems<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/blog/using-neural-networks-for-your-recommender-system/" target="_blank" rel="noopener noreferrer">Using Neural Networks for Your Recommender System<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://www.infoq.cn/article/qeawcijqfrycqpueaqs4" target="_blank" rel="noopener noreferrer">从算法到工程，推荐系统全面总结<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://www.cnblogs.com/USTC-ZCC/p/11068791.html" target="_blank" rel="noopener noreferrer">嵌入(embedding)层的理解<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://www.cnblogs.com/futurehau/p/6181008.html" target="_blank" rel="noopener noreferrer">【项目】搜索广告CTR预估<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="性能数据来源" tabindex="-1"><a class="header-anchor" href="#性能数据来源"><span><strong>性能数据来源</strong>：</span></a></h2><p><a href="https://mp.weixin.qq.com/s/Oieuhvt2vzFEfKklTHiuOg" target="_blank" rel="noopener noreferrer">GPU 计算专家团队 | HugeCTR ：英伟达点击率预估训练框架原型开源 <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/zh-cn/blog/accelerating-embedding-with-the-hugectr-tensorflow-embedding-plugin/" target="_blank" rel="noopener noreferrer">使用 HugeCTR TensorFlow 嵌入插件加速嵌入<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://developer.nvidia.com/blog/introducing-merlin-hugectr-training-framework-dedicated-to-recommender-systems/" target="_blank" rel="noopener noreferrer">Introducing NVIDIA Merlin HugeCTR: A Training Framework Dedicated to Recommender Systems<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link nav-link prev" href="/blogs/distributed_embeddings_blog.html" aria-label="Distributed_embeddings"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->Distributed_embeddings</div></a><a class="route-link nav-link next" href="/blogs/hugectr_src_blog.html" aria-label="HugeCTR源码阅读笔记"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">HugeCTR源码阅读笔记<!----></div></a></nav><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">BradZhone's Blog</div><div class="vp-copyright">Copyright © 2024 BradZhone </div></footer></div><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-Coh1oo3x.js" defer></script>
  </body>
</html>
