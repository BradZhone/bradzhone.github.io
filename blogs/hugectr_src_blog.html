<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.9" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.32" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://bradzhone.github.io/blogs/hugectr_src_blog.html"><meta property="og:site_name" content="BradZhone's Blog"><meta property="og:title" content="HugeCTR源码阅读笔记"><meta property="og:description" content="HugeCTR源码阅读笔记 1. Data 深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例： 数值特征（numeric feature、dense feature）： 分类特征..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="BradZhone"><meta property="article:tag" content="CUDA"><meta property="article:tag" content="HugeCTR"><meta property="article:published_time" content="2023-10-25T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"HugeCTR源码阅读笔记","image":[""],"datePublished":"2023-10-25T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"BradZhone","url":"https://github.com/BradZhone"}]}</script><title>HugeCTR源码阅读笔记 | BradZhone's Blog</title><meta name="description" content="HugeCTR源码阅读笔记 1. Data 深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例： 数值特征（numeric feature、dense feature）： 分类特征...">
    <link rel="preload" href="/assets/style-BkjCpNEe.css" as="style"><link rel="stylesheet" href="/assets/style-BkjCpNEe.css">
    <link rel="modulepreload" href="/assets/app-Coh1oo3x.js"><link rel="modulepreload" href="/assets/hugectr_src_blog.html-d9qgPAFk.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/intro.html-D9dwEpHI.js" as="script"><link rel="prefetch" href="/assets/index.html-D5LnkeFh.js" as="script"><link rel="prefetch" href="/assets/CRNN_blog.html-Cb6b7OD4.js" as="script"><link rel="prefetch" href="/assets/cucollection_blog.html-DLix_uWp.js" as="script"><link rel="prefetch" href="/assets/cuda_blog.html-CBZ1Rex-.js" as="script"><link rel="prefetch" href="/assets/distributed_embeddings_blog.html-Cw7oBr-d.js" as="script"><link rel="prefetch" href="/assets/howToBuildThisBlog.html-Dxn0xRj3.js" as="script"><link rel="prefetch" href="/assets/hugectr_blog.html-BrFINEES.js" as="script"><link rel="prefetch" href="/assets/index.html-DI16Z1C4.js" as="script"><link rel="prefetch" href="/assets/torchrec_cn_embedding_note.html-YEVLbIAq.js" as="script"><link rel="prefetch" href="/assets/warpcore_blog.html-Cz_5IJvA.js" as="script"><link rel="prefetch" href="/assets/c___note.html-BYbhq9Nq.js" as="script"><link rel="prefetch" href="/assets/deep_learning.html-b-b3zdJE.js" as="script"><link rel="prefetch" href="/assets/linux_command.html-G4dNyKFL.js" as="script"><link rel="prefetch" href="/assets/LLM.html-9hu1pKVY.js" as="script"><link rel="prefetch" href="/assets/loss.html-CJxfnubw.js" as="script"><link rel="prefetch" href="/assets/markdown.html-DJcQDvEC.js" as="script"><link rel="prefetch" href="/assets/metrics.html-DKJGeFbq.js" as="script"><link rel="prefetch" href="/assets/PLAN_Z.html-B9yJBwFA.js" as="script"><link rel="prefetch" href="/assets/precision.html-B_dd_MdY.js" as="script"><link rel="prefetch" href="/assets/index.html-D1wTsZoY.js" as="script"><link rel="prefetch" href="/assets/torchrec_note.html-B-i_O6mg.js" as="script"><link rel="prefetch" href="/assets/uml_note.html-IaIR5y-b.js" as="script"><link rel="prefetch" href="/assets/index.html-Cgwhpoct.js" as="script"><link rel="prefetch" href="/assets/404.html-DYVdKbdY.js" as="script"><link rel="prefetch" href="/assets/index.html-1jQ9-Uww.js" as="script"><link rel="prefetch" href="/assets/index.html-BEDqx9YQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BltlhrdK.js" as="script"><link rel="prefetch" href="/assets/index.html-C0yITs6x.js" as="script"><link rel="prefetch" href="/assets/index.html-maJbTduo.js" as="script"><link rel="prefetch" href="/assets/index.html-BPQ9UPx_.js" as="script"><link rel="prefetch" href="/assets/index.html-BQB6pLKG.js" as="script"><link rel="prefetch" href="/assets/index.html-Be8HnZrW.js" as="script"><link rel="prefetch" href="/assets/index.html-DzX6xTUq.js" as="script"><link rel="prefetch" href="/assets/index.html-BxZ6QV-X.js" as="script"><link rel="prefetch" href="/assets/index.html-Dl0UMf-I.js" as="script"><link rel="prefetch" href="/assets/index.html-xBRd_OsE.js" as="script"><link rel="prefetch" href="/assets/index.html-BTkUZ9Ws.js" as="script"><link rel="prefetch" href="/assets/index.html-D57wSldI.js" as="script"><link rel="prefetch" href="/assets/index.html-Dqr1foaP.js" as="script"><link rel="prefetch" href="/assets/index.html-CSGzSmAq.js" as="script"><link rel="prefetch" href="/assets/index.html-BnBAmG4V.js" as="script"><link rel="prefetch" href="/assets/index.html-d2G8e39M.js" as="script"><link rel="prefetch" href="/assets/index.html-CpCodvQl.js" as="script"><link rel="prefetch" href="/assets/index.html-hEB5WJuD.js" as="script"><link rel="prefetch" href="/assets/index.html-DX2Ijbyk.js" as="script"><link rel="prefetch" href="/assets/index.html-Da6Vp1bl.js" as="script"><link rel="prefetch" href="/assets/index.html-CGr0tdaC.js" as="script"><link rel="prefetch" href="/assets/index.html-D5fEOhj5.js" as="script"><link rel="prefetch" href="/assets/index.html-C1vK6J6C.js" as="script"><link rel="prefetch" href="/assets/index.html-DgD_mq8U.js" as="script"><link rel="prefetch" href="/assets/index.html-Demc7CPi.js" as="script"><link rel="prefetch" href="/assets/index.html-D31kcDwM.js" as="script"><link rel="prefetch" href="/assets/index.html-COTqqkDG.js" as="script"><link rel="prefetch" href="/assets/index.html-DtZDr4LJ.js" as="script"><link rel="prefetch" href="/assets/index.html-BYDcpP-H.js" as="script"><link rel="prefetch" href="/assets/index.html-QpKn8zOy.js" as="script"><link rel="prefetch" href="/assets/index.html-Fd1nQRc_.js" as="script"><link rel="prefetch" href="/assets/index.html-BEVLRn0k.js" as="script"><link rel="prefetch" href="/assets/giscus-7BMGhbDA.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo light" src="/light.png" alt><img class="vp-nav-logo dark" src="/dark.png" alt><span class="vp-site-name hide-in-pad">BradZhone&#39;s Blog</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/" aria-label="Home"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>Home<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link active" href="/blogs/" aria-label="Blogs"><span class="font-icon icon fa-fw fa-sm fas fa-blog" style=""></span>Blogs<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/notes/" aria-label="Notes"><span class="font-icon icon fa-fw fa-sm fas fa-note-sticky" style=""></span>Notes<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/thinking/" aria-label="Thinking"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span>Thinking<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/intro.html" aria-label="About Me"><span class="font-icon icon fa-fw fa-sm fas fa-star" style=""></span>About Me<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><!----><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable active"><span class="font-icon icon fa-fw fa-sm fas fa-blog" style=""></span><a class="route-link nav-link active vp-sidebar-title" href="/blogs/" aria-label="Blogs"><!---->Blogs<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/howToBuildThisBlog.html" aria-label="如何搭建本博客"><!---->如何搭建本博客<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/CRNN_blog.html" aria-label="CRNN网络调研适配记录"><!---->CRNN网络调研适配记录<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/cucollection_blog.html" aria-label="cuCollections性能测试"><!---->cuCollections性能测试<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/cuda_blog.html" aria-label="CUDA学习笔记"><!---->CUDA学习笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/distributed_embeddings_blog.html" aria-label="Distributed_embeddings"><!---->Distributed_embeddings<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/hugectr_blog.html" aria-label="HugeCTR 学习笔记"><!---->HugeCTR 学习笔记<!----></a></li><li><a class="route-link nav-link active vp-sidebar-link vp-sidebar-page active" href="/blogs/hugectr_src_blog.html" aria-label="HugeCTR源码阅读笔记"><!---->HugeCTR源码阅读笔记<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/torchrec_cn_embedding_note.html" aria-label="torchrec cn_embedding模块设计方案"><!---->torchrec cn_embedding模块设计方案<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/blogs/warpcore_blog.html" aria-label="WARPCORE 学习笔记"><!---->WARPCORE 学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-note-sticky" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/notes/" aria-label="Notes"><!---->Notes<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/c___note.html" aria-label="C++ note"><!---->C++ note<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/deep_learning.html" aria-label="DL相关"><!---->DL相关<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/precision.html" aria-label="Floating Point precision formats"><!---->Floating Point precision formats<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/linux_command.html" aria-label="Linux 快捷指令"><!---->Linux 快捷指令<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/LLM.html" aria-label="LLM"><!---->LLM<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/loss.html" aria-label="Loss 相关问题"><!---->Loss 相关问题<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/markdown.html" aria-label="Markdown 语法"><!---->Markdown 语法<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/metrics.html" aria-label="Metrics"><!---->Metrics<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/PLAN_Z.html" aria-label="TODO LIST"><!---->TODO LIST<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/torchrec_note.html" aria-label="Torchrec调研"><!---->Torchrec调研<!----></a></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/notes/uml_note.html" aria-label="UML学习笔记"><!---->UML学习笔记<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon fa-fw fa-sm fas fa-lightbulb" style=""></span><a class="route-link nav-link vp-sidebar-title" href="/thinking/" aria-label="Thinking"><!---->Thinking<!----></a><!----></p><ul class="vp-sidebar-links"></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->HugeCTR源码阅读笔记</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/BradZhone" target="_blank" rel="noopener noreferrer">BradZhone</a></span><span property="author" content="BradZhone"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-10-25T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 13 分钟</span><meta property="timeRequired" content="PT13M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category8 clickable" role="navigation">推荐系统</span><!--]--><meta property="articleSection" content="推荐系统"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag4 clickable" role="navigation">CUDA</span><span class="page-tag-item tag8 clickable" role="navigation">HugeCTR</span><!--]--><meta property="keywords" content="CUDA,HugeCTR"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!--[--><!----><!--]--><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-data">1. Data</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-hashing">2. Hashing</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-embedding">3. Embedding</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_4-other">4. Other</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_5-sok">5. SOK</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="hugectr源码阅读笔记" tabindex="-1"><a class="header-anchor" href="#hugectr源码阅读笔记"><span>HugeCTR源码阅读笔记</span></a></h1><h2 id="_1-data" tabindex="-1"><a class="header-anchor" href="#_1-data"><span>1. Data</span></a></h2><ul><li><p>深度推荐模型的输入特征可分为数值特征和分类特征，数值特征是一组连续值，而分类特征是离散值，以HugeCTR按照Criteo点击率数据格式（每个数据sample包括14个数值特征和26个分类特征，总共40个特征）合成的数据为例：</p></li><li><p><strong>数值特征</strong>（numeric feature、dense feature）：</p><ul><li><table><thead><tr><th></th><th>_col0</th><th>_col1</th><th>_col2</th><th>_col3</th><th>_col4</th><th>_col5</th><th>_col6</th></tr></thead><tbody><tr><td>0</td><td>0.080380</td><td>0.435741</td><td>0.078185</td><td>0.194161</td><td>0.087724</td><td>0.845081</td><td>0.937019</td></tr><tr><td>1</td><td>0.310647</td><td>0.669963</td><td>0.218886</td><td>0.945537</td><td>0.735421</td><td>0.637027</td><td>0.007011</td></tr><tr><td>2</td><td>0.337267</td><td>0.908792</td><td>0.795987</td><td>0.608301</td><td>0.290421</td><td>0.012273</td><td>0.671650</td></tr><tr><td>3</td><td>0.873908</td><td>0.694296</td><td>0.796788</td><td>0.553089</td><td>0.872149</td><td>0.502299</td><td>0.114150</td></tr><tr><td>4</td><td>0.333109</td><td>0.456773</td><td>0.403027</td><td>0.091778</td><td>0.215718</td><td>0.729457</td><td>0.941204</td></tr></tbody></table></li><li><table><thead><tr><th></th><th>_col7</th><th>_col8</th><th>_col9</th><th>_col10</th><th>_col11</th><th>_col12</th><th>_col13</th></tr></thead><tbody><tr><td>0</td><td>0.977882</td><td>0.042342</td><td>0.054632</td><td>0.855919</td><td>0.264451</td><td>0.224891</td><td>0.467242</td></tr><tr><td>1</td><td>0.204856</td><td>0.307856</td><td>0.775143</td><td>0.265654</td><td>0.301945</td><td>0.066413</td><td>0.499416</td></tr><tr><td>2</td><td>0.960113</td><td>0.018073</td><td>0.639101</td><td>0.229013</td><td>0.645756</td><td>0.123180</td><td>0.894010</td></tr><tr><td>3</td><td>0.444433</td><td>0.001794</td><td>0.147979</td><td>0.083302</td><td>0.744487</td><td>0.971924</td><td>0.362019</td></tr><tr><td>4</td><td>0.997079</td><td>0.563684</td><td>0.811862</td><td>0.457039</td><td>0.133213</td><td>0.169442</td><td>0.124149</td></tr></tbody></table></li></ul></li><li><p><strong>分类特征</strong>（sparse feature、category feature）：</p><ul><li><table><thead><tr><th></th><th>_col14</th><th>_col15</th><th>_col16</th><th>_col17</th><th>_col18</th><th>_col19</th><th>_col20</th><th>_col21</th><th>_col22</th></tr></thead><tbody><tr><td>0</td><td>151</td><td>0</td><td>9</td><td>13</td><td>1</td><td>1</td><td>1</td><td>9</td><td>4</td></tr><tr><td>1</td><td>0</td><td>0</td><td>11</td><td>4801</td><td>44</td><td>2</td><td>160</td><td>9</td><td>0</td></tr><tr><td>2</td><td>4549</td><td>3</td><td>1</td><td>10</td><td>31</td><td>2</td><td>485</td><td>2</td><td>10</td></tr><tr><td>3</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>3</td><td>111</td><td>10</td></tr><tr><td>4</td><td>2</td><td>5</td><td>160</td><td>0</td><td>72</td><td>0</td><td>13</td><td>53</td><td>0</td></tr></tbody></table></li><li><table><thead><tr><th></th><th>_col23</th><th>_col24</th><th>_col25</th><th>_col26</th><th>_col27</th><th>_col28</th><th>_col29</th><th>_col30</th><th>_col31</th></tr></thead><tbody><tr><td>0</td><td>2</td><td>395</td><td>41</td><td>1</td><td>14</td><td>5</td><td>2</td><td>7</td><td>0</td></tr><tr><td>1</td><td>101</td><td>3</td><td>1</td><td>1</td><td>4</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>2</td><td>2</td><td>19</td><td>6</td><td>6</td><td>1</td><td>0</td><td>4</td><td>1</td><td>2</td></tr><tr><td>3</td><td>1</td><td>2</td><td>38</td><td>6</td><td>1</td><td>7</td><td>1</td><td>2</td><td>0</td></tr><tr><td>4</td><td>63</td><td>616</td><td>7</td><td>1</td><td>175</td><td>23</td><td>4</td><td>0</td><td>1</td></tr></tbody></table></li><li><table><thead><tr><th></th><th>_col32</th><th>_col33</th><th>_col34</th><th>_col35</th><th>_col36</th><th>_col37</th><th>_col38</th><th>_col39</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>1</td><td>5283</td><td>4</td><td>0</td><td>21</td><td>33</td><td>1</td></tr><tr><td>1</td><td>2</td><td>3</td><td>204</td><td>310</td><td>1640</td><td>6</td><td>4</td><td>6</td></tr><tr><td>2</td><td>4</td><td>7</td><td>29</td><td>2</td><td>11</td><td>66</td><td>2</td><td>22</td></tr><tr><td>3</td><td>9</td><td>43</td><td>2</td><td>10</td><td>286</td><td>6</td><td>2</td><td>0</td></tr><tr><td>4</td><td>0</td><td>477</td><td>10</td><td>6</td><td>0</td><td>2</td><td>0</td><td>30</td></tr></tbody></table></li></ul></li><li><p>数据相关属性：</p><ul><li><p>以生成模拟数据为例：</p><ul><li><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># generate_data.py</span>

<span class="token keyword">import</span> hugectr
<span class="token keyword">from</span> hugectr<span class="token punctuation">.</span>tools <span class="token keyword">import</span> DataGenerator<span class="token punctuation">,</span> DataGeneratorParams
<span class="token keyword">from</span> mpi4py <span class="token keyword">import</span> MPI
<span class="token keyword">import</span> argparse
parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">&quot;Data Generation&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&quot;--num_files&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;number of files in training data&quot;</span><span class="token punctuation">,</span> default <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&quot;--eval_num_files&quot;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;number of files in validation data&quot;</span><span class="token punctuation">,</span> default <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&#39;--num_samples_per_file&#39;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;number of samples per file&quot;</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1000000</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">&#39;--dir_name&#39;</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">&quot;data directory name(Required)&quot;</span><span class="token punctuation">)</span>
args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

data_generator_params <span class="token operator">=</span> DataGeneratorParams<span class="token punctuation">(</span>
  <span class="token builtin">format</span> <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>DataReaderType_t<span class="token punctuation">.</span>Parquet<span class="token punctuation">,</span>
  label_dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
  dense_dim <span class="token operator">=</span> <span class="token number">13</span><span class="token punctuation">,</span>
  num_slot <span class="token operator">=</span> <span class="token number">26</span><span class="token punctuation">,</span>
  num_files <span class="token operator">=</span> args<span class="token punctuation">.</span>num_files<span class="token punctuation">,</span>
  eval_num_files <span class="token operator">=</span> args<span class="token punctuation">.</span>eval_num_files<span class="token punctuation">,</span>
  i64_input_key <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
  num_samples_per_file <span class="token operator">=</span> args<span class="token punctuation">.</span>num_samples_per_file<span class="token punctuation">,</span>
  source <span class="token operator">=</span> <span class="token string">&quot;./etc_data/&quot;</span> <span class="token operator">+</span> args<span class="token punctuation">.</span>dir_name <span class="token operator">+</span> <span class="token string">&quot;/file_list.txt&quot;</span><span class="token punctuation">,</span>
  eval_source <span class="token operator">=</span> <span class="token string">&quot;./etc_data/&quot;</span> <span class="token operator">+</span> args<span class="token punctuation">.</span>dir_name <span class="token operator">+</span> <span class="token string">&quot;/file_list_test.txt&quot;</span><span class="token punctuation">,</span>
  slot_size_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">12988</span><span class="token punctuation">,</span> <span class="token number">7129</span><span class="token punctuation">,</span> <span class="token number">8720</span><span class="token punctuation">,</span> <span class="token number">5820</span><span class="token punctuation">,</span> <span class="token number">15196</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4914</span><span class="token punctuation">,</span> <span class="token number">1020</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">14274</span><span class="token punctuation">,</span> <span class="token number">10220</span><span class="token punctuation">,</span> <span class="token number">15088</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1518</span><span class="token punctuation">,</span> <span class="token number">3672</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">820</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">12817</span><span class="token punctuation">,</span> <span class="token number">13908</span><span class="token punctuation">,</span> <span class="token number">13447</span><span class="token punctuation">,</span> <span class="token number">9447</span><span class="token punctuation">,</span> <span class="token number">5867</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  nnz_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token comment"># for parquet, check_type doesn&#39;t make any difference</span>
  check_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>Check_t<span class="token punctuation">.</span>Non<span class="token punctuation">,</span>
  dist_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>Distribution_t<span class="token punctuation">.</span>PowerLaw<span class="token punctuation">,</span>
  power_law_type <span class="token operator">=</span> hugectr<span class="token punctuation">.</span>PowerLaw_t<span class="token punctuation">.</span>Short<span class="token punctuation">)</span>
data_generator <span class="token operator">=</span> DataGenerator<span class="token punctuation">(</span>data_generator_params<span class="token punctuation">)</span>
data_generator<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>num_files：即数据集分为几个子集，也是使用ETC训练时每一个pass所用到的数据，子集数等于训练所需pass数</p></li><li><p>num_samples_per_file：也即每个子数据集的样本数</p></li><li><p>label_dim：每一个sample的标签维度</p></li><li><p>dense_dim：连续特征的数量</p></li><li><p>num_slot：分类特征的数量，也即slot数（特征域数量）</p></li><li><p>slot_size_array：每一个slot中的最大特征数量（也就是特征域的大小）</p></li><li><p>nnz_array： 样本在对应的slot (特征域)中最多可同时有几个特征（用于选择是one-hot还是multi-hot）</p></li></ul></li><li><p>执行脚本生成模拟数据（总共产生8个训练数据子集和2个测试子集）：</p><ul><li><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>python generate_data<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>dir_name <span class="token string">&quot;file0&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: Generate Parquet dataset
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: train data folder: ./etc_data/file0, <span class="token builtin class-name">eval</span> data folder: ./etc_data/file0, slot_size_array: <span class="token number">12988</span>, <span class="token number">7129</span>, <span class="token number">8720</span>, <span class="token number">5820</span>, <span class="token number">15196</span>, <span class="token number">4</span>, <span class="token number">4914</span>, <span class="token number">1020</span>, <span class="token number">30</span>, <span class="token number">14274</span>, <span class="token number">10220</span>, <span class="token number">15088</span>, <span class="token number">10</span>, <span class="token number">1518</span>, <span class="token number">3672</span>, <span class="token number">48</span>, <span class="token number">4</span>, <span class="token number">820</span>, <span class="token number">15</span>, <span class="token number">12817</span>, <span class="token number">13908</span>, <span class="token number">13447</span>, <span class="token number">9447</span>, <span class="token number">5867</span>, <span class="token number">45</span>, <span class="token number">33</span>, nnz array: <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token comment">#files for train: 8, #files for eval: 2, #samples per file: 1000000, Use power law distribution: 1, alpha of power law: 1.3</span>
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0 exist
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:28.823<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_0.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:33.757<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_1.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:36.560<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_2.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:39.337<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_3.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:42.083<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_4.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:44.807<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_5.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:47.641<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_6.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:50.377<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/train/gen_7.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:53.131<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/file_list.txt done<span class="token operator">!</span>
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:53.132<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/val/gen_0.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:55.941<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/val/gen_1.parquet
<span class="token punctuation">[</span>HCTR<span class="token punctuation">]</span><span class="token punctuation">[</span>03:28:58.788<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span><span class="token punctuation">[</span>RK0<span class="token punctuation">]</span><span class="token punctuation">[</span>main<span class="token punctuation">]</span>: ./etc_data/file0/file_list_test.txt done<span class="token operator">!</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>输出keysets（以gen_0为例）：</p><ul><li><p>每一个子数据集（每个pass用的数据集）会生成一个keysets，所有数据的keysets构成一个更大的集合all_keysets，最终将根据all_keysets生成keysets文件xxx.keyset供GPU在t时刻预读取t+1时刻的数据到ETC中</p></li><li><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>  ------------------------
  unique_keys:
  <span class="token number">0</span>            <span class="token number">0</span>
  <span class="token number">1</span>            <span class="token number">1</span>
  <span class="token number">2</span>            <span class="token number">2</span>
  <span class="token number">3</span>            <span class="token number">3</span>
  <span class="token number">4</span>            <span class="token number">4</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">12115</span>    <span class="token number">12978</span>
  <span class="token number">12116</span>    <span class="token number">12979</span>
  <span class="token number">12117</span>    <span class="token number">12981</span>
  <span class="token number">12118</span>    <span class="token number">12983</span>
  <span class="token number">12119</span>    <span class="token number">12986</span>
  Name: _col14, Length: <span class="token number">12120</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">12988</span>
  <span class="token number">1</span>       <span class="token number">12989</span>
  <span class="token number">2</span>       <span class="token number">12990</span>
  <span class="token number">3</span>       <span class="token number">12991</span>
  <span class="token number">4</span>       <span class="token number">12992</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">7077</span>    <span class="token number">20111</span>
  <span class="token number">7078</span>    <span class="token number">20112</span>
  <span class="token number">7079</span>    <span class="token number">20113</span>
  <span class="token number">7080</span>    <span class="token number">20114</span>
  <span class="token number">7081</span>    <span class="token number">20116</span>
  Name: _col15, Length: <span class="token number">7082</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">20117</span>
  <span class="token number">1</span>       <span class="token number">20118</span>
  <span class="token number">2</span>       <span class="token number">20119</span>
  <span class="token number">3</span>       <span class="token number">20120</span>
  <span class="token number">4</span>       <span class="token number">20121</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">8554</span>    <span class="token number">28827</span>
  <span class="token number">8555</span>    <span class="token number">28828</span>
  <span class="token number">8556</span>    <span class="token number">28830</span>
  <span class="token number">8557</span>    <span class="token number">28831</span>
  <span class="token number">8558</span>    <span class="token number">28834</span>
  Name: _col16, Length: <span class="token number">8559</span>, dtype: int64
  ------------------------
  unique_keys:
  <span class="token number">0</span>       <span class="token number">28837</span>
  <span class="token number">1</span>       <span class="token number">28838</span>
  <span class="token number">2</span>       <span class="token number">28839</span>
  <span class="token number">3</span>       <span class="token number">28840</span>
  <span class="token number">4</span>       <span class="token number">28841</span>
          <span class="token punctuation">..</span>.  
  <span class="token number">5798</span>    <span class="token number">34652</span>
  <span class="token number">5799</span>    <span class="token number">34653</span>
  <span class="token number">5800</span>    <span class="token number">34654</span>
  <span class="token number">5801</span>    <span class="token number">34655</span>
  <span class="token number">5802</span>    <span class="token number">34656</span>
  Name: _col17, Length: <span class="token number">5803</span>, dtype: int64
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li></ul></li></ul></li><li><p>使用ETC分pass训练示例(与上例不同，此例使用10个pass来训练)：</p><ul><li><table><thead><tr><th style="text-align:right;">Pass ID</th><th style="text-align:right;">Number of Unique Keys</th><th style="text-align:right;">Embedding size (GB)</th></tr></thead><tbody><tr><td style="text-align:right;">#0</td><td style="text-align:right;">24199179</td><td style="text-align:right;">11.54</td></tr><tr><td style="text-align:right;">#1</td><td style="text-align:right;">26015075</td><td style="text-align:right;">12.40</td></tr><tr><td style="text-align:right;">#2</td><td style="text-align:right;">27387817</td><td style="text-align:right;">13.06</td></tr><tr><td style="text-align:right;">#3</td><td style="text-align:right;">23672542</td><td style="text-align:right;">11.29</td></tr><tr><td style="text-align:right;">#4</td><td style="text-align:right;">26053910</td><td style="text-align:right;">12.42</td></tr><tr><td style="text-align:right;">#5</td><td style="text-align:right;">27697628</td><td style="text-align:right;">13.21</td></tr><tr><td style="text-align:right;">#6</td><td style="text-align:right;">24727672</td><td style="text-align:right;">11.79</td></tr><tr><td style="text-align:right;">#7</td><td style="text-align:right;">25643779</td><td style="text-align:right;">12.23</td></tr><tr><td style="text-align:right;">#8</td><td style="text-align:right;">26374086</td><td style="text-align:right;">12.58</td></tr><tr><td style="text-align:right;">#9</td><td style="text-align:right;">26580983</td><td style="text-align:right;">12.67</td></tr></tbody></table></li></ul></li><li><p>数据预处理时，HugeCTR将分类特征转换为整型序列的方法：</p><ul><li><p>使用NVTabular：</p></li><li><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># e.g. using NVTabular</span>

target_encode <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token string">&#39;brand&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;user_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;product_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;cat_2&#39;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&#39;ts_weekday&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;ts_day&#39;</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span>
    nvt<span class="token punctuation">.</span>ops<span class="token punctuation">.</span>TargetEncoding<span class="token punctuation">(</span>
        nvt<span class="token punctuation">.</span>ColumnGroup<span class="token punctuation">(</span><span class="token string">&#39;target&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        kfold<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
        p_smooth<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
        out_dtype<span class="token operator">=</span><span class="token string">&quot;float32&quot;</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><blockquote><p>https://nvidia-merlin.github.io/NVTabular/v0.7.1/api/ops/targetencoding.html</p><p>Target encoding is a common feature-engineering technique for categorical columns in tabular datasets. For each categorical group, the mean of a continuous target column is calculated, and the group-specific mean of each row is used to create a new feature (column). To prevent overfitting, the following additional logic is applied:</p><blockquote><ol><li><p>Cross Validation: To prevent overfitting in training data, a cross-validation strategy is used - The data is split into k random “folds”, and the mean values within the i-th fold are calculated with data from all other folds. The cross-validation strategy is only employed when the dataset is used to update recorded statistics. For transformation-only workflow execution, global-mean statistics are used instead.</p></li><li><p>Smoothing: To prevent overfitting for low cardinality categories, the means are smoothed with the overall mean of the target variable.</p></li></ol></blockquote></blockquote></li></ul></li></ul><h2 id="_2-hashing" tabindex="-1"><a class="header-anchor" href="#_2-hashing"><span>2. Hashing</span></a></h2><ul><li><!----><ul><li>存储hashtable和embedding的数据结构是什么？</li><li>为什么使用hash可以节省空间??</li><li>是每一个分类特征对应一个hashtable吗？（但是示例合成数据里面的key都是全局的key，而不是分特征从0开始累计的）</li></ul></li><li><p>relevant:</p><ul><li>&lt;thrust/pairs.h&gt; : 用于封装异构元素对（实现k-v）</li></ul></li><li><p>为什么用hashing （参考：<a href="https://cloud.tencent.com/developer/article/1871846" target="_blank" rel="noopener noreferrer">Deep Hash Embedding<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>）</p><ul><li>用于压缩embedding（将n维one-hot特征编码为m维one-hot特征，且m&lt;n）：如果不用hash，使用one-hot full embedding 的方式，则embedding将会非常庞大，因为许多低频特征也将占据大量embedding空间</li><li>当出现新特征时可动态扩容embedding</li></ul></li><li><p>什么hash函数（non-cryptographic hash function）</p><ul><li>Identity hash function：当数据足够小的时候（如key小于int64时）可以直接将数据作为hash value。也即直接将分类特征的key作为value用于查embedding？</li><li><a href="https://github.com/aappleby/smhasher/blob/master/src/MurmurHash3.cpp" target="_blank" rel="noopener noreferrer">murmurhash function<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></li><li><p>如何查（怎么分布式）</p><ul><li><p>每一个GPU上存放着不同slot对应的hashtable，用于压缩embedding matrix，在进行数据并行，每个GPU获得输入数据后，先做all-to-all将需要查询的数据对应特征传输到存储其特征域（slot）embedding的GPU上，再在对应GPU上查表（lookup）得到embedding vector，再使用all-to-all返回查询结果到原来的GPU中，每个GPU再通过寄存器合并不同特征域的embedding作为最终输入前馈网络的数据<img src="/assets/image-20221108171540235-2ioNMG-d.png" alt="image-20221108171540235" loading="lazy"></p></li><li><p>embedding前的输入数据为64位int哈希值，只有训练数据出现新的key而hashtable找不到时才在运行时插入一对k-v:</p></li><li><blockquote><p>Embedding initialization is not required before training takes place since the input training data are hash values (64-bit signed integer type) instead of original indices. A pair of &lt;key,value&gt; (random small weight) will be inserted during runtime only when a new key appears in the training data and the hash table cannot find it.</p></blockquote></li></ul></li><li><p>每一个GPU中的hashtable是一样的吗？</p><ul><li></li></ul></li><li><p>输出hashing 的是什么，是需要传入embedding table 中的值还是直接输出embedding vector？且输出的hash是指向CPU mem还是GPU cache？</p><ul><li><!----></li></ul></li><li><p>发生hash冲突如何处理？</p><ul><li>业界处理方法： <ul><li>double hash：使用两个hash函数分别计算编码，再聚合（e.g. sum）</li><li>frequency hash：只对低频特征做hashing，高频特征直接查表（identity hash？）</li><li>其他方法：Bloom Emb、Compositional Emb、Hash Emb</li></ul></li><li>Hugectr处理方法：</li></ul></li><li></li></ul><h2 id="_3-embedding" tabindex="-1"><a class="header-anchor" href="#_3-embedding"><span>3. Embedding</span></a></h2><ul><li><!----></li><li><p><strong><!----></strong>：<!----></p></li><li><p>embedding的插入查询先后顺序问题如何解决（读后写问题）？</p><ul><li>若当前thread准备插入一个slot，发现此处key已存入但是value暂未存入，说明有其他线程正在操作当前slot，则当前thread不操作，等待其他thread插入value</li></ul></li><li><p>embedding和hashtable内是如何搜索的？（什么搜索策略or直接计算得到?）</p></li><li><p>embedding是如何划分的，与梯度数据的关系为何？</p><ul><li>embedding是按照slot进行划分成一个个embedding table，然后将这些slot分布式存储在不同GPU上，每一个slot代表一个特征域，比如说用户的国籍作为一个category特征可以组成一个特征域（这里的特征域可以是多种特征融合而成的一个大的特征域）</li><li>而embedding层之上的前馈网络梯度数据是另外存储在GPU上的，可以看见使用SOK的代码将他们分别存储<img src="/assets/image-20221108170653755-DPFXAhTN.png" alt="image-20221108170653755" loading="lazy"></li></ul></li><li><p><em>参考实现：</em></p><ul><li><p><a href="https://mp.weixin.qq.com/s/rEHhf32L09KXGJ9bbB2LEA" target="_blank" rel="noopener noreferrer">美团的实现<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>是对于ids庞大的sparse特征，将embedding分布式存储到gpus的显存中，使用gpu内hash表<!---->；</p></li><li><!----></li><li><blockquote><p>The total number of embedding parameters is tens of billions, and there are thousands of feature fields in each sample. As the range of input features is not fixed and unknown in advance, the team uses hash tables to uniquely identify each input feature before feeding into an embedding layer</p></blockquote></li><li><p>hashtable只是一种存储稀疏特征embedding的方式，其他特征的存储可使用Variable存储（也即使用hash压缩embedding）</p></li><li><blockquote><p><strong>稀疏特征</strong>（ID类特征，规模较大，使用HashTable存储）：由于每张卡的输入样本数据不同，因此输入的稀疏特征对应的特征向量，可能存放在其他GPU卡上。具体流程上，训练的前向我们通过卡间AllToAll通信，将每张卡的ID特征以Modulo的方式Partition到其他卡中，每张卡再去卡内的GPUHashTable查询稀疏特征向量，然后再通过卡间AllToAll通信，将第一次AllToAll从其他卡上拿到的ID特征以及对应的特征向量原路返回，通过两次卡间AllToAll通信，每张卡样本输入的ID特征都拿到对应的特征向量。训练的反向则会再次通过卡间AllToAll通信，将稀疏参数的梯度以Modulo的方式Partition到其他卡中，每张卡拿到自己的稀疏梯度后再执行稀疏优化器，完成大规模稀疏特征的优化。详细流程如下图所示：<img src="/assets/641-B16B_pOR.png" alt="图片" loading="lazy"></p></blockquote></li><li><p>传统embedding方法：对特征进行编码，得到ID（key），用ID去embedding里面查表，得到对应的embedding（需要存放非常大的embedding），使用hashtable做压缩：将ID传入hash function，得到hashed indices，再传入embedding table得到embedding</p></li><li><blockquote><p>压缩方法的话也有几个分类，这里简单提几个比较有趣的工作，第一个就是twitter在Recsys 2021发表的Double hash的方法。这种方法首先把特征分成了高频和低频，因为高频特征相对比例比较小，给每一个高频特征分配一个独立的embedding，它所占的空间也不是很大。对于低频特征，使用Double hash方法进行压缩，该hash方法是为了尽可能地减少冲突<img src="/assets/642-DwzHOy1P.png" alt="图片" loading="lazy"></p></blockquote></li><li><p>对于ids不大的sparse特征，直接使用数据副本的方式在每个gpu上存放所有特征；对于dense特征，也是使用replica方式在每个gpu上存放所有特征。<img src="/assets/640-CS1I0ZdW.png" alt="图片" style="zoom:200%;"></p></li></ul></li></ul><h2 id="_4-other" tabindex="-1"><a class="header-anchor" href="#_4-other"><span>4. Other</span></a></h2><ul><li><p><strong>Training Steps</strong>:</p><ol><li>Create the solver, reader and optimizer, then initialize the model.</li><li>Construct the model graph by adding input, sparse embedding and dense layers in order.</li><li>Compile the model and have an overview of the model graph.</li><li>Dump the model graph to the JSON file.</li><li>Fit the model, save the model weights and optimizer states implicitly.</li></ol></li><li><p>参数服务器是如何布置的（在做数据并行时是否有某个server做master，以及master和worker的关系）</p><ul><li>CPU做PS，GPU做worker</li><li><img src="/assets/image-20221108165507297-BOY8AWvn.png" alt="image-20221108165507297" tabindex="0" loading="lazy"><figcaption>image-20221108165507297</figcaption></li></ul></li><li><p>Embedding Training Cache (ETC)：</p><ul><li>用于解决embedding太大无法放入GPU显存的问题</li><li>将数据集划分为一个个子集，训练每个子集的过程称为一个pass，每个数据集都有从category特征中提取出的keyset</li><li>所有key都使用与数据集分类特征相同的数据类型（uint，ll等）</li><li>key可以以任何顺序存储</li></ul></li></ul><h2 id="_5-sok" tabindex="-1"><a class="header-anchor" href="#_5-sok"><span><!----></span></a></h2><ul><li><p>SOK项目结构（包含从父文件夹获取的HugeCTR等）</p><table><thead><tr><th style="text-align:center;">DIR</th><th style="text-align:center;">Discription</th></tr></thead><tbody><tr><td style="text-align:center;">cmakes</td><td style="text-align:center;">用于构建项目时查找NCCL、NVTX、Tensorflow组件及判断版本号</td></tr><tr><td style="text-align:center;">documents</td><td style="text-align:center;">用于生成文档，包含示例代码和benchmark</td></tr><tr><td style="text-align:center;">experiment</td><td style="text-align:center;">SOK的实验性功能更新</td></tr><tr><td style="text-align:center;">HugeCTR</td><td style="text-align:center;">HugeCTR核心功能</td></tr><tr><td style="text-align:center;">kit_cc</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">kit_cc_impl</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">notebooks</td><td style="text-align:center;">SOK jupyter 示例</td></tr><tr><td style="text-align:center;">sparse_operation_kit</td><td style="text-align:center;">sok核心功能</td></tr><tr><td style="text-align:center;">third_party</td><td style="text-align:center;">其他依赖项，json</td></tr><tr><td style="text-align:center;">unit_test</td><td style="text-align:center;">单元测试，包含tf1&amp;2单卡多卡测试</td></tr></tbody></table></li><li><p>从setup.py开始编译安装sok，需要依赖于父文件夹中的HugeCTR和third_party/json</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>os.system(&quot;cp -r ../HugeCTR ./&quot;)
os.system(&quot;mkdir third_party&quot;)
os.system(&quot;cp -r ../third_party/json ./third_party/&quot;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>Notes：</strong></p><ul><li><p>使用hvd时，hvd的初始化需要在最前面</p></li><li><p>使用tf1时，sok初始化要在其他变量初始化之前</p></li></ul></li><li><p>sok如何使用hctr的so库，从何处编译:</p><ul><li><p>hugectr/sparse_operation_kit/sparse_operation_kit/kit_lib.py: 导入libsparse_operation_kit.so</p></li><li><p>hugectr/sparse_operation_kit/sparse_operation_kit/operations/compat_ops_lib.py：导入libsparse_operation_kit_compat_ops.so</p></li></ul></li><li><p>HCTR加速embedding的方法：重新实现embedding层，GPU加速的hashtable（基于RAPIDS cuDF，可实现相对CPUx35倍加速），节省内存的sparse optimizer，各种embedding分布策略，NCCL通信</p></li><li><p>sok实现了多种embedding层，部分参数有</p><ul><li>SparseEmbedding： <ul><li>combiner：如何合并slot内的embedding：mean或sum</li><li>[max_vocabulary_size_per_gpu, embedding_vec_size]：embedding变量的大小</li><li>slot_num：slot的总数，也即特征域的数量</li><li>max_nnz：一个slot中key 的最大数量</li><li>max_feature_num：特征的最大数，为slot_num*max_nnz</li><li>use_hashtable：是否使用哈希表存储嵌入向量，若为False，则输入embedding层的key作为索引值查找embedding（key需在[0, max_vocabulary_size_per_gpu * gpu_num)]范围内）</li></ul></li><li>DenseEmbedding： <ul><li>[max_vocabulary_size_per_gpu, embedding_vec_size]：embedding变量的大小</li><li>slot_num：slot的总数，也即特征域的数量</li><li>nnz_per_slot：每个slot中key 的数量，且都相等（nnz：number of non zero非零实例，我的理解：nnz为1，则是one-hot, nnz大于1则是multi-hot）</li><li>dynamic_input：是否输入张量的大小是动态的（非固定值）</li><li>use_hashtable：是否使用哈希表存储嵌入向量，若为False，则输入embedding层的key作为索引值查找embedding</li></ul></li></ul></li><li><p>分布式embedding的相关函数：</p><ul><li>sparse_operation_kit.experiment.lookup.lookup_sparse(<em>params</em>, <em>sp_ids</em>, <em>hotness</em>, <em>combiners</em>)： <ul><li>支持分布式lookup</li><li>支持融合查找，同时查找多个参数</li><li><strong>params</strong>：<em>sok.Variable</em>列表</li><li><strong>sp_ids</strong> (<em>list</em>*,* <em>tuple</em>) – tf.SparseTensor or tf.RaggedTensor的列表</li><li><strong>hotness</strong> (<em>list</em>*,* <em>tuple</em>) – a list or tuple of int to specify the max hotness of each lookup.？？</li><li><strong>combiners</strong> (<em>list</em>*,* <em>tuple</em>) – 每次lookup的合并策略的列表</li></ul></li></ul></li></ul></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link nav-link prev" href="/blogs/hugectr_blog.html" aria-label="HugeCTR 学习笔记"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->HugeCTR 学习笔记</div></a><a class="route-link nav-link next" href="/blogs/torchrec_cn_embedding_note.html" aria-label="torchrec cn_embedding模块设计方案"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">torchrec cn_embedding模块设计方案<!----></div></a></nav><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">BradZhone's Blog</div><div class="vp-copyright">Copyright © 2024 BradZhone </div></footer></div><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-Coh1oo3x.js" defer></script>
  </body>
</html>
